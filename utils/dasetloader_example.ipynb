{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 数据的加载"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e671594ca070828"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 从UCI官方加载数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcc20f7088f61831"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset \n",
    "uci_dataset = fetch_ucirepo(id=45)\n",
    "\n",
    "# data (as pandas dataframes) \n",
    "X = uci_dataset.data.features\n",
    "y = uci_dataset.data.targets\n",
    "\n",
    "# variable information \n",
    "print(uci_dataset.variables)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "596442a5722cf962",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 从UCI加载数据，转化格式，转换为数字形式，并保存为mat数据 \n",
    "X为特征数据：num_instances,features\n",
    "Y为lable：(num_instances,1) 是一个列向量"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0aae6c7540c325f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from scipy.io import savemat\n",
    "\n",
    "# 数据集\n",
    "# 76 Nursery \n",
    "# 30 Contraceptive Method Choice\n",
    "# 146 Satellite\n",
    "# 33 Dermatology\n",
    "# 23 Chess\n",
    "# 19 Car\n",
    "# 12 Balance Scale\n",
    "# 39 Ecoli\n",
    "# 42 Glass\n",
    "# 78 Page Blocks\n",
    "# 90 Soybean (Large)\n",
    "# 69 Molecular Biology Splice-junction\n",
    "# 59 Letter\n",
    "uci_dataset = fetch_ucirepo(id=59)\n",
    "# 1. 特征和标签分离\n",
    "X = uci_dataset.data.features.values\n",
    "X_columns = uci_dataset.data.features.columns.tolist()\n",
    "y = uci_dataset.data.targets.values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc120ad7beb3db27",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 2. 特征编码\n",
    "label_encoder = LabelEncoder()\n",
    "X_encoded = np.copy(X)\n",
    "\n",
    "# # 将特征数据每一列都进行编码\n",
    "# for i in range(X.shape[1]):\n",
    "#     X_encoded[:, i] = label_encoder.fit_transform(X_encoded[:, i])\n",
    "y_encoded = label_encoder.fit_transform(y[:, 0])\n",
    "\n",
    "\n",
    "#index=[163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184]\n",
    "# 去除掉X_encoded、y_encoded中index里的索引对应的数据\n",
    "\n",
    "def remove_data_by_index(X1, y1, index_list):\n",
    "    \"\"\"\n",
    "    根据索引列表去除特征数据和标签数据中对应的数据。\n",
    "    :param X1: 特征数据，类型为numpy.ndarray\n",
    "    :param y1: 标签数据，类型为numpy.ndarray\n",
    "    :param index_list: 索引列表，类型为list\n",
    "    :return: 去除对应数据后的特征数据X2和标签数据y2\n",
    "    \"\"\"\n",
    "    index_list = sorted(index_list, reverse=True)  # 先对索引列表排序，倒序方便后续删除\n",
    "    for index in index_list:\n",
    "        X1 = np.delete(X1, index, axis=0)  # 按行删除特征数据中对应索引的数据\n",
    "        y1 = np.delete(y1, index, axis=0)  # 按行删除标签数据中对应索引的数据\n",
    "    return X1, y1\n",
    "\n",
    "\n",
    "#X_encoded,y_encoded=remove_data_by_index(X_encoded, y_encoded, index)\n",
    "# 转成int格式\n",
    "# X_encoded = X_encoded.astype(int)\n",
    "#y_encoded = label_encoder.fit_transform(y_encoded)\n",
    "y_encoded = y_encoded.astype(int)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e6013c5c80a9a4d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 保存为 .mat 文件\n",
    "data_dict = {'X': X_encoded, 'Y': y_encoded.reshape(-1, 1)}  # 以字典形式存储\n",
    "savemat('Letter.mat', data_dict)\n",
    "# 输出保存成功\n",
    "print(\"数据保存成功！\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7898e7587b7860b4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 五折交叉验证"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "555765ac90d56703"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def k_fold_cross_validation_with_soft_labels(model, X, y, n_splits=5):\n",
    "    \"\"\"\n",
    "    Perform 5-fold cross-validation and generate soft labels (probability predictions).\n",
    "\n",
    "    Parameters:\n",
    "    - model: A sklearn-compatible model with a `predict_proba` method.\n",
    "    - X: Feature matrix (numpy array or pandas DataFrame).\n",
    "    - y: Target vector (numpy array or pandas Series).\n",
    "\n",
    "    Returns:\n",
    "    - soft_labels: A numpy array containing the soft labels for each sample.\n",
    "    - scores: A list of accuracy scores for each fold.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)  # 5-fold cross-validation\n",
    "    soft_labels = np.zeros((len(y), len(np.unique(y))))  # Initialize array for soft labels\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # Split data into train and test\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # Clone and fit the model on the training set\n",
    "        model_clone = clone(model)\n",
    "        model_clone.fit(X_train, y_train)\n",
    "        # Generate soft labels (probability predictions)\n",
    "        y_proba = model_clone.predict_proba(X_test)\n",
    "        soft_labels[test_index] = y_proba\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred = np.argmax(y_proba, axis=1)  # Convert probabilities to class predictions\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        scores.append(score)\n",
    "\n",
    "    return soft_labels, scores\n",
    "\n",
    "\n",
    "# 示例用法\n",
    "if __name__ == \"__main__\":\n",
    "    from sklearn.datasets import load_iris\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    # 加载数据集\n",
    "    data = load_iris()\n",
    "    X, y = data.data, data.target\n",
    "\n",
    "    # 定义模型\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # 执行5折交叉验证\n",
    "    soft_labels, scores = k_fold_cross_validation_with_soft_labels(model, X, y, n_splits=5)\n",
    "    hard_labels = np.argmax(soft_labels, axis=1)\n",
    "    # 输出结果\n",
    "    print(\"Soft labels:\", soft_labels)\n",
    "    print(\"Hard labels:\", hard_labels)\n",
    "    print(\"Cross-validation scores:\", scores)\n",
    "    print(\"Mean accuracy:\", np.mean(scores))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "136614d4efa986da",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 从imbalanced-learn官网加载UCI数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3830b395126c04fe"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3163, 42)\n",
      "(array([-1,  1], dtype=int64), array([2870,  293], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "from imblearn.datasets import fetch_datasets\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "datasetname = 'sick_euthyroid'\n",
    "imba_dataset = fetch_datasets()[datasetname]\n",
    "print(imba_dataset.data.shape)\n",
    "x = imba_dataset.data\n",
    "y = imba_dataset.target\n",
    "# 计算唯一元素的数量\n",
    "print(np.unique(y, return_counts=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-16T13:23:30.195863Z",
     "start_time": "2025-02-16T13:23:30.019914Z"
    }
   },
   "id": "22495883074f86b6",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 保存为mat文件"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27319c4355dddb8c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 2. 特征编码\n",
    "label_encoder = LabelEncoder()\n",
    "X_encoded = np.copy(x)\n",
    "\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "# 保存为 .mat 文件\n",
    "data_dict = {'X': X_encoded, 'Y': y_encoded.reshape(-1, 1)}  # 以字典形式存储\n",
    "savemat(datasetname + '.mat', data_dict)\n",
    "# 输出保存成功\n",
    "print(\"数据保存成功！\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bc15127e04c808b",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
