{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 从UCI加载数据，转化格式，转换为数字形式，并保存为mat数据 \n",
    "X为特征数据：num_instances*features\n",
    "Y为lable：(num_instances,1) 是一个列向量"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd67632612062020"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Attribute1', 'Attribute2', 'Attribute3', 'Attribute4', 'Attribute5', 'Attribute6', 'Attribute7', 'Attribute8', 'Attribute9', 'Attribute10', 'Attribute11', 'Attribute12', 'Attribute13', 'Attribute14', 'Attribute15', 'Attribute16', 'Attribute17', 'Attribute18', 'Attribute19', 'Attribute20', 'Attribute21', 'Attribute22', 'Attribute23', 'Attribute24', 'Attribute25', 'Attribute26', 'Attribute27', 'Attribute28', 'Attribute29', 'Attribute30', 'Attribute31', 'Attribute32', 'Attribute33', 'Attribute34', 'Attribute35', 'Attribute36', 'class']\n",
      "准确率: 0.23303987571206627\n",
      "\n",
      "分类报告:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      1.00      0.38       450\n",
      "           1       0.00      0.00      0.00       186\n",
      "           2       0.00      0.00      0.00       416\n",
      "           3       0.00      0.00      0.00       201\n",
      "           4       0.00      0.00      0.00       219\n",
      "           5       0.00      0.00      0.00       459\n",
      "\n",
      "    accuracy                           0.23      1931\n",
      "   macro avg       0.04      0.17      0.06      1931\n",
      "weighted avg       0.05      0.23      0.09      1931\n",
      "\n",
      "Confusion Matrix:\n",
      "[[450   0   0   0   0   0]\n",
      " [186   0   0   0   0   0]\n",
      " [416   0   0   0   0   0]\n",
      " [201   0   0   0   0   0]\n",
      " [219   0   0   0   0   0]\n",
      " [459   0   0   0   0   0]]\n",
      "(1931, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.24326894, 0.11259506, 0.21212099, 0.10328532, 0.10662391,\n        0.22210578],\n       [0.24326894, 0.11259506, 0.21212099, 0.10328532, 0.10662391,\n        0.22210578],\n       [0.24326894, 0.11259506, 0.21212099, 0.10328532, 0.10662391,\n        0.22210578],\n       ...,\n       [0.24326894, 0.11259506, 0.21212099, 0.10328532, 0.10662391,\n        0.22210578],\n       [0.24326894, 0.11259506, 0.21212099, 0.10328532, 0.10662391,\n        0.22210578],\n       [0.24326894, 0.11259506, 0.21212099, 0.10328532, 0.10662391,\n        0.22210578]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from scipy.io import savemat\n",
    "# 76 Nursery \n",
    "# 30 Contraceptive Method Choice\n",
    "# 146 Satellite\n",
    "\n",
    "\n",
    "# 数据集\n",
    "uci_dataset = fetch_ucirepo(id=146)\n",
    "# 示例数据集\n",
    "data = uci_dataset.data\n",
    "print(data.headers.tolist())  # \n",
    "# 1. 特征和标签分离\n",
    "X = data.features.values\n",
    "X_columns = data.features.columns.tolist()\n",
    "y = data.targets.values\n",
    "\n",
    "# 3. 特征编码\n",
    "label_encoder = LabelEncoder()\n",
    "X_encoded = np.copy(X)\n",
    "# 将特征数据每一列都进行编码\n",
    "for i in range(X.shape[1]):\n",
    "    X_encoded[:, i] = label_encoder.fit_transform(X_encoded[:, i])\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "#indexs = np.where(y_encoded == 2)\n",
    "\n",
    "#X_encoded = np.delete(X_encoded, indexs[0], axis=0)\n",
    "# 转成float格式\n",
    "X_encoded = X_encoded.astype(float)\n",
    "#y_encoded = np.delete(y_encoded, indexs[0], axis=0)\n",
    "y_encoded = label_encoder.fit_transform(y_encoded)\n",
    "# 保存为 .mat 文件\n",
    "data_dict = {'X': X_encoded, 'Y': y_encoded.reshape(-1, 1)}  # 以字典形式存储\n",
    "savemat('Satellite.mat', data_dict)\n",
    "\n",
    "# 将数据集分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# 数据标准化\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# 构建并训练MLP模型\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(15,), max_iter=100, random_state=42,learning_rate_init=0.1)\n",
    "mlp.fit(X_train, y_train)\n",
    "index_pred_proba = mlp.predict_proba(X_test)\n",
    "# 预测和评估模型\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# 输出结果\n",
    "print(\"准确率:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n分类报告:\\n\", classification_report(y_test, y_pred))\n",
    "# 打印混淆矩阵\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(index_pred_proba.shape)\n",
    "index_pred_proba"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-25T14:28:56.476904Z",
     "start_time": "2024-11-25T14:28:50.912341Z"
    }
   },
   "id": "1751b2d934078a02",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## numpy转mat的demo"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "504701a453767c28"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(1, 3)\n",
      "数据已保存为 dataset.mat 文件。\n",
      "加载的 X：\n",
      " [[1.1 2.2 3.3]\n",
      " [4.4 5.5 6.6]\n",
      " [7.7 8.8 9.9]]\n",
      "加载的 y：\n",
      " [[0]\n",
      " [1]\n",
      " [0]]\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "\n",
    "# 示例数据\n",
    "X = np.array([[1.1, 2.2, 3.3], [4.4, 5.5, 6.6], [7.7, 8.8, 9.9]])  # 特征数据\n",
    "y = np.array([[0, 1, 0]])  # 标签数据\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "y = y.reshape(-1, 1)\n",
    "# 保存为 .mat 文件\n",
    "data_dict = {'X': X, 'y': y}  # 以字典形式存储\n",
    "savemat('dataset.mat', data_dict)\n",
    "\n",
    "print(\"数据已保存为 dataset.mat 文件。\")\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# 加载 .mat 文件\n",
    "loaded_data = loadmat('dataset.mat')\n",
    "\n",
    "XX = loaded_data['X']\n",
    "YY = loaded_data['y']\n",
    "# 查看加载的数据\n",
    "print(\"加载的 X：\\n\", XX)\n",
    "print(\"加载的 y：\\n\", YY)\n",
    "print(YY[:, 0].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-25T14:28:02.689130Z",
     "start_time": "2024-11-25T14:28:02.656157Z"
    }
   },
   "id": "9b685b02ce64a200",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 测试保存的mat"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "261af92fd4fdb709"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1533  703 1358  626  707 1508]\n",
      "(6435, 36)\n",
      "(6435,)\n",
      "[450 186 416 201 219 459]\n",
      "[0 1 2 3 4 5]\n",
      "准确率: 0.8208182288969446\n",
      "\n",
      "分类报告:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       450\n",
      "           1       0.98      0.96      0.97       186\n",
      "           2       0.81      0.82      0.82       416\n",
      "           3       0.46      0.32      0.38       201\n",
      "           4       0.83      0.80      0.82       219\n",
      "           5       0.75      0.86      0.80       459\n",
      "\n",
      "    accuracy                           0.82      1931\n",
      "   macro avg       0.80      0.79      0.79      1931\n",
      "weighted avg       0.81      0.82      0.81      1931\n",
      "\n",
      "Confusion Matrix:\n",
      "[[431   1   7   2   8   1]\n",
      " [  0 178   0   2   6   0]\n",
      " [  6   0 343  42   1  24]\n",
      " [  1   0  48  64   5  83]\n",
      " [  9   3   1   4 176  26]\n",
      " [  0   0  26  25  15 393]]\n",
      "(1931, 6)\n",
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from utils.dataset_utils import get_classes_indexes_counts\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# 导入必要的库\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "import numpy as np\n",
    "# 加载鸢尾花数据集\n",
    "# data = load_iris()\n",
    "mat_data = sio.loadmat('Satellite.mat')\n",
    "X = mat_data['X']  # 特征\n",
    "y = mat_data['Y'][:, 0]  # 标签\n",
    "classes, counts = get_classes_indexes_counts(y)\n",
    "print(counts)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "# 将数据集分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# classes, counts = get_classes_indexes_counts(np.argmax(y_test, axis=1))\n",
    "classes, counts = get_classes_indexes_counts(y_test)\n",
    "print(counts)\n",
    "# 数据标准化\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "# One-hot encode target variable 强制将类别转换为0-1序列，0表示不是该类，1表示属于该类\n",
    "\n",
    "# 构建并训练MLP模型\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(15,), max_iter=200, random_state=42,learning_rate_init=0.001)\n",
    "# mlp.fit(X_train, np.argmax(y_train, axis=1))\n",
    "mlp.fit(X_train, y_train)\n",
    "print(mlp.classes_)\n",
    "index_pred_proba = mlp.predict_proba(X_test)\n",
    "# 预测和评估模型\n",
    "y_pred = mlp.predict(X_test)\n",
    "#y_test_labels = np.argmax(y_test, axis=1)\n",
    "# y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_pred_labels = y_pred\n",
    "# 输出结果\n",
    "print(\"准确率:\", accuracy_score(y_test, y_pred_labels))\n",
    "print(\"\\n分类报告:\\n\", classification_report(y_test, y_pred_labels))\n",
    "# 打印混淆矩阵\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_labels))\n",
    "\n",
    "print(index_pred_proba.shape)\n",
    "res=np.sum(index_pred_proba, axis=1)\n",
    "print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-25T14:29:28.151262Z",
     "start_time": "2024-11-25T14:29:27.286669Z"
    }
   },
   "id": "d979cf5d8a3a5aa9",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### k-folds交叉验证\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "223ffd9203e56767"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 定义MLP模型\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, random_state=42)\n",
    "\n",
    "# 定义5折交叉验证\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 使用交叉验证进行预测\n",
    "y_pred = cross_val_predict(mlp_model, X, y, cv=kf)\n",
    "\n",
    "# 输出分类结果报告\n",
    "report = classification_report(y, y_pred, target_names=iris.target_names)\n",
    "print(report)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b9f77bc566ce7af",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 设置参数\n",
    "lambda_ = 1.2  # 指数分布的参数λ（lambda）\n",
    "threshold = 1.0  # 阈值（阈值决定了生成0或1）\n",
    "\n",
    "def generate_sequence(n):\n",
    "    sequence = []\n",
    "    for _ in range(n):\n",
    "        # 生成一个指数分布的随机数\n",
    "        value = random.expovariate(lambda_)\n",
    "        # 根据值与阈值的比较，生成 0 或 1\n",
    "        if value < threshold:\n",
    "            sequence.append(1)\n",
    "        else:\n",
    "            sequence.append(0)\n",
    "    return sequence\n",
    "\n",
    "# 生成一个包含100个元素的0和1的序列\n",
    "sequence = generate_sequence(100)\n",
    "print(sequence)\n",
    "random.randint(1,1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96d64983d62982f3",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
