{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# E-MOSAIC\n",
    "\n",
    "引用自[E. R. Q. Fernandes, A. C. P. L. F. de Carvalho and X. Yao, \"Ensemble of Classifiers Based on Multiobjective Genetic Sampling for Imbalanced Data,\" in IEEE Transactions on Knowledge and Data Engineering, vol. 32, no. 6, pp. 1104-1115, 1 June 2020, doi: 10.1109/TKDE.2019.2898861.]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8825cc0902bf4ba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据集的预处理 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a36fc2d4930535ec"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################加载数据集#########################\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (12960, 8) instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 26\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# 对特征进行编码\u001B[39;00m\n\u001B[0;32m     25\u001B[0m label_encoder \u001B[38;5;241m=\u001B[39m LabelEncoder()\n\u001B[1;32m---> 26\u001B[0m features_encoded \u001B[38;5;241m=\u001B[39m \u001B[43mlabel_encoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m# 将数据由dataframe转换成numpy格式\u001B[39;00m\n\u001B[0;32m     29\u001B[0m dataset_x \u001B[38;5;241m=\u001B[39m label_encoder\u001B[38;5;241m.\u001B[39mto_numpy()\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114\u001B[0m, in \u001B[0;36mLabelEncoder.fit_transform\u001B[1;34m(self, y)\u001B[0m\n\u001B[0;32m    101\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit_transform\u001B[39m(\u001B[38;5;28mself\u001B[39m, y):\n\u001B[0;32m    102\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Fit label encoder and return encoded labels.\u001B[39;00m\n\u001B[0;32m    103\u001B[0m \n\u001B[0;32m    104\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;124;03m        Encoded labels.\u001B[39;00m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 114\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mcolumn_or_1d\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwarn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_, y \u001B[38;5;241m=\u001B[39m _unique(y, return_inverse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m y\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\utils\\validation.py:1367\u001B[0m, in \u001B[0;36mcolumn_or_1d\u001B[1;34m(y, dtype, warn)\u001B[0m\n\u001B[0;32m   1356\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   1357\u001B[0m             (\n\u001B[0;32m   1358\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA column-vector y was passed when a 1d array was\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1363\u001B[0m             stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m   1364\u001B[0m         )\n\u001B[0;32m   1365\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _asarray_with_order(xp\u001B[38;5;241m.\u001B[39mreshape(y, (\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,)), order\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m\"\u001B[39m, xp\u001B[38;5;241m=\u001B[39mxp)\n\u001B[1;32m-> 1367\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1368\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my should be a 1d array, got an array of shape \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(shape)\n\u001B[0;32m   1369\u001B[0m )\n",
      "\u001B[1;31mValueError\u001B[0m: y should be a 1d array, got an array of shape (12960, 8) instead."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from utils.dataset_utils import get_classes_indexes_counts\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"#########################加载数据集#########################\")\n",
    "'''\n",
    "id = :\n",
    "12 balance_scale  \n",
    "76 nursery \n",
    "'''\n",
    "# 数据集\n",
    "uci_dataset = fetch_ucirepo(id=76)\n",
    "#mat_data = sio.loadmat('../../data/dataset/USPS.mat') \n",
    "# 提取变量\n",
    "features = uci_dataset.data.features  # 特征数据\n",
    "targets = uci_dataset.data.targets  # 标签lable\n",
    "\n",
    "# 对特征进行编码\n",
    "label_encoder = LabelEncoder()\n",
    "features_encoded = label_encoder.fit_transform(features)\n",
    "# 将数据由dataframe转换成numpy格式\n",
    "\n",
    "dataset_x = label_encoder.to_numpy()\n",
    "dataset_y = targets.to_numpy()[:, 0]\n",
    "\n",
    "# dataset_x = mat_data['X']\n",
    "# dataset_y = mat_data['Y'][:, 0]  # mat_data['Y']得到的形状为[n,1]，通过[:,0]，得到形状[n,]\n",
    "\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", dataset_x.shape)\n",
    "print(\"label:\", dataset_y.shape)\n",
    "\n",
    "# One-hot encode target variable 强制将类别转换为0-1序列，0表示不是该类，1表示属于该类\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_onehot = encoder.fit_transform(dataset_y.reshape(-1, 1))\n",
    "print(\"label:\", y_onehot.shape)\n",
    "# 统计每个类别的个数，dataset_y.max()+1是类别的个数\n",
    "classes, counts = get_classes_indexes_counts(\n",
    "    np.argmax(y_onehot, axis=1))  #np.argmax(y_onehot, axis=1)找最大值的索引，将0-1序列转化为0,1,2,3......的整数标签\n",
    "print(\"每种类别的数量：\", counts)\n",
    "\n",
    "#############################################划分数据集##################################\n",
    "print(\"#########################划分数据集#########################\")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset_x, y_onehot, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the feature data\n",
    "#scaler = StandardScaler()\n",
    "#X_train_scaled = scaler.fit_transform(x_train)\n",
    "#X_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", x_train.shape)\n",
    "print(\"label:\", y_train.shape)\n",
    "\n",
    "# 统计每个类别的个数 np.argmax(y_train, axis=1) Convert one-hot encoded test labels back to single class labels\n",
    "classes_train, counts_train = get_classes_indexes_counts(np.argmax(y_train, axis=1))\n",
    "print(\"训练集每种类别的数量：\", counts_train)\n",
    "\n",
    "classes_test, counts_test = get_classes_indexes_counts(np.argmax(y_test, axis=1))\n",
    "print(\"测试集每种类别的数量：\", counts_test)\n",
    "\n",
    "print(\"#########################平衡数据集#########################\")\n",
    "# 确定每个类别的数量\n",
    "num_instances = int(counts_train.min() * 0.9)  # 向下取整\n",
    "print(\"最小数量:\", num_instances)\n",
    "\n",
    "# 在每个类别中随机的选择该数量的实例的索引\n",
    "balanced_classes = np.array([])\n",
    "for indexes in classes_train:\n",
    "    random_selecte_indices = np.random.choice(indexes, size=num_instances, replace=False)\n",
    "    balanced_classes = np.hstack((balanced_classes, random_selecte_indices))\n",
    "balanced_classes = np.sort(balanced_classes).astype(int)\n",
    "\n",
    "# 得到平衡的数据集\n",
    "balanced_dataset_x = []\n",
    "balanced_dataset_y = []\n",
    "for index in balanced_classes:\n",
    "    balanced_dataset_x.append(x_train[index])\n",
    "    balanced_dataset_y.append(y_train[index, :])\n",
    "balanced_dataset_x = np.array(balanced_dataset_x)\n",
    "balanced_dataset_y = np.array(balanced_dataset_y).astype(int)\n",
    "\n",
    "# 显示数据集分布\n",
    "print(\"平衡的数据集的特征数据:\", balanced_dataset_x.shape)\n",
    "print(\"label:\", balanced_dataset_y.shape)\n",
    "\n",
    "# 统计每个类别的个数\n",
    "classes_balanced_dataset, counts_balanced_dataset = get_classes_indexes_counts(np.argmax(balanced_dataset_y, axis=1))\n",
    "print(\"平衡的数据集中每种类别的数量：\", counts_balanced_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-23T09:21:50.500509Z",
     "start_time": "2024-11-23T09:21:01.956878Z"
    }
   },
   "id": "abb6e4d62d32f110",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 评价函数\n",
    "（G-mean,mAUC两个目标）"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df0310c8b3d57eb3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.stats import gmean\n",
    "from sklearn.metrics import precision_score, roc_auc_score, accuracy_score\n",
    "from scipy.stats import mode\n",
    "\n",
    "\n",
    "##########################由个体得到选择的实例子集的索引###########################\n",
    "def get_indices(individual):\n",
    "    '''\n",
    "    :param individual: individual（用实值进行编码）\n",
    "    :return: 被选择实例的索引\n",
    "    '''\n",
    "    individual = np.round(individual)  # 数据范围在0-1之间，转化成int的同时会舍去小数部分，从而将个体映射到0-1编码\n",
    "    indices = np.where(individual == 1)  # 1代表选择该实例，返回值是tuple，tuple[0]取元组中的第一个元素\n",
    "    return indices[0]\n",
    "\n",
    "\n",
    "###########################获取实例子集############################\n",
    "def get_subset(individual):\n",
    "    '''\n",
    "    :param individual: \n",
    "    :return: 实例子集\n",
    "    '''\n",
    "    indices = get_indices(individual)\n",
    "    x_sub = balanced_dataset_x[indices, :]\n",
    "    y_sub = balanced_dataset_y[indices, :]\n",
    "    return x_sub, y_sub\n",
    "\n",
    "##########################适应度函数（PPV和PFC，为主要、次要指标）#################################\n",
    "def fitness_function(individual):\n",
    "    # 使用训练数据进行预测\n",
    "    index_pred = individual.mlp.predict(x_test)  # 计算accuracy、PPV\n",
    "    index_pred_proba = individual.mlp.predict_proba(x_test)  # 计算mAUC\n",
    "    print(index_pred_proba.shape)\n",
    "    print(individual.mlp.classes_)\n",
    "    print(index_pred_proba)\n",
    "\n",
    "    # Convert one-hot encoded test labels back to single class labels\n",
    "    y_test_labels = np.argmax(y_test, axis=1)\n",
    "    print(y_test_labels.shape)\n",
    "    print(y_test_labels)\n",
    "    \n",
    "    y_pred_labels = np.argmax(index_pred, axis=1)\n",
    "    _, counts = get_classes_indexes_counts(y_test_labels)\n",
    "\n",
    "    ######################G-mean#########################\n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(y_test_labels, y_pred_labels)\n",
    "\n",
    "    # 计算每类召回率（每类正确预测个数 / 该类总数）\n",
    "    recall_per_class = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "    # 计算G-Mean\n",
    "    g_mean = np.prod(recall_per_class) ** (1 / len(recall_per_class))\n",
    "    geometric_mean = gmean(recall_per_class)\n",
    "    print(\"两种G-mean的计算结果：\", geometric_mean, g_mean)\n",
    "    ######################mAUC#######################\n",
    "    # 计算 ROC AUC（ovo+macro）\n",
    "    auc_ovo_macro = roc_auc_score(y_test_labels, index_pred_proba, multi_class=\"ovo\", average=\"macro\")\n",
    "    return round(geometric_mean, 4), round(auc_ovo_macro, 4)\n",
    "\n",
    "\n",
    "# 集成分类器的投票\n",
    "def vote_ensembles(save_ensembles):\n",
    "    y_pred_labels_ensembles = []\n",
    "    y_test_labels = np.argmax(y_test, axis=1)\n",
    "    for ensemble in save_ensembles:\n",
    "        index_pred = ensemble.predict(x_test)  # 计算accuracy、PPV\n",
    "        # Convert one-hot encoded test labels back to single class labels\n",
    "        y_pred_labels = np.argmax(index_pred, axis=1)\n",
    "        y_pred_labels_ensembles.append(y_pred_labels)\n",
    "    # 按列投票，取每列中出现次数最多的类别作为最终分类结果\n",
    "    final_pred_result = mode(y_pred_labels_ensembles, axis=0, keepdims=False).mode.flatten()\n",
    "    cm = confusion_matrix(y_test_labels, final_pred_result)\n",
    "    # 计算每类召回率（每类正确预测个数 / 该类总数）\n",
    "    recall_per_class = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "    # 计算G-Mean\n",
    "    geometric_mean = gmean(recall_per_class)\n",
    "    # 计算准确率\n",
    "    accuracy = accuracy_score(y_test_labels, final_pred_result)\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "    # 打印分类报告\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test_labels, final_pred_result))\n",
    "\n",
    "    # 打印混淆矩阵\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test_labels, final_pred_result))\n",
    "    return geometric_mean\n",
    "\n",
    "\n",
    "from array import array\n",
    "\n",
    "\n",
    "# 在种群中找到重复的个体\n",
    "def find_duplicates(pop, similar=0.85):\n",
    "    \"\"\"\n",
    "    找到重复个体的索引。\n",
    "    :param arrays: 一个包含 array.array 的列表\n",
    "    :param threshold: 重复的判断阈值\n",
    "    :return: 重复对的索引列表\n",
    "    \"\"\"\n",
    "    n = len(pop)\n",
    "    duplicates = []  # 用于记录重复对的索引\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            # 当前两组数组\n",
    "            a = pop[i]\n",
    "            b = pop[j]\n",
    "\n",
    "            # 计算1的个数\n",
    "            ones_a = sum(a)\n",
    "            ones_b = sum(b)\n",
    "\n",
    "            # 如果其中一个数组全是0，不可能满足条件\n",
    "            if ones_a == 0 or ones_b == 0:\n",
    "                continue\n",
    "\n",
    "            # 计算交集中的1的数量\n",
    "            common_ones = sum(x & y for x, y in zip(a, b))\n",
    "\n",
    "            # 判断是否满足重复的定义\n",
    "            if (common_ones / ones_a > similar) and (common_ones / ones_b > similar):\n",
    "                duplicates.append((i, j))\n",
    "\n",
    "    return duplicates\n",
    "\n",
    "\n",
    "# 根据索引对，去除种群中重复的个体\n",
    "def remove_duplicates(pop, duplicates):\n",
    "    \"\"\"\n",
    "    移除重复的个体。\n",
    "    :param arrays: 一个包含 array.array 的列表\n",
    "    :param duplicates: 重复对的索引列表\n",
    "    :return: 去重后的列表\n",
    "    \"\"\"\n",
    "    # 找到所有需要移除的索引\n",
    "    to_remove = set(j for _, j in duplicates)  # 只保留后出现的索引\n",
    "    # 构造去重后的列表\n",
    "    return [pop[i] for i in range(len(pop)) if i not in to_remove]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42403853ade4c910",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NDGA-II"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bb11017ee1ef86"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from instance_selection.nsga_2.genetic_operator import selNSGA2, mutate_binary_inversion, selTournamentDCD\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # 忽略警告\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import array\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "\n",
    "# 最大化评价目标\n",
    "creator.create(\"FitnessMaxAndMax\", base.Fitness, weights=(1.0, 1.0))\n",
    "'''\n",
    "fitness:适应度：Gmean和mAUC\n",
    "pfc：每个分类器的成对故障信用，用于评估分类器集合的多样性\n",
    "'''\n",
    "creator.create(\"Individual\", array.array, typecode='i', fitness=creator.FitnessMaxAndMax, pfc=None, mlp=None)\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "NDIM = num_instances\n",
    "\n",
    "# 二进制编码\n",
    "toolbox.register(\"attr_binary\", random.randint, 0, 1)  # 0-1编码\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_binary, n=num_instances)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", fitness_function)\n",
    "\n",
    "# 单点交叉\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "\n",
    "# 二进制突变\n",
    "toolbox.register(\"mutate\", mutate_binary_inversion)\n",
    "\n",
    "# NSGA-II选择\n",
    "toolbox.register(\"select\", selNSGA2, x_test=X_test_scaled, y_test=y_test)\n",
    "\n",
    "# 找到种群中重复个体的索引对\n",
    "toolbox.register(\"find_duplicates\", find_duplicates)\n",
    "\n",
    "# 去重\n",
    "toolbox.register(\"remove_duplicates\", remove_duplicates)\n",
    "\n",
    "# 创建一个MLP模型\n",
    "init_mlp = MLPClassifier(hidden_layer_sizes=(15,), max_iter=500, random_state=42)\n",
    "\n",
    "\n",
    "# 绘制Pareto Front曲线\n",
    "def plot_front(fronts, gen, title):\n",
    "    \"\"\"绘制当前代非支配排序的第一等级前沿\"\"\"\n",
    "    fitnesses = [ind.fitness.values for ind in fronts]\n",
    "    plt.scatter(*zip(*fitnesses), marker='o', label=f\"Generation {gen}\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"mAUC\")\n",
    "    plt.ylabel(\"G-mean\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f286b798f84564ae",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 种群的迭代"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3af0218c1c802bf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def main(seed=None):\n",
    "    random.seed(seed)\n",
    "\n",
    "    NGEN = 30  # 迭代次数\n",
    "    POPSIZE = 40  # 种群数量\n",
    "    CXPB = 1.0  # 交叉因子/交叉率\n",
    "    MR = 0.2  # 突变因子/突变率\n",
    "    SIMILAR = 0.85\n",
    "\n",
    "    ####################################迭代过程的记录#############################\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = \"gen\", \"evals\", \"fronts\", \"duplicates\"\n",
    "    ####################################种群的初始化###########################\n",
    "    pop = toolbox.population(n=POPSIZE)\n",
    "    ####################################计算初始种群的适应度###########################\n",
    "    stop_sign = 0\n",
    "    ensembles = []  # 当前每个个体对应的mlp模型\n",
    "    save_ensembles = []  # 保存最好的集成模型\n",
    "    current_ensembles = []  # 存储当前种群对应的集成模型\n",
    "    g_means_record = []\n",
    "    #pop_x_sub = []  # 当前每个个体的实例选择的特征数据\n",
    "    #pop_y_sub = []  # 当前每个个体对应的实例选择的lable\n",
    "    duplicates = []\n",
    "    # 对于每个个体都训练得到一个mlp模型\n",
    "    for i in range(len(pop)):\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(15,), max_iter=500, random_state=42)\n",
    "        x_sub, y_sub = get_subset(pop[i])\n",
    "        mlp.fit(x_sub, y_sub)\n",
    "        ensembles.append(mlp)\n",
    "        #pop_x_sub.append(x_sub)\n",
    "        #pop_y_sub.append(y_sub)\n",
    "        pop[i].mlp = mlp\n",
    "\n",
    "    # 由mlp模型得到个体的适应度\n",
    "    for i in range(len(pop)):\n",
    "        pop[i].fitness.values = toolbox.evaluate(pop[i])\n",
    "\n",
    "    #################################计算PFC并进行非支配排序#########################################\n",
    "    # 计算PFC并进行非支配排序 PFC代替拥挤距离\n",
    "    pop, pareto_fronts = toolbox.select(pop, len(pop))\n",
    "    # 保存第一个pareto_front中的模型，进行集成\n",
    "    for ind in pareto_fronts[0]:\n",
    "        save_ensembles.append(ind.mlp)\n",
    "    g_mean = vote_ensembles(save_ensembles)\n",
    "    g_means_record.append(g_mean)\n",
    "    \n",
    "    # record = stats.compile(pop)\n",
    "    # logbook.record(gen=0, evals=len(pop), **record)\n",
    "    # print(logbook.stream)\n",
    "    ####################################种群的迭代#################################################\n",
    "    for gen in range(1, NGEN + 1):\n",
    "        # 清空当前的集成分类器\n",
    "        current_ensembles.clear()\n",
    "        # 选择\n",
    "        offspring = selTournamentDCD(pop, POPSIZE)\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "        # 交叉\n",
    "        for i in range(0, len(offspring) - 1, 2):\n",
    "            if random.random() <= CXPB:\n",
    "                offspring[i], offspring[i + 1] = toolbox.mate(offspring[i], offspring[i + 1])\n",
    "            # 突变\n",
    "            offspring[i] = toolbox.mutate(offspring[i], MR)[0]\n",
    "            offspring[i + 1] = toolbox.mutate(offspring[i + 1], MR)[0]\n",
    "            del offspring[i].fitness.values, offspring[i + 1].fitness.values\n",
    "\n",
    "        # 计算新的种群适应度 \n",
    "        ensembles.clear()\n",
    "        #pop_x_sub.clear()\n",
    "        #pop_y_sub.clear()\n",
    "        for i in range(len(offspring)):\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=(15,), max_iter=500, random_state=42)\n",
    "            x_sub, y_sub = get_subset(offspring[i])\n",
    "            mlp.fit(x_sub, y_sub)\n",
    "            ensembles.append(mlp)\n",
    "            #pop_x_sub.append(x_sub)\n",
    "            #pop_y_sub.append(y_sub)\n",
    "            offspring[i].mlp = mlp\n",
    "        for i in range(len(offspring)):\n",
    "            offspring[i].fitness.values = toolbox.evaluate(offspring[i])\n",
    "\n",
    "        # 种群的合并\n",
    "        new_pop = pop + offspring\n",
    "\n",
    "        # 找到重复个体的索引对\n",
    "        duplicates = toolbox.find_duplicates(new_pop, SIMILAR)\n",
    "        # 去除对应重复的个体\n",
    "        new_pop = toolbox.remove_duplicates(new_pop, duplicates)\n",
    "        ###########################################再次进行突变################################################\n",
    "        for ind in range(len(offspring)):\n",
    "            # 突变\n",
    "            offspring[i] = toolbox.mutate(offspring[i], MR)[0]\n",
    "            del offspring[i].fitness.values\n",
    "        # 计算新的种群适应度 \n",
    "        ensembles.clear()\n",
    "        #pop_x_sub.clear()\n",
    "        #pop_y_sub.clear()\n",
    "        for i in range(len(offspring)):\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=(15,), max_iter=500, random_state=42)\n",
    "            x_sub, y_sub = get_subset(offspring[i])\n",
    "            mlp.fit(x_sub, y_sub)\n",
    "            ensembles.append(mlp)\n",
    "            #pop_x_sub.append(x_sub)\n",
    "            #pop_y_sub.append(y_sub)\n",
    "            offspring[i].mlp = mlp\n",
    "        for i in range(len(offspring)):\n",
    "            offspring[i].fitness.values = toolbox.evaluate(offspring[i])\n",
    "\n",
    "        # 种群的合并\n",
    "        pop = new_pop + offspring\n",
    "        ###############################################得到pareto_fronts############################################\n",
    "        pop, pareto_fronts = toolbox.select(pop, POPSIZE)\n",
    "        plot_front(pareto_fronts[0], gen, title=\"Pareto Front (Current Generation)\")\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=gen, evals=len(pop), fronts=len(pareto_fronts[0]), duplicates=len(duplicates), **record)\n",
    "        print(logbook.stream)\n",
    "        # 保存第一个等级里的mlp模型进行集成\n",
    "        for ind in pareto_fronts[0]:\n",
    "            current_ensembles.append(ind.mlp)\n",
    "        g_mean = vote_ensembles(current_ensembles)\n",
    "        if g_mean > g_means_record[-1]:  # 当前的gmean与列表最后一个gmean做对比\n",
    "            save_ensembles = current_ensembles\n",
    "            g_means_record.append(g_mean)\n",
    "            stop_sign = 0\n",
    "        else:\n",
    "            stop_sign += 1\n",
    "        if stop_sign == 10:\n",
    "            break\n",
    "    return pop, logbook, save_ensembles\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pop, stats, ensembles = main()\n",
    "\n",
    "    print(\"##############################集成分类器的预测结果：################################\")\n",
    "    vote_ensembles(ensembles)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8deac9b0ca9c40b",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
