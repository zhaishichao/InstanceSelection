{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# E-MOSAIC\n",
    "\n",
    "引用自[E. R. Q. Fernandes, A. C. P. L. F. de Carvalho and X. Yao, \"Ensemble of Classifiers Based on Multiobjective Genetic Sampling for Imbalanced Data,\" in IEEE Transactions on Knowledge and Data Engineering, vol. 32, no. 6, pp. 1104-1115, 1 June 2020, doi: 10.1109/TKDE.2019.2898861.]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8825cc0902bf4ba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据集的预处理 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a36fc2d4930535ec"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################加载数据集#########################\n",
      "特征数据: (625, 4)\n",
      "label: (625,)\n",
      "label: (625, 3)\n",
      "每种类别的数量： [ 49 288 288]\n",
      "#########################划分数据集#########################\n",
      "特征数据: (437, 4)\n",
      "label: (437, 3)\n",
      "训练集每种类别的数量： [ 31 208 198]\n",
      "测试集每种类别的数量： [18 80 90]\n",
      "#########################平衡数据集#########################\n",
      "最小数量: 27\n",
      "平衡的数据集的特征数据: (81, 4)\n",
      "label: (81, 3)\n",
      "平衡的数据集中每种类别的数量： [27 27 27]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from utils.dataset_utils import get_classes_indexes_counts\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"#########################加载数据集#########################\")\n",
    "'''\n",
    "id = 12 balance_scale  \n",
    "'''\n",
    "# 数据集\n",
    "uci_dataset = fetch_ucirepo(id=12)\n",
    "#mat_data = sio.loadmat('../../data/dataset/USPS.mat') \n",
    "# 提取变量\n",
    "features = uci_dataset.data.features  # 特征数据\n",
    "targets = uci_dataset.data.targets  # 标签lable\n",
    "# 将数据由dataframe转换成numpy格式\n",
    "\n",
    "dataset_x = features.to_numpy()\n",
    "dataset_y = targets.to_numpy()[:, 0]\n",
    "\n",
    "# dataset_x = mat_data['X']\n",
    "# dataset_y = mat_data['Y'][:, 0]  # mat_data['Y']得到的形状为[n,1]，通过[:,0]，得到形状[n,]\n",
    "\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", dataset_x.shape)\n",
    "print(\"label:\", dataset_y.shape)\n",
    "\n",
    "# One-hot encode target variable 强制将类别转换为0-1序列，0表示不是该类，1表示属于该类\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_onehot = encoder.fit_transform(dataset_y.reshape(-1, 1))\n",
    "print(\"label:\", y_onehot.shape)\n",
    "# 统计每个类别的个数，dataset_y.max()+1是类别的个数\n",
    "classes, counts = get_classes_indexes_counts(\n",
    "    np.argmax(y_onehot, axis=1))  #np.argmax(y_onehot, axis=1)找最大值的索引，将0-1序列转化为0,1,2,3......的整数标签\n",
    "print(\"每种类别的数量：\", counts)\n",
    "\n",
    "#############################################划分数据集##################################\n",
    "print(\"#########################划分数据集#########################\")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset_x, y_onehot, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the feature data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(x_train)\n",
    "X_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", x_train.shape)\n",
    "print(\"label:\", y_train.shape)\n",
    "\n",
    "# 统计每个类别的个数 np.argmax(y_train, axis=1) Convert one-hot encoded test labels back to single class labels\n",
    "classes_train, counts_train = get_classes_indexes_counts(np.argmax(y_train, axis=1))\n",
    "print(\"训练集每种类别的数量：\", counts_train)\n",
    "\n",
    "classes_test, counts_test = get_classes_indexes_counts(np.argmax(y_test, axis=1))\n",
    "print(\"测试集每种类别的数量：\", counts_test)\n",
    "\n",
    "print(\"#########################平衡数据集#########################\")\n",
    "# 确定每个类别的数量\n",
    "num_instances = int(counts_train.min() * 0.9)  # 向下取整\n",
    "print(\"最小数量:\", num_instances)\n",
    "\n",
    "# 在每个类别中随机的选择该数量的实例的索引\n",
    "balanced_classes = np.array([])\n",
    "for indexes in classes_train:\n",
    "    random_selecte_indices = np.random.choice(indexes, size=num_instances, replace=False)\n",
    "    balanced_classes = np.hstack((balanced_classes, random_selecte_indices))\n",
    "balanced_classes = np.sort(balanced_classes).astype(int)\n",
    "\n",
    "# 得到平衡的数据集\n",
    "balanced_dataset_x = []\n",
    "balanced_dataset_y = []\n",
    "for index in balanced_classes:\n",
    "    balanced_dataset_x.append(x_train[index])\n",
    "    balanced_dataset_y.append(y_train[index, :])\n",
    "balanced_dataset_x = np.array(balanced_dataset_x)\n",
    "balanced_dataset_y = np.array(balanced_dataset_y).astype(int)\n",
    "\n",
    "# 显示数据集分布\n",
    "print(\"平衡的数据集的特征数据:\", balanced_dataset_x.shape)\n",
    "print(\"label:\", balanced_dataset_y.shape)\n",
    "\n",
    "# 统计每个类别的个数\n",
    "classes_balanced_dataset, counts_balanced_dataset = get_classes_indexes_counts(np.argmax(balanced_dataset_y, axis=1))\n",
    "print(\"平衡的数据集中每种类别的数量：\", counts_balanced_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:06:06.026945Z",
     "start_time": "2024-11-22T15:06:00.448902Z"
    }
   },
   "id": "abb6e4d62d32f110",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 评价函数\n",
    "（G-mean,mAUC两个目标）"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df0310c8b3d57eb3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.stats import gmean\n",
    "from sklearn.metrics import precision_score, roc_auc_score, accuracy_score\n",
    "from scipy.stats import mode\n",
    "\n",
    "\n",
    "##########################由个体得到选择的实例子集的索引###########################\n",
    "def get_indices(individual):\n",
    "    '''\n",
    "    :param individual: individual（用实值进行编码）\n",
    "    :return: 被选择实例的索引\n",
    "    '''\n",
    "    individual = np.round(individual)  # 数据范围在0-1之间，转化成int的同时会舍去小数部分，从而将个体映射到0-1编码\n",
    "    indices = np.where(individual == 1)  # 1代表选择该实例，返回值是tuple，tuple[0]取元组中的第一个元素\n",
    "    return indices[0]\n",
    "\n",
    "\n",
    "###########################获取实例子集############################\n",
    "def get_subset(individual):\n",
    "    '''\n",
    "    :param individual: \n",
    "    :return: 实例子集\n",
    "    '''\n",
    "    indices = get_indices(individual)\n",
    "    x_sub = balanced_dataset_x[indices, :]\n",
    "    y_sub = balanced_dataset_y[indices, :]\n",
    "    return x_sub, y_sub\n",
    "\n",
    "##########################适应度函数（PPV和PFC，为主要、次要指标）#################################\n",
    "def fitness_function(individual):\n",
    "    # 使用训练数据进行预测\n",
    "    index_pred = individual.mlp.predict(x_test)  # 计算accuracy、PPV\n",
    "    index_pred_proba = individual.mlp.predict_proba(x_test)  # 计算mAUC\n",
    "    print(index_pred_proba.shape)\n",
    "    print(index_pred_proba)\n",
    "\n",
    "    # Convert one-hot encoded test labels back to single class labels\n",
    "    y_test_labels = np.argmax(y_test, axis=1)\n",
    "    print(y_test_labels.shape)\n",
    "    print(y_test_labels)\n",
    "    \n",
    "    y_pred_labels = np.argmax(index_pred, axis=1)\n",
    "    _, counts = get_classes_indexes_counts(y_test_labels)\n",
    "\n",
    "    ######################G-mean#########################\n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(y_test_labels, y_pred_labels)\n",
    "\n",
    "    # 计算每类召回率（每类正确预测个数 / 该类总数）\n",
    "    recall_per_class = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "    # 计算G-Mean\n",
    "    g_mean = np.prod(recall_per_class) ** (1 / len(recall_per_class))\n",
    "    geometric_mean = gmean(recall_per_class)\n",
    "    print(\"两种G-mean的计算结果：\", geometric_mean, g_mean)\n",
    "    ######################mAUC#######################\n",
    "    # 计算 ROC AUC（ovo+macro）\n",
    "    auc_ovo_macro = roc_auc_score(y_test_labels, index_pred_proba, multi_class=\"ovo\", average=\"macro\")\n",
    "    return round(geometric_mean, 4), round(auc_ovo_macro, 4)\n",
    "\n",
    "\n",
    "# 集成分类器的投票\n",
    "def vote_ensembles(save_ensembles):\n",
    "    y_pred_labels_ensembles = []\n",
    "    y_test_labels = np.argmax(y_test, axis=1)\n",
    "    for ensemble in save_ensembles:\n",
    "        index_pred = ensemble.predict(x_test)  # 计算accuracy、PPV\n",
    "        # Convert one-hot encoded test labels back to single class labels\n",
    "        y_pred_labels = np.argmax(index_pred, axis=1)\n",
    "        y_pred_labels_ensembles.append(y_pred_labels)\n",
    "    # 按列投票，取每列中出现次数最多的类别作为最终分类结果\n",
    "    final_pred_result = mode(y_pred_labels_ensembles, axis=0, keepdims=False).mode.flatten()\n",
    "    cm = confusion_matrix(y_test_labels, final_pred_result)\n",
    "    # 计算每类召回率（每类正确预测个数 / 该类总数）\n",
    "    recall_per_class = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "    # 计算G-Mean\n",
    "    geometric_mean = gmean(recall_per_class)\n",
    "    # 计算准确率\n",
    "    accuracy = accuracy_score(y_test_labels, final_pred_result)\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "    # 打印分类报告\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test_labels, final_pred_result))\n",
    "\n",
    "    # 打印混淆矩阵\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test_labels, final_pred_result))\n",
    "    return geometric_mean\n",
    "\n",
    "\n",
    "from array import array\n",
    "\n",
    "\n",
    "# 在种群中找到重复的个体\n",
    "def find_duplicates(pop, similar=0.85):\n",
    "    \"\"\"\n",
    "    找到重复个体的索引。\n",
    "    :param arrays: 一个包含 array.array 的列表\n",
    "    :param threshold: 重复的判断阈值\n",
    "    :return: 重复对的索引列表\n",
    "    \"\"\"\n",
    "    n = len(pop)\n",
    "    duplicates = []  # 用于记录重复对的索引\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            # 当前两组数组\n",
    "            a = pop[i]\n",
    "            b = pop[j]\n",
    "\n",
    "            # 计算1的个数\n",
    "            ones_a = sum(a)\n",
    "            ones_b = sum(b)\n",
    "\n",
    "            # 如果其中一个数组全是0，不可能满足条件\n",
    "            if ones_a == 0 or ones_b == 0:\n",
    "                continue\n",
    "\n",
    "            # 计算交集中的1的数量\n",
    "            common_ones = sum(x & y for x, y in zip(a, b))\n",
    "\n",
    "            # 判断是否满足重复的定义\n",
    "            if (common_ones / ones_a > similar) and (common_ones / ones_b > similar):\n",
    "                duplicates.append((i, j))\n",
    "\n",
    "    return duplicates\n",
    "\n",
    "\n",
    "# 根据索引对，去除种群中重复的个体\n",
    "def remove_duplicates(pop, duplicates):\n",
    "    \"\"\"\n",
    "    移除重复的个体。\n",
    "    :param arrays: 一个包含 array.array 的列表\n",
    "    :param duplicates: 重复对的索引列表\n",
    "    :return: 去重后的列表\n",
    "    \"\"\"\n",
    "    # 找到所有需要移除的索引\n",
    "    to_remove = set(j for _, j in duplicates)  # 只保留后出现的索引\n",
    "    # 构造去重后的列表\n",
    "    return [pop[i] for i in range(len(pop)) if i not in to_remove]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:06:08.866679Z",
     "start_time": "2024-11-22T15:06:08.846018Z"
    }
   },
   "id": "42403853ade4c910",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NDGA-II"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bb11017ee1ef86"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from instance_selection.nsga_2.genetic_operator import selNSGA2, mutate_binary_inversion, selTournamentDCD\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # 忽略警告\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import array\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "\n",
    "# 最大化评价目标\n",
    "creator.create(\"FitnessMaxAndMax\", base.Fitness, weights=(1.0, 1.0))\n",
    "'''\n",
    "fitness:适应度：Gmean和mAUC\n",
    "pfc：每个分类器的成对故障信用，用于评估分类器集合的多样性\n",
    "'''\n",
    "creator.create(\"Individual\", array.array, typecode='i', fitness=creator.FitnessMaxAndMax, pfc=None, mlp=None)\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "NDIM = num_instances\n",
    "\n",
    "# 二进制编码\n",
    "toolbox.register(\"attr_binary\", random.randint, 0, 1)  # 0-1编码\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_binary, n=num_instances)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", fitness_function)\n",
    "\n",
    "# 单点交叉\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "\n",
    "# 二进制突变\n",
    "toolbox.register(\"mutate\", mutate_binary_inversion)\n",
    "\n",
    "# NSGA-II选择\n",
    "toolbox.register(\"select\", selNSGA2, x_test=X_test_scaled, y_test=y_test)\n",
    "\n",
    "# 找到种群中重复个体的索引对\n",
    "toolbox.register(\"find_duplicates\", find_duplicates)\n",
    "\n",
    "# 去重\n",
    "toolbox.register(\"remove_duplicates\", remove_duplicates)\n",
    "\n",
    "# 创建一个MLP模型\n",
    "init_mlp = MLPClassifier(hidden_layer_sizes=(15,), max_iter=500, random_state=42)\n",
    "\n",
    "\n",
    "# 绘制Pareto Front曲线\n",
    "def plot_front(fronts, gen, title):\n",
    "    \"\"\"绘制当前代非支配排序的第一等级前沿\"\"\"\n",
    "    fitnesses = [ind.fitness.values for ind in fronts]\n",
    "    plt.scatter(*zip(*fitnesses), marker='o', label=f\"Generation {gen}\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"mAUC\")\n",
    "    plt.ylabel(\"G-mean\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:06:14.806682Z",
     "start_time": "2024-11-22T15:06:14.546618Z"
    }
   },
   "id": "f286b798f84564ae",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 种群的迭代"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3af0218c1c802bf"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188, 3)\n",
      "[[0.05271551 0.29617087 0.84628544]\n",
      " [0.01061369 0.99891548 0.00919106]\n",
      " [0.03791053 0.9928169  0.0429382 ]\n",
      " [0.19088222 0.82682686 0.26024535]\n",
      " [0.01341614 0.99919173 0.00601195]\n",
      " [0.03585722 0.23952423 0.58703447]\n",
      " [0.1867263  0.02827049 0.87640188]\n",
      " [0.42764365 0.5593543  0.04913278]\n",
      " [0.34865051 0.26087583 0.21273017]\n",
      " [0.04206066 0.05768132 0.95956899]\n",
      " [0.09812546 0.11568723 0.75212157]\n",
      " [0.58201627 0.07342201 0.27101773]\n",
      " [0.21387458 0.89950003 0.02960513]\n",
      " [0.05498975 0.99031744 0.05650526]\n",
      " [0.1644235  0.54385996 0.24264794]\n",
      " [0.22118457 0.89498108 0.01991271]\n",
      " [0.58883129 0.00689009 0.34221198]\n",
      " [0.10804699 0.85598938 0.38336759]\n",
      " [0.03421675 0.11228703 0.86017647]\n",
      " [0.22006423 0.26080523 0.48981954]\n",
      " [0.50515303 0.0260775  0.42174508]\n",
      " [0.0158809  0.00723666 0.99677773]\n",
      " [0.01629037 0.01231607 0.99655694]\n",
      " [0.0072005  0.98935441 0.08110532]\n",
      " [0.15996939 0.44676415 0.4591901 ]\n",
      " [0.0234404  0.99823294 0.01753327]\n",
      " [0.38061617 0.01942039 0.6137655 ]\n",
      " [0.28723444 0.65148384 0.16230238]\n",
      " [0.00333394 0.99791314 0.02284582]\n",
      " [0.45880085 0.04807967 0.39147948]\n",
      " [0.37213489 0.26560621 0.48714021]\n",
      " [0.2450879  0.04566369 0.73533831]\n",
      " [0.30724155 0.05264158 0.65451913]\n",
      " [0.41318233 0.15866243 0.45147944]\n",
      " [0.37757716 0.01207302 0.64516855]\n",
      " [0.05954884 0.97254783 0.08820506]\n",
      " [0.0311738  0.99482372 0.02611205]\n",
      " [0.03618387 0.97231678 0.08575142]\n",
      " [0.33617149 0.73931315 0.07032529]\n",
      " [0.06559632 0.25371568 0.90143644]\n",
      " [0.30101895 0.10311168 0.41140731]\n",
      " [0.10745554 0.0097424  0.94514985]\n",
      " [0.14332157 0.93689173 0.09300341]\n",
      " [0.11681439 0.89165526 0.14166874]\n",
      " [0.13334596 0.16086036 0.90599396]\n",
      " [0.39784019 0.37505644 0.28294254]\n",
      " [0.18727519 0.17363581 0.46864523]\n",
      " [0.12531925 0.02069386 0.89673671]\n",
      " [0.50483253 0.22527035 0.12134929]\n",
      " [0.13437534 0.32875418 0.88477437]\n",
      " [0.08830386 0.86148889 0.07675648]\n",
      " [0.36790586 0.29399484 0.19448237]\n",
      " [0.31442478 0.04121868 0.62493583]\n",
      " [0.17558885 0.00601488 0.86666688]\n",
      " [0.01284618 0.99931499 0.00278246]\n",
      " [0.13497522 0.81661573 0.19015263]\n",
      " [0.2704376  0.08417297 0.52395521]\n",
      " [0.35880992 0.16089399 0.55913452]\n",
      " [0.04780603 0.9943371  0.02837608]\n",
      " [0.47875295 0.41695218 0.06225068]\n",
      " [0.39560163 0.37750187 0.35100857]\n",
      " [0.07791339 0.97787385 0.04936115]\n",
      " [0.14807633 0.26928987 0.85275031]\n",
      " [0.17937973 0.01561092 0.83273409]\n",
      " [0.1104424  0.54138604 0.52848766]\n",
      " [0.16179723 0.96386022 0.0118734 ]\n",
      " [0.40803833 0.52254166 0.08938605]\n",
      " [0.0502691  0.52714741 0.78684455]\n",
      " [0.04229257 0.77772849 0.13301836]\n",
      " [0.01933819 0.99857368 0.01340271]\n",
      " [0.02969053 0.0138828  0.99043812]\n",
      " [0.00929941 0.0026141  0.99856397]\n",
      " [0.32463287 0.63762439 0.12293463]\n",
      " [0.39219014 0.02900064 0.61158676]\n",
      " [0.09708606 0.05359649 0.91096553]\n",
      " [0.02395056 0.98811644 0.0886148 ]\n",
      " [0.03444096 0.81968036 0.39964707]\n",
      " [0.0404565  0.83660505 0.52139015]\n",
      " [0.09060183 0.97386403 0.06736735]\n",
      " [0.15659617 0.03461574 0.80871001]\n",
      " [0.16751603 0.58548796 0.68018313]\n",
      " [0.16965913 0.91502646 0.07481457]\n",
      " [0.01907377 0.01065005 0.99325549]\n",
      " [0.12712751 0.8089184  0.05829369]\n",
      " [0.32706796 0.1803651  0.5375848 ]\n",
      " [0.10208636 0.30417864 0.84331043]\n",
      " [0.04323595 0.99633851 0.00668191]\n",
      " [0.27480317 0.16553147 0.65611724]\n",
      " [0.01689869 0.01882197 0.99613342]\n",
      " [0.01780215 0.99903763 0.00535687]\n",
      " [0.4990241  0.21502158 0.05046405]\n",
      " [0.35096361 0.8042566  0.02787773]\n",
      " [0.35358452 0.00653388 0.57018662]\n",
      " [0.00755938 0.93494074 0.23086906]\n",
      " [0.0746699  0.98286603 0.01478977]\n",
      " [0.16041923 0.45544919 0.81250872]\n",
      " [0.12347346 0.06767362 0.91954724]\n",
      " [0.00954572 0.00697212 0.99810412]\n",
      " [0.11295003 0.08679524 0.87468797]\n",
      " [0.03936347 0.02559805 0.97705503]\n",
      " [0.4857573  0.29794552 0.1358007 ]\n",
      " [0.23834211 0.06665186 0.72277816]\n",
      " [0.04189165 0.18474406 0.86424087]\n",
      " [0.27788728 0.02604042 0.73582157]\n",
      " [0.04850681 0.99297553 0.02811787]\n",
      " [0.17975597 0.92911035 0.04170008]\n",
      " [0.0226559  0.9926453  0.04217463]\n",
      " [0.23246995 0.38531084 0.40791171]\n",
      " [0.13655625 0.17743297 0.85353276]\n",
      " [0.13927139 0.94174821 0.03596346]\n",
      " [0.20373032 0.07282996 0.82873944]\n",
      " [0.33837848 0.60300519 0.05945546]\n",
      " [0.07235972 0.15953158 0.96362784]\n",
      " [0.3388649  0.03476821 0.59303226]\n",
      " [0.1821165  0.58660573 0.32883435]\n",
      " [0.09473054 0.76048872 0.59945997]\n",
      " [0.26994285 0.34628872 0.543776  ]\n",
      " [0.06603951 0.96342854 0.05797039]\n",
      " [0.01719102 0.9954435  0.01241571]\n",
      " [0.10710389 0.96995697 0.08689076]\n",
      " [0.11114064 0.07838261 0.85949188]\n",
      " [0.04814896 0.17722301 0.91947243]\n",
      " [0.27226006 0.72876725 0.0871685 ]\n",
      " [0.21165205 0.11797825 0.71422433]\n",
      " [0.2753209  0.12745351 0.76098876]\n",
      " [0.07424199 0.01484674 0.95175698]\n",
      " [0.15428255 0.31936997 0.83592798]\n",
      " [0.50326235 0.01458926 0.48472399]\n",
      " [0.36238122 0.31825223 0.17746385]\n",
      " [0.14829981 0.39970085 0.67740372]\n",
      " [0.08872569 0.97769577 0.03124121]\n",
      " [0.01215003 0.98947345 0.08313206]\n",
      " [0.13317177 0.58357539 0.65598941]\n",
      " [0.08762316 0.21777115 0.83443421]\n",
      " [0.53706838 0.21798564 0.22891091]\n",
      " [0.54597808 0.08521695 0.2786148 ]\n",
      " [0.04066275 0.65555572 0.33327765]\n",
      " [0.01076671 0.00761876 0.99701997]\n",
      " [0.06731565 0.58155746 0.41139691]\n",
      " [0.25540138 0.25503939 0.50245054]\n",
      " [0.62773229 0.21982406 0.08531014]\n",
      " [0.06797263 0.47126321 0.78969331]\n",
      " [0.11113332 0.03683272 0.9497183 ]\n",
      " [0.04864307 0.09064487 0.98172166]\n",
      " [0.04355843 0.34659169 0.60707183]\n",
      " [0.13069988 0.52578523 0.63790339]\n",
      " [0.26311393 0.01340235 0.82380487]\n",
      " [0.20626709 0.86556714 0.12907216]\n",
      " [0.12850225 0.55059291 0.79968154]\n",
      " [0.03942555 0.04112719 0.97078803]\n",
      " [0.03055984 0.08063676 0.98971031]\n",
      " [0.34030763 0.24974763 0.36095193]\n",
      " [0.09202994 0.1201924  0.93071311]\n",
      " [0.12880608 0.86370417 0.30097989]\n",
      " [0.40794524 0.08637406 0.32776163]\n",
      " [0.01567598 0.00443395 0.99719508]\n",
      " [0.06297644 0.16850676 0.66418096]\n",
      " [0.10155161 0.96814138 0.02924383]\n",
      " [0.09536483 0.50982098 0.52741595]\n",
      " [0.01157213 0.99252189 0.04274953]\n",
      " [0.07631757 0.97445392 0.07628726]\n",
      " [0.270799   0.42556423 0.57645042]\n",
      " [0.17751884 0.01170632 0.89141647]\n",
      " [0.15360891 0.23147166 0.69636769]\n",
      " [0.01256636 0.63680127 0.53397522]\n",
      " [0.42645539 0.68334581 0.02712596]\n",
      " [0.16540161 0.0022302  0.89782279]\n",
      " [0.34420755 0.16417957 0.4354235 ]\n",
      " [0.15625355 0.83205759 0.31307415]\n",
      " [0.35282476 0.07294207 0.58912357]\n",
      " [0.00631306 0.99889313 0.00897818]\n",
      " [0.04386735 0.01114555 0.98423983]\n",
      " [0.24539176 0.10628932 0.63870031]\n",
      " [0.11677131 0.18391418 0.76802584]\n",
      " [0.24857294 0.39210647 0.51702608]\n",
      " [0.02271637 0.91000847 0.27951522]\n",
      " [0.52323568 0.07577607 0.29929028]\n",
      " [0.02341851 0.99593854 0.01442185]\n",
      " [0.05902589 0.95453616 0.25854608]\n",
      " [0.18838838 0.16462182 0.35157426]\n",
      " [0.01799945 0.0253103  0.99485449]\n",
      " [0.58621646 0.02515827 0.2962078 ]\n",
      " [0.09521196 0.98256825 0.00821494]\n",
      " [0.11593892 0.68525586 0.61204677]\n",
      " [0.04539716 0.60950953 0.6500887 ]\n",
      " [0.10952903 0.09073394 0.94035809]\n",
      " [0.12857007 0.04110532 0.89286347]\n",
      " [0.19479136 0.3447972  0.16886741]]\n",
      "(188,)\n",
      "[2 1 1 2 1 1 2 1 1 2 2 2 1 0 1 1 2 2 2 0 2 2 2 1 1 1 2 1 1 2 1 2 2 1 2 1 1\n",
      " 1 1 2 0 2 2 1 2 0 0 2 0 2 1 1 2 2 1 1 2 1 1 0 1 1 2 2 1 1 2 2 1 1 2 2 2 2\n",
      " 2 1 1 2 1 2 2 0 2 1 2 0 1 1 2 1 1 1 2 1 1 2 2 2 2 2 1 0 2 2 1 0 1 2 2 1 2\n",
      " 1 2 2 1 2 1 1 1 1 2 2 1 2 2 2 2 2 0 2 1 1 0 2 1 1 1 2 1 1 1 2 2 2 1 2 2 1\n",
      " 2 2 2 2 2 1 2 2 0 1 0 1 1 2 2 1 1 1 2 1 2 0 1 2 2 2 0 1 1 1 2 1 2 0 1 2 2\n",
      " 2 2 1]\n",
      "两种G-mean的计算结果： 0.6213399248722369 0.6213399248722369\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 133\u001B[0m\n\u001B[0;32m    129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pop, logbook, save_ensembles\n\u001B[0;32m    132\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 133\u001B[0m     pop, stats, ensembles \u001B[38;5;241m=\u001B[39m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    135\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m##############################集成分类器的预测结果：################################\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    136\u001B[0m     vote_ensembles(ensembles)\n",
      "Cell \u001B[1;32mIn[4], line 37\u001B[0m, in \u001B[0;36mmain\u001B[1;34m(seed)\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m# 由mlp模型得到个体的适应度\u001B[39;00m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(pop)):\n\u001B[1;32m---> 37\u001B[0m     pop[i]\u001B[38;5;241m.\u001B[39mfitness\u001B[38;5;241m.\u001B[39mvalues \u001B[38;5;241m=\u001B[39m \u001B[43mtoolbox\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpop\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;66;03m#################################计算PFC并进行非支配排序#########################################\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;66;03m# 计算PFC并进行非支配排序 PFC代替拥挤距离\u001B[39;00m\n\u001B[0;32m     41\u001B[0m pop, pareto_fronts \u001B[38;5;241m=\u001B[39m toolbox\u001B[38;5;241m.\u001B[39mselect(pop, \u001B[38;5;28mlen\u001B[39m(pop))\n",
      "Cell \u001B[1;32mIn[2], line 57\u001B[0m, in \u001B[0;36mfitness_function\u001B[1;34m(individual)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m两种G-mean的计算结果：\u001B[39m\u001B[38;5;124m\"\u001B[39m, geometric_mean, g_mean)\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m######################mAUC#######################\u001B[39;00m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;66;03m# 计算 ROC AUC（ovo+macro）\u001B[39;00m\n\u001B[1;32m---> 57\u001B[0m auc_ovo_macro \u001B[38;5;241m=\u001B[39m \u001B[43mroc_auc_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex_pred_proba\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43movo\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmacro\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mround\u001B[39m(geometric_mean, \u001B[38;5;241m4\u001B[39m), \u001B[38;5;28mround\u001B[39m(auc_ovo_macro, \u001B[38;5;241m4\u001B[39m)\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    211\u001B[0m         )\n\u001B[0;32m    212\u001B[0m     ):\n\u001B[1;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    223\u001B[0m     )\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:634\u001B[0m, in \u001B[0;36mroc_auc_score\u001B[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001B[0m\n\u001B[0;32m    632\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m multi_class \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    633\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulti_class must be in (\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124movo\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124movr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 634\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_multiclass_roc_auc_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    635\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\n\u001B[0;32m    636\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    637\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    638\u001B[0m     labels \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(y_true)\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:707\u001B[0m, in \u001B[0;36m_multiclass_roc_auc_score\u001B[1;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001B[0m\n\u001B[0;32m    705\u001B[0m \u001B[38;5;66;03m# validation of the input y_score\u001B[39;00m\n\u001B[0;32m    706\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39mallclose(\u001B[38;5;241m1\u001B[39m, y_score\u001B[38;5;241m.\u001B[39msum(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)):\n\u001B[1;32m--> 707\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    708\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTarget scores need to be probabilities for multiclass \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    709\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mroc_auc, i.e. they should sum up to 1.0 over classes\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    710\u001B[0m     )\n\u001B[0;32m    712\u001B[0m \u001B[38;5;66;03m# validation for multiclass parameter specifications\u001B[39;00m\n\u001B[0;32m    713\u001B[0m average_options \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmacro\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweighted\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[1;31mValueError\u001B[0m: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes"
     ]
    }
   ],
   "source": [
    "def main(seed=None):\n",
    "    random.seed(seed)\n",
    "\n",
    "    NGEN = 30  # 迭代次数\n",
    "    POPSIZE = 40  # 种群数量\n",
    "    CXPB = 1.0  # 交叉因子/交叉率\n",
    "    MR = 0.2  # 突变因子/突变率\n",
    "    SIMILAR = 0.85\n",
    "\n",
    "    ####################################迭代过程的记录#############################\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = \"gen\", \"evals\", \"fronts\", \"duplicates\"\n",
    "    ####################################种群的初始化###########################\n",
    "    pop = toolbox.population(n=POPSIZE)\n",
    "    ####################################计算初始种群的适应度###########################\n",
    "    stop_sign = 0\n",
    "    ensembles = []  # 当前每个个体对应的mlp模型\n",
    "    save_ensembles = []  # 保存最好的集成模型\n",
    "    current_ensembles = []  # 存储当前种群对应的集成模型\n",
    "    g_means_record = []\n",
    "    #pop_x_sub = []  # 当前每个个体的实例选择的特征数据\n",
    "    #pop_y_sub = []  # 当前每个个体对应的实例选择的lable\n",
    "    duplicates = []\n",
    "    # 对于每个个体都训练得到一个mlp模型\n",
    "    for i in range(len(pop)):\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(15,), max_iter=500, random_state=42)\n",
    "        x_sub, y_sub = get_subset(pop[i])\n",
    "        mlp.fit(x_sub, y_sub)\n",
    "        ensembles.append(mlp)\n",
    "        #pop_x_sub.append(x_sub)\n",
    "        #pop_y_sub.append(y_sub)\n",
    "        pop[i].mlp = mlp\n",
    "\n",
    "    # 由mlp模型得到个体的适应度\n",
    "    for i in range(len(pop)):\n",
    "        pop[i].fitness.values = toolbox.evaluate(pop[i])\n",
    "\n",
    "    #################################计算PFC并进行非支配排序#########################################\n",
    "    # 计算PFC并进行非支配排序 PFC代替拥挤距离\n",
    "    pop, pareto_fronts = toolbox.select(pop, len(pop))\n",
    "    # 保存第一个pareto_front中的模型，进行集成\n",
    "    for ind in pareto_fronts[0]:\n",
    "        save_ensembles.append(ind.mlp)\n",
    "    g_mean = vote_ensembles(save_ensembles)\n",
    "    g_means_record.append(g_mean)\n",
    "    \n",
    "    # record = stats.compile(pop)\n",
    "    # logbook.record(gen=0, evals=len(pop), **record)\n",
    "    # print(logbook.stream)\n",
    "    ####################################种群的迭代#################################################\n",
    "    for gen in range(1, NGEN + 1):\n",
    "        # 清空当前的集成分类器\n",
    "        current_ensembles.clear()\n",
    "        # 选择\n",
    "        offspring = selTournamentDCD(pop, POPSIZE)\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "        # 交叉\n",
    "        for i in range(0, len(offspring) - 1, 2):\n",
    "            if random.random() <= CXPB:\n",
    "                offspring[i], offspring[i + 1] = toolbox.mate(offspring[i], offspring[i + 1])\n",
    "            # 突变\n",
    "            offspring[i] = toolbox.mutate(offspring[i], MR)[0]\n",
    "            offspring[i + 1] = toolbox.mutate(offspring[i + 1], MR)[0]\n",
    "            del offspring[i].fitness.values, offspring[i + 1].fitness.values\n",
    "\n",
    "        # 计算新的种群适应度 \n",
    "        ensembles.clear()\n",
    "        #pop_x_sub.clear()\n",
    "        #pop_y_sub.clear()\n",
    "        for i in range(len(offspring)):\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=(15,), max_iter=500, random_state=42)\n",
    "            x_sub, y_sub = get_subset(offspring[i])\n",
    "            mlp.fit(x_sub, y_sub)\n",
    "            ensembles.append(mlp)\n",
    "            #pop_x_sub.append(x_sub)\n",
    "            #pop_y_sub.append(y_sub)\n",
    "            offspring[i].mlp = mlp\n",
    "        for i in range(len(offspring)):\n",
    "            offspring[i].fitness.values = toolbox.evaluate(offspring[i])\n",
    "\n",
    "        # 种群的合并\n",
    "        new_pop = pop + offspring\n",
    "\n",
    "        # 找到重复个体的索引对\n",
    "        duplicates = toolbox.find_duplicates(new_pop, SIMILAR)\n",
    "        # 去除对应重复的个体\n",
    "        new_pop = toolbox.remove_duplicates(new_pop, duplicates)\n",
    "        ###########################################再次进行突变################################################\n",
    "        for ind in range(len(offspring)):\n",
    "            # 突变\n",
    "            offspring[i] = toolbox.mutate(offspring[i], MR)[0]\n",
    "            del offspring[i].fitness.values\n",
    "        # 计算新的种群适应度 \n",
    "        ensembles.clear()\n",
    "        #pop_x_sub.clear()\n",
    "        #pop_y_sub.clear()\n",
    "        for i in range(len(offspring)):\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=(15,), max_iter=500, random_state=42)\n",
    "            x_sub, y_sub = get_subset(offspring[i])\n",
    "            mlp.fit(x_sub, y_sub)\n",
    "            ensembles.append(mlp)\n",
    "            #pop_x_sub.append(x_sub)\n",
    "            #pop_y_sub.append(y_sub)\n",
    "            offspring[i].mlp = mlp\n",
    "        for i in range(len(offspring)):\n",
    "            offspring[i].fitness.values = toolbox.evaluate(offspring[i])\n",
    "\n",
    "        # 种群的合并\n",
    "        pop = new_pop + offspring\n",
    "        ###############################################得到pareto_fronts############################################\n",
    "        pop, pareto_fronts = toolbox.select(pop, POPSIZE)\n",
    "        plot_front(pareto_fronts[0], gen, title=\"Pareto Front (Current Generation)\")\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=gen, evals=len(pop), fronts=len(pareto_fronts[0]), duplicates=len(duplicates), **record)\n",
    "        print(logbook.stream)\n",
    "        # 保存第一个等级里的mlp模型进行集成\n",
    "        for ind in pareto_fronts[0]:\n",
    "            current_ensembles.append(ind.mlp)\n",
    "        g_mean = vote_ensembles(current_ensembles)\n",
    "        if g_mean > g_means_record[-1]:  # 当前的gmean与列表最后一个gmean做对比\n",
    "            save_ensembles = current_ensembles\n",
    "            g_means_record.append(g_mean)\n",
    "            stop_sign = 0\n",
    "        else:\n",
    "            stop_sign += 1\n",
    "        if stop_sign == 10:\n",
    "            break\n",
    "    return pop, logbook, save_ensembles\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pop, stats, ensembles = main()\n",
    "\n",
    "    print(\"##############################集成分类器的预测结果：################################\")\n",
    "    vote_ensembles(ensembles)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:06:21.452927Z",
     "start_time": "2024-11-22T15:06:18.790799Z"
    }
   },
   "id": "e8deac9b0ca9c40b",
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
