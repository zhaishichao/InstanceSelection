{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# E-MOSAIC\n",
    "\n",
    "引用自[E. R. Q. Fernandes, A. C. P. L. F. de Carvalho and X. Yao, \"Ensemble of Classifiers Based on Multiobjective Genetic Sampling for Imbalanced Data,\" in IEEE Transactions on Knowledge and Data Engineering, vol. 32, no. 6, pp. 1104-1115, 1 June 2020, doi: 10.1109/TKDE.2019.2898861.]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8825cc0902bf4ba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据集的预处理 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a36fc2d4930535ec"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################加载数据集#########################\n",
      "特征数据: (6435, 36)\n",
      "label: (6435,)\n",
      "每种类别的分布： [1533  703 1358  626  707 1508]\n",
      "#########################划分数据集#########################\n",
      "特征数据: (4504, 36)\n",
      "label: (4504,)\n",
      "训练集每种类别的分布： [1053  499  958  444  505 1045]\n",
      "测试集每种类别的分布： [480 204 400 182 202 463]\n",
      "#########################平衡数据集#########################\n",
      "最小数量: 444\n",
      "平衡的数据集的特征数据: (2664, 36)\n",
      "label: (2664,)\n",
      "平衡的数据集中每种类别的分布： [444 444 444 444 444 444]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from utils.dataset_utils import get_classes_indexes_counts\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 随机种子\n",
    "random_seed = 43\n",
    "print(\"#########################加载数据集#########################\")\n",
    "'''\n",
    "id = :\n",
    "12 balance_scale  \n",
    "76 nursery 8、4、12958(4266: 4320: 328: 4044)\n",
    "'''\n",
    "# 数据集\n",
    "# uci_dataset = fetch_ucirepo(id=76)\n",
    "mat_data = sio.loadmat('../../data/dataset/Satellite.mat')\n",
    "# 提取变量\n",
    "# features = uci_dataset.data.features  # 特征数据\n",
    "# targets = uci_dataset.data.targets  # 标签lable\n",
    "dataset_x = mat_data['X']\n",
    "dataset_y = mat_data['Y'][:, 0]  # mat_data['Y']得到的形状为[n,1]，通过[:,0]，得到形状[n,]\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", dataset_x.shape)\n",
    "print(\"label:\", dataset_y.shape)\n",
    "# 统计每个类别的个数\n",
    "classes, counts = get_classes_indexes_counts(dataset_y)  #np.argmax(y_onehot, axis=1)找最大值的索引，将0-1序列转化为0,1,2,3......的整数标签\n",
    "print(\"每种类别的分布：\", counts)\n",
    "print(\"#########################划分数据集#########################\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset_x, dataset_y, test_size=0.3, random_state=random_seed)\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", x_train.shape)\n",
    "print(\"label:\", y_train.shape)\n",
    "# 统计每个类别的个数 \n",
    "classes_train, counts_train = get_classes_indexes_counts(y_train)\n",
    "print(\"训练集每种类别的分布：\", counts_train)\n",
    "classes_test, counts_test = get_classes_indexes_counts(y_test)\n",
    "print(\"测试集每种类别的分布：\", counts_test)\n",
    "print(\"#########################平衡数据集#########################\")\n",
    "# 确定每个类别的分布\n",
    "num_instances = int(counts_train.min() * 1.0)  # 向下取整\n",
    "print(\"最小数量:\", num_instances)\n",
    "# 在每个类别中随机的选择该数量的实例的索引\n",
    "balanced_classes = np.array([])\n",
    "for indexes in classes_train:\n",
    "    random_selecte_indices = np.random.choice(indexes, size=num_instances, replace=False)\n",
    "    balanced_classes = np.hstack((balanced_classes, random_selecte_indices))\n",
    "balanced_classes = np.sort(balanced_classes).astype(int)\n",
    "# 得到平衡的数据集\n",
    "balanced_dataset_x = []\n",
    "balanced_dataset_y = []\n",
    "for index in balanced_classes:\n",
    "    balanced_dataset_x.append(x_train[index])\n",
    "    balanced_dataset_y.append(y_train[index])\n",
    "balanced_dataset_x = np.array(balanced_dataset_x)\n",
    "balanced_dataset_y = np.array(balanced_dataset_y).astype(int)\n",
    "\n",
    "# 显示数据集分布\n",
    "print(\"平衡的数据集的特征数据:\", balanced_dataset_x.shape)\n",
    "print(\"label:\", balanced_dataset_y.shape)\n",
    "# 统计每个类别的分布\n",
    "classes_balanced_dataset, counts_balanced_dataset = get_classes_indexes_counts(balanced_dataset_y)\n",
    "print(\"平衡的数据集中每种类别的分布：\", counts_balanced_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T13:20:07.033236Z",
     "start_time": "2024-12-10T13:20:06.401116Z"
    }
   },
   "id": "abb6e4d62d32f110",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 评价函数\n",
    "（G-mean,mAUC两个目标）"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df0310c8b3d57eb3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.stats import gmean\n",
    "from sklearn.metrics import precision_score, roc_auc_score, accuracy_score\n",
    "from scipy.stats import mode\n",
    "\n",
    "\n",
    "##########################由个体得到选择的实例子集的索引###########################\n",
    "def get_indices(individual):\n",
    "    '''\n",
    "    :param individual: individual（用实值进行编码）\n",
    "    :return: 被选择实例的索引\n",
    "    '''\n",
    "    individual = np.round(individual)  # 数据范围在0-1之间，转化成int的同时会舍去小数部分，从而将个体映射到0-1编码\n",
    "    indices = np.where(individual == 1)  # 1代表选择该实例，返回值是tuple，tuple[0]取元组中的第一个元素\n",
    "    return indices[0]\n",
    "\n",
    "\n",
    "###########################获取实例子集############################\n",
    "def get_subset(individual):\n",
    "    '''\n",
    "    :param individual: \n",
    "    :return: 实例子集\n",
    "    '''\n",
    "    indices = get_indices(individual)\n",
    "    x_sub = balanced_dataset_x[indices, :]\n",
    "    y_sub = balanced_dataset_y[indices]\n",
    "    return x_sub, y_sub\n",
    "\n",
    "\n",
    "##########################适应度函数（PPV和PFC，为主要、次要指标）#################################\n",
    "def fitness_function(individual):\n",
    "    # 使用训练数据进行预测\n",
    "    ind_pred = individual.mlp.predict(x_test)  # 计算accuracy、PPV\n",
    "    index_pred_proba = individual.mlp.predict_proba(x_test)  # 计算mAUC\n",
    "    ######################G-mean#########################\n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(y_test, ind_pred)\n",
    "\n",
    "    # 计算每类召回率（每类正确预测个数 / 该类总数）\n",
    "    recall_per_class = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "    # 计算G-Mean\n",
    "    geometric_mean = gmean(recall_per_class)\n",
    "    ######################mAUC#######################\n",
    "    # 计算 ROC AUC（ovo+macro）\n",
    "    auc_ovo_macro = roc_auc_score(y_test, index_pred_proba, multi_class=\"ovo\", average=\"macro\")\n",
    "    return round(geometric_mean, 4), round(auc_ovo_macro, 4)\n",
    "\n",
    "\n",
    "# 集成分类器的投票\n",
    "def vote_ensembles(save_ensembles, show_result=False):\n",
    "    y_pred_labels_ensembles = []\n",
    "    y_pred_prob_labels_ensembles = []\n",
    "    for ensemble in save_ensembles:\n",
    "        ind_pred = ensemble.predict(x_test)  # 计算accuracy、PPV\n",
    "        ind_proba = ensemble.predict_proba(x_test)\n",
    "        # Convert one-hot encoded test labels back to single class labels\n",
    "        y_pred_labels_ensembles.append(ind_pred)\n",
    "        y_pred_prob_labels_ensembles.append(ind_proba)\n",
    "    # 按列投票，取每列中出现次数最多的类别作为最终分类结果\n",
    "    final_pred_result = mode(y_pred_labels_ensembles, axis=0, keepdims=False).mode.flatten()\n",
    "    # 堆叠为三维数组\n",
    "    stacked_predictions_prob = np.stack(y_pred_prob_labels_ensembles, axis=0)\n",
    "    # 对第一个维度 (num_classifiers) 求平均\n",
    "    ensemble_predictions_prob = np.mean(stacked_predictions_prob, axis=0)\n",
    "    # 计算 ROC AUC（ovo+macro）\n",
    "    auc_ovo_macro = roc_auc_score(y_test, ensemble_predictions_prob, multi_class=\"ovo\", average=\"macro\")\n",
    "    cm = confusion_matrix(y_test, final_pred_result)\n",
    "    # 计算每类召回率（每类正确预测个数 / 该类总数）\n",
    "    recall_per_class = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "    # 计算G-Mean\n",
    "    geometric_mean = gmean(recall_per_class)\n",
    "    # 计算准确率\n",
    "    accuracy = accuracy_score(y_test, final_pred_result)\n",
    "    if show_result:\n",
    "        print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "        # 打印分类报告\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, final_pred_result))\n",
    "\n",
    "        # 打印混淆矩阵\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_test, final_pred_result))\n",
    "    return round(geometric_mean, 4), round(auc_ovo_macro, 4), np.array(\n",
    "        [\"{:.4f}\".format(x) for x in recall_per_class]).tolist()  # 保留4位小数\n",
    "\n",
    "\n",
    "# 在种群中找到重复的个体\n",
    "def find_duplicates(pop, similar=0.9):\n",
    "    \"\"\"\n",
    "    找到重复个体的索引。\n",
    "    :param arrays: 一个包含 array.array 的列表\n",
    "    :param threshold: 重复的判断阈值\n",
    "    :return: 重复对的索引列表\n",
    "    \"\"\"\n",
    "    n = len(pop)\n",
    "    duplicates = []  # 用于记录重复对的索引\n",
    "\n",
    "    for i in range(n):\n",
    "        duplicate = ()\n",
    "        for j in range(i + 1, n):\n",
    "            # 当前两组数组\n",
    "            a = pop[i]\n",
    "            b = pop[j]\n",
    "\n",
    "            # 计算1的个数\n",
    "            ones_a = sum(a)\n",
    "            ones_b = sum(b)\n",
    "\n",
    "            # 如果其中一个数组全是0，不可能满足条件\n",
    "            if ones_a == 0 or ones_b == 0:\n",
    "                continue\n",
    "\n",
    "            # 计算交集中的1的数量\n",
    "            common_ones = sum(x == 1 & y == 1 for x, y in zip(a, b))\n",
    "\n",
    "            # 判断是否满足重复的定义\n",
    "            if (common_ones / ones_a > similar) and (common_ones / ones_b > similar):\n",
    "                duplicate = duplicate + (j,)\n",
    "        duplicates.append(duplicate)\n",
    "    return duplicates\n",
    "\n",
    "\n",
    "# 根据索引对，去除种群中重复的个体\n",
    "def remove_duplicates(pop, duplicates):\n",
    "    \"\"\"\n",
    "    移除重复的个体。\n",
    "    :param arrays: 一个包含 array.array 的列表\n",
    "    :param duplicates: 重复对的索引列表\n",
    "    :return: 去重后的列表\n",
    "    \"\"\"\n",
    "    # 找到所有需要移除的索引\n",
    "    to_remove = set()  # 只保留后出现的索引\n",
    "    for duplicate in duplicates:\n",
    "        to_remove.update(duplicate)  # update是用来更新set集合的\n",
    "    # 构造去重后的列表\n",
    "    return [pop[i] for i in range(len(pop)) if i not in to_remove], len(to_remove)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T13:20:07.048833Z",
     "start_time": "2024-12-10T13:20:07.034186Z"
    }
   },
   "id": "42403853ade4c910",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NDGA-II"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bb11017ee1ef86"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from instance_selection.nsga_2.genetic_operator import selNSGA2, mutate_binary_inversion, selTournamentDCD\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # 忽略警告\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import array\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "\n",
    "# 最大化评价目标\n",
    "creator.create(\"FitnessMaxAndMax\", base.Fitness, weights=(1.0, 1.0))\n",
    "'''\n",
    "fitness:适应度：Gmean和mAUC\n",
    "pfc：每个分类器的成对故障信用，用于评估分类器集合的多样性\n",
    "'''\n",
    "creator.create(\"Individual\", array.array, typecode='i', fitness=creator.FitnessMaxAndMax, pfc=None, mlp=None)\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "NDIM = len(balanced_dataset_y)\n",
    "# 设置参数\n",
    "lambda_ = 1.7  # 指数分布的参数λ（lambda）在下面的函数中，该值越大越偏向于1\n",
    "threshold = 1.0  # 阈值（阈值决定了生成0或1）\n",
    "\n",
    "\n",
    "def exponential_distribution(lambda_, threshold):\n",
    "    '''\n",
    "    :param lambda_: 指数分布的参数λ（lambda）\n",
    "    :param threshold: 阈值（阈值决定了生成0或1）\n",
    "    :return: \n",
    "    '''\n",
    "    # 生成一个指数分布的随机数\n",
    "    value = random.expovariate(lambda_)\n",
    "    # 根据值与阈值的比较，生成 0 或 1\n",
    "    if value < threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# 二进制编码\n",
    "toolbox.register(\"attr_binary\", exponential_distribution, lambda_, threshold)  # 0-1编码\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_binary, n=NDIM)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", fitness_function)\n",
    "\n",
    "# 单点交叉\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "\n",
    "# 二进制突变\n",
    "toolbox.register(\"mutate\", mutate_binary_inversion)\n",
    "\n",
    "# NSGA-II选择\n",
    "toolbox.register(\"select\", selNSGA2, x_test=x_test, y_test=y_test)\n",
    "\n",
    "# 找到种群中重复个体的索引对\n",
    "toolbox.register(\"find_duplicates\", find_duplicates)\n",
    "\n",
    "# 去重\n",
    "toolbox.register(\"remove_duplicates\", remove_duplicates)\n",
    "\n",
    "# 创建一个MLP模型\n",
    "init_mlp = MLPClassifier(hidden_layer_sizes=(20,), max_iter=500, random_state=random_seed, learning_rate_init=0.1)\n",
    "\n",
    "\n",
    "# 绘制Pareto Front曲线\n",
    "def plot_front(fronts, gen, title):\n",
    "    \"\"\"绘制当前代非支配排序的第一等级前沿\"\"\"\n",
    "    fitnesses = [ind.fitness.values for ind in fronts]\n",
    "    plt.scatter(*zip(*fitnesses), marker='o', label=f\"Generation {gen}\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"G-mean\")\n",
    "    plt.ylabel(\"mAUC\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    #plt.show()\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T13:20:07.285447Z",
     "start_time": "2024-12-10T13:20:07.049335Z"
    }
   },
   "id": "f286b798f84564ae",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 种群的迭代"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3af0218c1c802bf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def main(seed=None):\n",
    "    random.seed(seed)\n",
    "\n",
    "    NGEN = 100  # 迭代次数\n",
    "    POPSIZE = 40  # 种群数量\n",
    "    CXPB = 1.0  # 交叉因子/交叉率\n",
    "    MR = 0.25  # 突变因子/突变率\n",
    "    SIMILAR = 0.9\n",
    "    learning_rate = 0.1\n",
    "    max_iter = 100\n",
    "    hidden_size = 15\n",
    "    ####################################迭代过程的记录#############################\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = \"gen\", \"fronts\", \"fronts_0_size\", \"Gmean\", \"Save_Gmean\", \"mAUC\", \"Save_mAUC\"\n",
    "    ####################################种群的初始化###########################\n",
    "    pop = toolbox.population(n=POPSIZE)\n",
    "    ####################################计算初始种群的适应度###########################\n",
    "    stop_sign = 0\n",
    "    ensembles = []  # 当前每个个体对应的mlp模型\n",
    "    save_ensembles = []  # 保存最好的集成模型\n",
    "    current_ensembles = []  # 存储当前种群对应的集成模型\n",
    "    g_means_record = []\n",
    "    m_AUC_record = []\n",
    "    #pop_x_sub = []  # 当前每个个体的实例选择的特征数据\n",
    "    #pop_y_sub = []  # 当前每个个体对应的实例选择的lable\n",
    "    duplicates = []\n",
    "    # 对于每个个体都训练得到一个mlp模型\n",
    "    for i in range(len(pop)):\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(hidden_size,), max_iter=max_iter, random_state=random_seed,\n",
    "                            learning_rate_init=learning_rate)\n",
    "        x_sub, y_sub = get_subset(pop[i])\n",
    "        mlp.fit(x_sub, y_sub)\n",
    "        ensembles.append(mlp)\n",
    "        #pop_x_sub.append(x_sub)\n",
    "        #pop_y_sub.append(y_sub)\n",
    "        pop[i].mlp = mlp\n",
    "\n",
    "    # 由mlp模型得到个体的适应度\n",
    "    for i in range(len(pop)):\n",
    "        pop[i].fitness.values = toolbox.evaluate(pop[i])\n",
    "\n",
    "    #################################计算PFC并进行非支配排序#########################################\n",
    "    # 计算PFC并进行非支配排序 PFC代替拥挤距离\n",
    "    pop, pareto_fronts = toolbox.select(pop, len(pop))\n",
    "    # 保存第一个pareto_front中的模型，进行集成\n",
    "    for ind in pop:\n",
    "        save_ensembles.append(ind.mlp)\n",
    "    g_mean, m_auc, recall_per_class = vote_ensembles(save_ensembles)\n",
    "    g_means_record.append(g_mean)\n",
    "    m_AUC_record.append(m_auc)\n",
    "\n",
    "    # record = stats.compile(pop)\n",
    "    # logbook.record(gen=0, evals=len(pop), **record)\n",
    "    # print(logbook.stream)\n",
    "    ####################################种群的迭代#################################################\n",
    "    for gen in range(1, NGEN + 1):\n",
    "        # 清空当前的集成分类器\n",
    "        current_ensembles.clear()\n",
    "        # 选择\n",
    "        offspring = selTournamentDCD(pop, POPSIZE)\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "        # 交叉\n",
    "        for i in range(0, len(offspring) - 1, 2):\n",
    "            if random.random() <= CXPB:\n",
    "                offspring[i], offspring[i + 1] = toolbox.mate(offspring[i], offspring[i + 1])\n",
    "            # 突变\n",
    "            offspring[i] = toolbox.mutate(offspring[i], MR)[0]\n",
    "            offspring[i + 1] = toolbox.mutate(offspring[i + 1], MR)[0]\n",
    "            del offspring[i].fitness.values, offspring[i + 1].fitness.values\n",
    "\n",
    "        # 计算新的种群适应度 \n",
    "        ensembles.clear()\n",
    "        #pop_x_sub.clear()\n",
    "        #pop_y_sub.clear()\n",
    "        for i in range(len(offspring)):\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=(hidden_size,), max_iter=max_iter, random_state=random_seed,\n",
    "                                learning_rate_init=learning_rate)\n",
    "            x_sub, y_sub = get_subset(offspring[i])\n",
    "            mlp.fit(x_sub, y_sub)\n",
    "            ensembles.append(mlp)\n",
    "            #pop_x_sub.append(x_sub)\n",
    "            #pop_y_sub.append(y_sub)\n",
    "            offspring[i].mlp = mlp\n",
    "        for i in range(len(offspring)):\n",
    "            offspring[i].fitness.values = toolbox.evaluate(offspring[i])\n",
    "\n",
    "        # 种群的合并\n",
    "        new_pop = pop + offspring\n",
    "\n",
    "        # 找到重复个体的索引对\n",
    "        duplicates = toolbox.find_duplicates(new_pop, SIMILAR)\n",
    "        # 去除对应重复的个体\n",
    "        new_pop, num_duplicates = toolbox.remove_duplicates(new_pop, duplicates)\n",
    "        if len(new_pop) < POPSIZE:\n",
    "            ###########################################再次进行突变################################################\n",
    "            for ind in range(len(offspring)):\n",
    "                # 突变\n",
    "                offspring[i] = toolbox.mutate(offspring[i], MR)[0]\n",
    "                del offspring[i].fitness.values\n",
    "            # 计算新的种群适应度 \n",
    "            ensembles.clear()\n",
    "            #pop_x_sub.clear()\n",
    "            #pop_y_sub.clear()\n",
    "            for i in range(len(offspring)):\n",
    "                mlp = MLPClassifier(hidden_layer_sizes=(hidden_size,), max_iter=max_iter, random_state=random_seed,\n",
    "                                    learning_rate_init=learning_rate)\n",
    "                x_sub, y_sub = get_subset(offspring[i])\n",
    "                mlp.fit(x_sub, y_sub)\n",
    "                ensembles.append(mlp)\n",
    "                #pop_x_sub.append(x_sub)\n",
    "                #pop_y_sub.append(y_sub)\n",
    "                offspring[i].mlp = mlp\n",
    "            for i in range(len(offspring)):\n",
    "                offspring[i].fitness.values = toolbox.evaluate(offspring[i])\n",
    "        else:\n",
    "            offspring.clear()\n",
    "        # 种群的合并\n",
    "        pop = new_pop + offspring\n",
    "        ###############################################得到pareto_fronts############################################\n",
    "        pop, pareto_fronts = toolbox.select(pop, POPSIZE)\n",
    "        # print(\"下一代种群的规模：\", len(pop))\n",
    "        # plot_front(pareto_fronts[0], gen, title=\"Pareto Front (Current Generation)\")\n",
    "        record = stats.compile(pop)\n",
    "        fronts_distribution = []\n",
    "        for fronts in pareto_fronts:\n",
    "            fronts_distribution.append(len(fronts))\n",
    "\n",
    "        # 保存第一个等级里的mlp模型进行集成\n",
    "        for ind in pop:\n",
    "            current_ensembles.append(ind.mlp)\n",
    "        g_mean, m_auc, recall_per_class = vote_ensembles(current_ensembles)\n",
    "        logbook.record(gen=gen, fronts=len(fronts_distribution), fronts_0_size=len(pareto_fronts[0]),\n",
    "                       Gmean=g_mean, Save_Gmean=g_means_record[-1], mAUC=m_auc, Save_mAUC=m_AUC_record[-1], **record)\n",
    "        print(logbook.stream)\n",
    "        if g_mean > g_means_record[-1] and m_auc >= m_AUC_record[-1]:  # 当前的gmean与列表最后一个gmean做对比\n",
    "            save_ensembles = current_ensembles\n",
    "            g_means_record.append(g_mean)\n",
    "            m_AUC_record.append(m_auc)\n",
    "            stop_sign = 0\n",
    "        else:\n",
    "            stop_sign += 1\n",
    "        if stop_sign == 50:\n",
    "            break\n",
    "    return pop, logbook, save_ensembles"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T13:20:07.301467Z",
     "start_time": "2024-12-10T13:20:07.286448Z"
    }
   },
   "id": "e8deac9b0ca9c40b",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tfronts\tfronts_0_size\tGmean \tSave_Gmean\tmAUC  \tSave_mAUC\n",
      "1  \t11    \t1            \t0.8862\t0.8841    \t0.9868\t0.9867   \n",
      "2  \t10    \t1            \t0.8864\t0.8862    \t0.9869\t0.9868   \n",
      "3  \t11    \t1            \t0.8855\t0.8864    \t0.9869\t0.9869   \n",
      "4  \t10    \t1            \t0.8866\t0.8864    \t0.9869\t0.9869   \n",
      "5  \t10    \t1            \t0.8882\t0.8866    \t0.9871\t0.9869   \n",
      "6  \t11    \t1            \t0.8903\t0.8882    \t0.987 \t0.9871   \n",
      "7  \t11    \t1            \t0.891 \t0.8882    \t0.987 \t0.9871   \n",
      "8  \t11    \t1            \t0.8897\t0.8882    \t0.9871\t0.9871   \n",
      "9  \t10    \t1            \t0.889 \t0.8897    \t0.987 \t0.9871   \n",
      "10 \t10    \t2            \t0.8885\t0.8897    \t0.9873\t0.9871   \n",
      "11 \t9     \t2            \t0.8886\t0.8897    \t0.9873\t0.9871   \n",
      "12 \t8     \t3            \t0.8887\t0.8897    \t0.9875\t0.9871   \n",
      "13 \t8     \t4            \t0.889 \t0.8897    \t0.9875\t0.9871   \n",
      "14 \t8     \t3            \t0.8893\t0.8897    \t0.9876\t0.9871   \n",
      "15 \t7     \t3            \t0.889 \t0.8897    \t0.9876\t0.9871   \n",
      "16 \t8     \t3            \t0.8911\t0.8897    \t0.9876\t0.9871   \n",
      "17 \t8     \t3            \t0.892 \t0.8911    \t0.9876\t0.9876   \n",
      "18 \t8     \t3            \t0.8909\t0.892     \t0.9877\t0.9876   \n",
      "19 \t8     \t3            \t0.8922\t0.892     \t0.9878\t0.9876   \n",
      "20 \t8     \t3            \t0.8938\t0.8922    \t0.9878\t0.9878   \n",
      "21 \t7     \t3            \t0.8943\t0.8938    \t0.9878\t0.9878   \n",
      "22 \t7     \t3            \t0.8931\t0.8943    \t0.9878\t0.9878   \n",
      "23 \t7     \t3            \t0.8951\t0.8943    \t0.9878\t0.9878   \n",
      "24 \t8     \t3            \t0.894 \t0.8951    \t0.9879\t0.9878   \n",
      "25 \t7     \t3            \t0.8938\t0.8951    \t0.9878\t0.9878   \n",
      "26 \t8     \t2            \t0.8946\t0.8951    \t0.9878\t0.9878   \n",
      "27 \t8     \t2            \t0.8946\t0.8951    \t0.9878\t0.9878   \n",
      "28 \t8     \t2            \t0.8926\t0.8951    \t0.9879\t0.9878   \n",
      "29 \t7     \t2            \t0.8915\t0.8951    \t0.9878\t0.9878   \n",
      "30 \t7     \t2            \t0.8924\t0.8951    \t0.9878\t0.9878   \n",
      "31 \t7     \t2            \t0.8931\t0.8951    \t0.9878\t0.9878   \n",
      "32 \t7     \t2            \t0.8932\t0.8951    \t0.9879\t0.9878   \n",
      "33 \t7     \t2            \t0.8932\t0.8951    \t0.9879\t0.9878   \n",
      "34 \t7     \t2            \t0.8929\t0.8951    \t0.988 \t0.9878   \n",
      "35 \t7     \t2            \t0.8929\t0.8951    \t0.988 \t0.9878   \n",
      "36 \t7     \t2            \t0.8913\t0.8951    \t0.988 \t0.9878   \n",
      "37 \t7     \t2            \t0.8926\t0.8951    \t0.988 \t0.9878   \n",
      "38 \t7     \t2            \t0.8926\t0.8951    \t0.988 \t0.9878   \n",
      "39 \t7     \t2            \t0.8926\t0.8951    \t0.988 \t0.9878   \n",
      "40 \t7     \t2            \t0.893 \t0.8951    \t0.988 \t0.9878   \n",
      "41 \t7     \t2            \t0.893 \t0.8951    \t0.988 \t0.9878   \n",
      "42 \t7     \t2            \t0.893 \t0.8951    \t0.988 \t0.9878   \n",
      "43 \t7     \t2            \t0.893 \t0.8951    \t0.988 \t0.9878   \n",
      "44 \t8     \t2            \t0.8946\t0.8951    \t0.988 \t0.9878   \n",
      "45 \t8     \t2            \t0.8932\t0.8951    \t0.9881\t0.9878   \n",
      "46 \t8     \t2            \t0.8954\t0.8951    \t0.988 \t0.9878   \n",
      "47 \t8     \t2            \t0.8939\t0.8954    \t0.9882\t0.988    \n",
      "48 \t7     \t2            \t0.8935\t0.8954    \t0.988 \t0.988    \n",
      "49 \t7     \t2            \t0.8963\t0.8954    \t0.9881\t0.988    \n",
      "50 \t7     \t2            \t0.8963\t0.8963    \t0.9881\t0.9881   \n",
      "51 \t7     \t2            \t0.8959\t0.8963    \t0.9881\t0.9881   \n",
      "52 \t7     \t2            \t0.8959\t0.8963    \t0.9881\t0.9881   \n",
      "53 \t8     \t2            \t0.897 \t0.8963    \t0.9881\t0.9881   \n",
      "54 \t8     \t2            \t0.8958\t0.897     \t0.9881\t0.9881   \n",
      "55 \t7     \t2            \t0.8962\t0.897     \t0.9881\t0.9881   \n",
      "56 \t8     \t2            \t0.8971\t0.897     \t0.9881\t0.9881   \n",
      "57 \t8     \t2            \t0.8971\t0.8971    \t0.9881\t0.9881   \n",
      "58 \t7     \t2            \t0.8967\t0.8971    \t0.9881\t0.9881   \n",
      "59 \t7     \t2            \t0.8967\t0.8971    \t0.9881\t0.9881   \n",
      "60 \t7     \t2            \t0.8967\t0.8971    \t0.9881\t0.9881   \n",
      "61 \t7     \t2            \t0.8967\t0.8971    \t0.9881\t0.9881   \n",
      "62 \t7     \t2            \t0.8976\t0.8971    \t0.9881\t0.9881   \n",
      "63 \t7     \t2            \t0.8965\t0.8976    \t0.988 \t0.9881   \n",
      "64 \t7     \t2            \t0.8972\t0.8976    \t0.988 \t0.9881   \n",
      "65 \t7     \t2            \t0.8972\t0.8976    \t0.988 \t0.9881   \n",
      "66 \t7     \t2            \t0.8972\t0.8976    \t0.988 \t0.9881   \n",
      "67 \t7     \t2            \t0.8964\t0.8976    \t0.988 \t0.9881   \n",
      "68 \t7     \t2            \t0.8964\t0.8976    \t0.988 \t0.9881   \n",
      "69 \t6     \t3            \t0.8952\t0.8976    \t0.988 \t0.9881   \n",
      "70 \t6     \t3            \t0.8952\t0.8976    \t0.988 \t0.9881   \n",
      "71 \t6     \t3            \t0.8952\t0.8976    \t0.988 \t0.9881   \n",
      "72 \t6     \t3            \t0.8971\t0.8976    \t0.988 \t0.9881   \n",
      "73 \t6     \t3            \t0.897 \t0.8976    \t0.9881\t0.9881   \n",
      "74 \t6     \t4            \t0.8966\t0.8976    \t0.9881\t0.9881   \n",
      "75 \t6     \t4            \t0.8966\t0.8976    \t0.9881\t0.9881   \n",
      "76 \t6     \t4            \t0.8966\t0.8976    \t0.9881\t0.9881   \n",
      "77 \t6     \t4            \t0.8966\t0.8976    \t0.9881\t0.9881   \n",
      "78 \t6     \t4            \t0.8966\t0.8976    \t0.9881\t0.9881   \n",
      "79 \t6     \t4            \t0.8971\t0.8976    \t0.9882\t0.9881   \n",
      "80 \t6     \t4            \t0.897 \t0.8976    \t0.9882\t0.9881   \n",
      "81 \t6     \t4            \t0.897 \t0.8976    \t0.9882\t0.9881   \n",
      "82 \t6     \t4            \t0.897 \t0.8976    \t0.9882\t0.9881   \n",
      "83 \t6     \t4            \t0.8971\t0.8976    \t0.9882\t0.9881   \n",
      "84 \t6     \t4            \t0.8968\t0.8976    \t0.9882\t0.9881   \n",
      "85 \t6     \t4            \t0.8968\t0.8976    \t0.9882\t0.9881   \n",
      "86 \t6     \t4            \t0.8968\t0.8976    \t0.9882\t0.9881   \n",
      "87 \t6     \t4            \t0.8968\t0.8976    \t0.9882\t0.9881   \n",
      "88 \t6     \t4            \t0.8968\t0.8976    \t0.9882\t0.9881   \n",
      "89 \t6     \t4            \t0.8968\t0.8976    \t0.9882\t0.9881   \n",
      "90 \t6     \t4            \t0.8968\t0.8976    \t0.9882\t0.9881   \n",
      "91 \t5     \t4            \t0.8994\t0.8976    \t0.9883\t0.9881   \n",
      "92 \t5     \t4            \t0.8994\t0.8994    \t0.9883\t0.9883   \n",
      "93 \t5     \t4            \t0.8994\t0.8994    \t0.9883\t0.9883   \n",
      "94 \t5     \t4            \t0.8994\t0.8994    \t0.9883\t0.9883   \n",
      "95 \t5     \t4            \t0.8994\t0.8994    \t0.9883\t0.9883   \n",
      "96 \t5     \t4            \t0.8994\t0.8994    \t0.9883\t0.9883   \n",
      "97 \t5     \t4            \t0.8994\t0.8994    \t0.9883\t0.9883   \n",
      "98 \t5     \t4            \t0.8994\t0.8994    \t0.9883\t0.9883   \n",
      "99 \t5     \t4            \t0.8994\t0.8994    \t0.9883\t0.9883   \n",
      "100\t5     \t4            \t0.8967\t0.8994    \t0.9882\t0.9883   \n",
      "##############################集成分类器的预测结果：################################\n",
      "Accuracy: 0.90\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       480\n",
      "           1       0.98      0.99      0.98       204\n",
      "           2       0.92      0.92      0.92       400\n",
      "           3       0.62      0.79      0.70       182\n",
      "           4       0.81      0.95      0.87       202\n",
      "           5       0.94      0.79      0.86       463\n",
      "\n",
      "    accuracy                           0.90      1931\n",
      "   macro avg       0.88      0.90      0.88      1931\n",
      "weighted avg       0.91      0.90      0.90      1931\n",
      "\n",
      "Confusion Matrix:\n",
      "[[468   0   3   0   9   0]\n",
      " [  0 201   0   0   3   0]\n",
      " [  0   1 366  29   1   3]\n",
      " [  0   1  20 144   3  14]\n",
      " [  3   1   0   1 192   5]\n",
      " [  0   1  10  58  30 364]]\n",
      "最终的集成分类结果：Recall_Per_Class['0.9750', '0.9853', '0.9150', '0.7912', '0.9505', '0.7862']，Gmean：0.8967，mAUC：0.9882\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pop, stats, ensembles = main()\n",
    "    print(\"##############################集成分类器的预测结果：################################\")\n",
    "    g_mean, m_auc, recall_per_class = vote_ensembles(ensembles, show_result=True)\n",
    "    print(f\"最终的集成分类结果：Recall_Per_Class{recall_per_class}，Gmean：{g_mean}，mAUC：{m_auc}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T13:27:31.511753Z",
     "start_time": "2024-12-10T13:20:07.302971Z"
    }
   },
   "id": "25dd90ac47aaedb6",
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
