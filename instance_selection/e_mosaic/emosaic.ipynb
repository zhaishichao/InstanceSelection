{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# E-MOSAIC\n",
    "\n",
    "引用自[E. R. Q. Fernandes, A. C. P. L. F. de Carvalho and X. Yao, \"Ensemble of Classifiers Based on Multiobjective Genetic Sampling for Imbalanced Data,\" in IEEE Transactions on Knowledge and Data Engineering, vol. 32, no. 6, pp. 1104-1115, 1 June 2020, doi: 10.1109/TKDE.2019.2898861.]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8825cc0902bf4ba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据集的预处理 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a36fc2d4930535ec"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lymphography distribution: [ 4 60 81]\n",
      "trainset distribution: [ 3 40 58]\n",
      "testset distribution: [ 1 20 23]\n"
     ]
    }
   ],
   "source": [
    "from utils.dataset_utils import get_distribution\n",
    "from instance_selection.parameter.parameter import *  # 导入参数的设定\n",
    "from instance_selection.operator.init_toolbox import init_toolbox_emosaic\n",
    "from instance_selection.operator.metrics import calculate_gmean_mauc, calculate_average_gmean_mauc\n",
    "from instance_selection.operator.genetic_operator import selTournamentNDCD\n",
    "from instance_selection.operator.ensemble import vote_result_ensembles, ensemble_individuals\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "import random\n",
    "from deap import tools\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # 忽略警告\n",
    "\n",
    "DATASET = Lymphography  # 数据集名称（包含对应的参数配置）\n",
    "datasetname = DATASET.DATASETNAME.split('.')[0]\n",
    "\n",
    "# 加载、划分数据集\n",
    "mat_data = sio.loadmat(IMBALANCED_DATASET_PATH + DATASET.DATASETNAME)\n",
    "#datasetname = 'Lymph.mat'\n",
    "# mat_data = sio.loadmat('../../data/dataset/' + datasetname)\n",
    "x = mat_data['X']\n",
    "y = mat_data['Y'][:, 0]  # mat_data['Y']得到的形状为[n,1]，通过[:,0]，得到形状[n,]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=RANDOM_SEED)  # 划分数据集\n",
    "scaler = StandardScaler()  # 数据的标准化\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "unique_elements_all, classes_all, counts_all = get_distribution(y)  # 获取原始数据集分布\n",
    "unique_elements_train, classes_train, counts_train = get_distribution(y_train)  # 获取训练集分布\n",
    "unique_elements_test, classes_test, counts_test = get_distribution(y_test)  # 获取测试集分布\n",
    "print(datasetname + f' distribution: {counts_all}')\n",
    "print(f'trainset distribution: {counts_train}')\n",
    "print(f'testset distribution: {counts_test}')\n",
    "model = MLPClassifier(hidden_layer_sizes=(DATASET.HIDDEN_SIZE,), max_iter=DATASET.MAX_ITER,\n",
    "                      random_state=RANDOM_SEED, learning_rate_init=DATASET.LEARNING_RATE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-20T13:31:22.000214Z",
     "start_time": "2025-03-20T13:31:20.375282Z"
    }
   },
   "id": "abb6e4d62d32f110",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## E-MOSAIC"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a2d1ad5f2c1a2f2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************算法开始执行：******************\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_splits=5 cannot be greater than the number of members in each class.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 62\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*****************算法开始执行：******************\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 62\u001B[0m     ensemble_classifiers \u001B[38;5;241m=\u001B[39m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     63\u001B[0m     vote_pred_prob \u001B[38;5;241m=\u001B[39m vote_result_ensembles(ensemble_classifiers, x_test)  \u001B[38;5;66;03m# 默认预测结果是软标签\u001B[39;00m\n\u001B[0;32m     64\u001B[0m     gmean, mauc, recall_per_class \u001B[38;5;241m=\u001B[39m calculate_gmean_mauc(vote_pred_prob, y_test)\n",
      "Cell \u001B[1;32mIn[2], line 11\u001B[0m, in \u001B[0;36mmain\u001B[1;34m(x_train, y_train, model, balanced_method)\u001B[0m\n\u001B[0;32m      9\u001B[0m pop \u001B[38;5;241m=\u001B[39m toolbox\u001B[38;5;241m.\u001B[39mpopulation(n\u001B[38;5;241m=\u001B[39mPOPSIZE)  \u001B[38;5;66;03m# 个体编码默认全为0\u001B[39;00m\n\u001B[0;32m     10\u001B[0m pop \u001B[38;5;241m=\u001B[39m toolbox\u001B[38;5;241m.\u001B[39minit_population(pop, balanced_method\u001B[38;5;241m=\u001B[39mbalanced_method)  \u001B[38;5;66;03m# 初始化种群中的个体\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m \u001B[43mtoolbox\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpop\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 计算个体的适应度\u001B[39;00m\n\u001B[0;32m     12\u001B[0m save_ensembles \u001B[38;5;241m=\u001B[39m pop  \u001B[38;5;66;03m# 保存ensembles为初始种群\u001B[39;00m\n\u001B[0;32m     13\u001B[0m save_gmean, save_mauc \u001B[38;5;241m=\u001B[39m calculate_average_gmean_mauc(pop)\n",
      "File \u001B[1;32mD:\\Develop\\WorkSpace\\Python\\InstanceSelection\\instance_selection\\operator\\metrics.py:24\u001B[0m, in \u001B[0;36mevaluate_individuals\u001B[1;34m(individuals, model, x_train, y_train, n_splits, random_seed, fitness_function)\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m individual \u001B[38;5;129;01min\u001B[39;00m individuals:\n\u001B[0;32m     23\u001B[0m     x_sub, y_sub \u001B[38;5;241m=\u001B[39m get_subset(individual, x_train, y_train)\n\u001B[1;32m---> 24\u001B[0m     y_pred_proba \u001B[38;5;241m=\u001B[39m \u001B[43mk_fold_cross_validation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_sub\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_sub\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_splits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msoft\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_seed\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 交叉验证得到软标签\u001B[39;00m\n\u001B[0;32m     26\u001B[0m     individual\u001B[38;5;241m.\u001B[39my_sub_and_pred_proba \u001B[38;5;241m=\u001B[39m (y_sub, y_pred_proba)  \u001B[38;5;66;03m# 保存个体的软标签和预测概率\u001B[39;00m\n\u001B[0;32m     27\u001B[0m     individual\u001B[38;5;241m.\u001B[39mgmean, individual\u001B[38;5;241m.\u001B[39mmauc, _ \u001B[38;5;241m=\u001B[39m calculate_gmean_mauc(y_pred_proba, y_sub)  \u001B[38;5;66;03m# 计算个体的gmean和mauc\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Develop\\WorkSpace\\Python\\InstanceSelection\\utils\\dataset_utils.py:44\u001B[0m, in \u001B[0;36mk_fold_cross_validation\u001B[1;34m(model, X, y, n_splits, method, random_state)\u001B[0m\n\u001B[0;32m     42\u001B[0m soft_labels \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;28mlen\u001B[39m(y), \u001B[38;5;28mlen\u001B[39m(np\u001B[38;5;241m.\u001B[39munique(y))))  \u001B[38;5;66;03m# Initialize array for soft labels\u001B[39;00m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;66;03m# scores = []\u001B[39;00m\n\u001B[1;32m---> 44\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m train_index, test_index \u001B[38;5;129;01min\u001B[39;00m kf\u001B[38;5;241m.\u001B[39msplit(X, y):\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;66;03m# Split datasets into train and test\u001B[39;00m\n\u001B[0;32m     46\u001B[0m     X_train, X_test \u001B[38;5;241m=\u001B[39m X[train_index], X[test_index]\n\u001B[0;32m     47\u001B[0m     y_train, y_test \u001B[38;5;241m=\u001B[39m y[train_index], y[test_index]\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\model_selection\\_split.py:411\u001B[0m, in \u001B[0;36m_BaseKFold.split\u001B[1;34m(self, X, y, groups)\u001B[0m\n\u001B[0;32m    403\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_splits \u001B[38;5;241m>\u001B[39m n_samples:\n\u001B[0;32m    404\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    405\u001B[0m         (\n\u001B[0;32m    406\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot have number of splits n_splits=\u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m greater\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    407\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m than the number of samples: n_samples=\u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    408\u001B[0m         )\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_splits, n_samples)\n\u001B[0;32m    409\u001B[0m     )\n\u001B[1;32m--> 411\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m train, test \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39msplit(X, y, groups):\n\u001B[0;32m    412\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m train, test\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\model_selection\\_split.py:142\u001B[0m, in \u001B[0;36mBaseCrossValidator.split\u001B[1;34m(self, X, y, groups)\u001B[0m\n\u001B[0;32m    140\u001B[0m X, y, groups \u001B[38;5;241m=\u001B[39m indexable(X, y, groups)\n\u001B[0;32m    141\u001B[0m indices \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marange(_num_samples(X))\n\u001B[1;32m--> 142\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m test_index \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iter_test_masks(X, y, groups):\n\u001B[0;32m    143\u001B[0m     train_index \u001B[38;5;241m=\u001B[39m indices[np\u001B[38;5;241m.\u001B[39mlogical_not(test_index)]\n\u001B[0;32m    144\u001B[0m     test_index \u001B[38;5;241m=\u001B[39m indices[test_index]\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\model_selection\\_split.py:838\u001B[0m, in \u001B[0;36mStratifiedKFold._iter_test_masks\u001B[1;34m(self, X, y, groups)\u001B[0m\n\u001B[0;32m    837\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_iter_test_masks\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, groups\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m--> 838\u001B[0m     test_folds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_test_folds\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    839\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_splits):\n\u001B[0;32m    840\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m test_folds \u001B[38;5;241m==\u001B[39m i\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\model_selection\\_split.py:800\u001B[0m, in \u001B[0;36mStratifiedKFold._make_test_folds\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    798\u001B[0m min_groups \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmin(y_counts)\n\u001B[0;32m    799\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mall(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_splits \u001B[38;5;241m>\u001B[39m y_counts):\n\u001B[1;32m--> 800\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    801\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_splits=\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m cannot be greater than the\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    802\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m number of members in each class.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_splits)\n\u001B[0;32m    803\u001B[0m     )\n\u001B[0;32m    804\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_splits \u001B[38;5;241m>\u001B[39m min_groups:\n\u001B[0;32m    805\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    806\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe least populated class in y has only \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    807\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m members, which is less than n_splits=\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    808\u001B[0m         \u001B[38;5;241m%\u001B[39m (min_groups, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_splits),\n\u001B[0;32m    809\u001B[0m         \u001B[38;5;167;01mUserWarning\u001B[39;00m,\n\u001B[0;32m    810\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: n_splits=5 cannot be greater than the number of members in each class."
     ]
    }
   ],
   "source": [
    "toolbox = init_toolbox_emosaic(model, x_train, y_train, n_splits=N_SPLITS, random_seed=RANDOM_SEED)  # 初始化toolbox\n",
    "\n",
    "def main(x_train, y_train, model, balanced_method='balanced'):\n",
    "    not_replaced = 0\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = \"gen\", \"fronts\", \"ensembles_size\", \"avg_gmean\", \"avg_mauc\"\n",
    "    ####################################种群的初始化###########################\n",
    "    pop = toolbox.population(n=POPSIZE)  # 个体编码默认全为0\n",
    "    pop = toolbox.init_population(pop, balanced_method=balanced_method)  # 初始化种群中的个体\n",
    "    toolbox.evaluate(pop)  # 计算个体的适应度\n",
    "    save_ensembles = pop  # 保存ensembles为初始种群\n",
    "    save_gmean, save_mauc = calculate_average_gmean_mauc(pop)\n",
    "    ####################################种群的迭代#################################################\n",
    "    for gen in range(1, NGEN + 1):\n",
    "        offspring = selTournamentNDCD(pop, POPSIZE, tournsize=3)  # 锦标赛选择（1、先根据非支配排序的等级2、再根据拥挤距离）\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "        for i in range(0, len(offspring) - 1, 2):\n",
    "            if random.random() <= CXPB:\n",
    "                offspring[i], offspring[i + 1] = toolbox.mate(offspring[i], offspring[i + 1])  # 单点交叉\n",
    "            offspring[i] = toolbox.mutate(offspring[i], MR)[0]  # 二进制反转突变\n",
    "            offspring[i + 1] = toolbox.mutate(offspring[i + 1], MR)[0]  # 二进制反转突变\n",
    "            del offspring[i].fitness.values, offspring[i + 1].fitness.values\n",
    "        #############################################################合并、去重#####################################################\n",
    "        offspring = toolbox.individuals_constraints(offspring)  # 限制每个类至少有一个实例被选择\n",
    "        pop = pop + offspring  # 种群的合并\n",
    "        pop, _ = toolbox.remove_duplicates(pop)  # 去重\n",
    "        while len(pop) < POPSIZE:  # 保证种群大小为POPSIZE\n",
    "            add_individual = []\n",
    "            num_add = POPSIZE - len(pop)\n",
    "            for i in range(0, num_add):\n",
    "                index = random.randint(0, len(offspring) - 1)  # 在0-len(offspring)范围内随机产生一个索引\n",
    "                offspring[index] = toolbox.mutate(offspring[index], MR)[0]  # 选择index对应的个体进行突变\n",
    "                del offspring[index].fitness.values\n",
    "                add_individual.append(offspring[index])\n",
    "            add_individual = toolbox.individuals_constraints(add_individual)  # 限制每个类至少有一个实例被选择\n",
    "            pop = pop + add_individual  # 种群的合并\n",
    "            pop, _ = toolbox.remove_duplicates(pop)  # 去重\n",
    "        pop = toolbox.individuals_constraints(pop) # 限制每个类至少有5个实例被选择\n",
    "        toolbox.evaluate(pop)  # 计算新种群适应度\n",
    "        ###############################################得到pareto_fronts############################################\n",
    "        pop, pareto_fronts = toolbox.select(pop, POPSIZE)\n",
    "        ensembles = pop  # 集成的个体\n",
    "        curr_gmean, curr_mauc = calculate_average_gmean_mauc(ensembles)\n",
    "        if curr_gmean >= save_gmean and curr_mauc >= save_mauc:\n",
    "            save_ensembles = ensembles\n",
    "            not_replaced = 0\n",
    "        else:\n",
    "            not_replaced += 1\n",
    "        if not_replaced >= STOP_SIGN:\n",
    "            break  # 迭代结束\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=gen, fronts=len(pareto_fronts), ensembles_size=len(ensembles),\n",
    "                       avg_gmean=curr_gmean, avg_mauc=curr_mauc, **record)\n",
    "        print(logbook.stream)\n",
    "    ensemble_classifiers = ensemble_individuals(save_ensembles, model, x_train, y_train)\n",
    "    return ensemble_classifiers\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"*****************算法开始执行：******************\")\n",
    "    ensemble_classifiers = main(x_train, y_train, model=model)\n",
    "    vote_pred_prob = vote_result_ensembles(ensemble_classifiers, x_test)  # 默认预测结果是软标签\n",
    "    gmean, mauc, recall_per_class = calculate_gmean_mauc(vote_pred_prob, y_test)\n",
    "    print(f\"Reacll:{recall_per_class}，Gmean：{gmean}，mAUC：{mauc}\")\n",
    "    print(\"*****************算法执行结束！******************\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-20T13:31:22.768036Z",
     "start_time": "2025-03-20T13:31:22.017220Z"
    }
   },
   "id": "615623c1721b2411",
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
