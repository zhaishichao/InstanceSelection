{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# E-MOSAIC\n",
    "\n",
    "引用自[E. R. Q. Fernandes, A. C. P. L. F. de Carvalho and X. Yao, \"Ensemble of Classifiers Based on Multiobjective Genetic Sampling for Imbalanced Data,\" in IEEE Transactions on Knowledge and Data Engineering, vol. 32, no. 6, pp. 1104-1115, 1 June 2020, doi: 10.1109/TKDE.2019.2898861.]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8825cc0902bf4ba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据集的预处理 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a36fc2d4930535ec"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################加载数据集#########################\n",
      "特征数据: (6435, 36)\n",
      "label: (6435,)\n",
      "每种类别的分布： [1533  703 1358  626  707 1508]\n",
      "#########################划分数据集#########################\n",
      "特征数据: (4504, 36)\n",
      "label: (4504,)\n",
      "训练集每种类别的分布： [1083  517  942  425  488 1049]\n",
      "测试集每种类别的分布： [450 186 416 201 219 459]\n",
      "#########################平衡数据集#########################\n",
      "最小数量: 425\n",
      "平衡的数据集的特征数据: (2550, 36)\n",
      "label: (2550,)\n",
      "平衡的数据集中每种类别的分布： [425 425 425 425 425 425]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from utils.dataset_utils import get_classes_indexes_counts\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"#########################加载数据集#########################\")\n",
    "'''\n",
    "id = :\n",
    "12 balance_scale  \n",
    "76 nursery 8、4、12958(4266: 4320: 328: 4044)\n",
    "'''\n",
    "# 数据集\n",
    "# uci_dataset = fetch_ucirepo(id=76)\n",
    "mat_data = sio.loadmat('../../data/dataset/Satellite.mat')\n",
    "\n",
    "# 提取变量\n",
    "# features = uci_dataset.data.features  # 特征数据\n",
    "# targets = uci_dataset.data.targets  # 标签lable\n",
    "dataset_x = mat_data['X']\n",
    "dataset_y = mat_data['Y'][:, 0]  # mat_data['Y']得到的形状为[n,1]，通过[:,0]，得到形状[n,]\n",
    "\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", dataset_x.shape)\n",
    "print(\"label:\", dataset_y.shape)\n",
    "# 统计每个类别的个数，dataset_y.max()+1是类别的个数\n",
    "classes, counts = get_classes_indexes_counts(dataset_y)  #np.argmax(y_onehot, axis=1)找最大值的索引，将0-1序列转化为0,1,2,3......的整数标签\n",
    "print(\"每种类别的分布：\", counts)\n",
    "\n",
    "#############################################划分数据集##################################\n",
    "# 随机种子\n",
    "random_seed = 42\n",
    "print(\"#########################划分数据集#########################\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset_x, dataset_y, test_size=0.3, random_state=random_seed)\n",
    "\n",
    "# Standardize the feature data\n",
    "#scaler = StandardScaler()\n",
    "#X_train_scaled = scaler.fit_transform(x_train)\n",
    "#X_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", x_train.shape)\n",
    "print(\"label:\", y_train.shape)\n",
    "\n",
    "# 统计每个类别的分布 np.argmax(y_train, axis=1) Convert one-hot encoded test labels back to single class labels\n",
    "classes_train, counts_train = get_classes_indexes_counts(y_train)\n",
    "print(\"训练集每种类别的分布：\", counts_train)\n",
    "\n",
    "classes_test, counts_test = get_classes_indexes_counts(y_test)\n",
    "print(\"测试集每种类别的分布：\", counts_test)\n",
    "\n",
    "print(\"#########################平衡数据集#########################\")\n",
    "# 确定每个类别的分布\n",
    "num_instances = int(counts_train.min() * 1.0)  # 向下取整\n",
    "print(\"最小数量:\", num_instances)\n",
    "\n",
    "# 在每个类别中随机的选择该数量的实例的索引\n",
    "balanced_classes = np.array([])\n",
    "for indexes in classes_train:\n",
    "    random_selecte_indices = np.random.choice(indexes, size=num_instances, replace=False)\n",
    "    balanced_classes = np.hstack((balanced_classes, random_selecte_indices))\n",
    "balanced_classes = np.sort(balanced_classes).astype(int)\n",
    "\n",
    "# 得到平衡的数据集\n",
    "balanced_dataset_x = []\n",
    "balanced_dataset_y = []\n",
    "for index in balanced_classes:\n",
    "    balanced_dataset_x.append(x_train[index])\n",
    "    balanced_dataset_y.append(y_train[index])\n",
    "balanced_dataset_x = np.array(balanced_dataset_x)\n",
    "balanced_dataset_y = np.array(balanced_dataset_y).astype(int)\n",
    "\n",
    "# 显示数据集分布\n",
    "print(\"平衡的数据集的特征数据:\", balanced_dataset_x.shape)\n",
    "print(\"label:\", balanced_dataset_y.shape)\n",
    "\n",
    "# 统计每个类别的分布\n",
    "classes_balanced_dataset, counts_balanced_dataset = get_classes_indexes_counts(balanced_dataset_y)\n",
    "print(\"平衡的数据集中每种类别的分布：\", counts_balanced_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T16:50:30.862860Z",
     "start_time": "2024-11-26T16:50:30.208996Z"
    }
   },
   "id": "abb6e4d62d32f110",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 评价函数\n",
    "（G-mean,mAUC两个目标）"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df0310c8b3d57eb3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.stats import gmean\n",
    "from sklearn.metrics import precision_score, roc_auc_score, accuracy_score\n",
    "from scipy.stats import mode\n",
    "\n",
    "\n",
    "##########################由个体得到选择的实例子集的索引###########################\n",
    "def get_indices(individual):\n",
    "    '''\n",
    "    :param individual: individual（用实值进行编码）\n",
    "    :return: 被选择实例的索引\n",
    "    '''\n",
    "    individual = np.round(individual)  # 数据范围在0-1之间，转化成int的同时会舍去小数部分，从而将个体映射到0-1编码\n",
    "    indices = np.where(individual == 1)  # 1代表选择该实例，返回值是tuple，tuple[0]取元组中的第一个元素\n",
    "    return indices[0]\n",
    "\n",
    "\n",
    "###########################获取实例子集############################\n",
    "def get_subset(individual):\n",
    "    '''\n",
    "    :param individual: \n",
    "    :return: 实例子集\n",
    "    '''\n",
    "    indices = get_indices(individual)\n",
    "    x_sub = balanced_dataset_x[indices, :]\n",
    "    y_sub = balanced_dataset_y[indices]\n",
    "    return x_sub, y_sub\n",
    "\n",
    "\n",
    "##########################适应度函数（PPV和PFC，为主要、次要指标）#################################\n",
    "def fitness_function(individual):\n",
    "    # 使用训练数据进行预测\n",
    "    ind_pred = individual.mlp.predict(x_test)  # 计算Gmean\n",
    "    index_pred_proba = individual.mlp.predict_proba(x_test)  # 计算mAUC\n",
    "    ######################G-mean#########################\n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(y_test, ind_pred)\n",
    "    # 计算每类召回率（每类正确预测个数 / 该类总数）\n",
    "    recall_per_class = cm.diagonal() / cm.sum(axis=1)\n",
    "    # 计算G-Mean\n",
    "    geometric_mean = gmean(recall_per_class)\n",
    "    ########################mAUC#######################\n",
    "    # 计算 ROC-mAUC（ovo+macro）\n",
    "    auc_ovo_macro = roc_auc_score(y_test, index_pred_proba, multi_class=\"ovo\",\n",
    "                                  average=\"macro\")  # index_pred_proba的概率之和应为1\n",
    "    return round(geometric_mean, 4), round(auc_ovo_macro, 4)\n",
    "\n",
    "\n",
    "# 集成分类器的投票\n",
    "def vote_ensembles(save_ensembles, show=False):\n",
    "    y_pred_ensembles = []\n",
    "    for ensemble in save_ensembles:\n",
    "        ind_pred = ensemble.predict(x_test)  # 计算G-mean\n",
    "        y_pred_ensembles.append(ind_pred)\n",
    "    # 按列投票，取每列中出现次数最多的类别作为最终分类结果\n",
    "    final_pred_result = mode(y_pred_ensembles, axis=0, keepdims=False).mode.flatten()\n",
    "    cm = confusion_matrix(y_test, final_pred_result)\n",
    "    # 计算每类召回率（每类正确预测个数 / 该类总数）\n",
    "    recall_per_class = cm.diagonal() / cm.sum(axis=1)\n",
    "    # 计算Gmean\n",
    "    geometric_mean = gmean(recall_per_class)\n",
    "\n",
    "    # 计算准确率\n",
    "    #accuracy = accuracy_score(y_test, final_pred_result)\n",
    "    #print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "    # 打印分类报告\n",
    "    # print(\"Classification Report:\")\n",
    "    # print(classification_report(y_test, final_pred_result))\n",
    "\n",
    "    # 打印混淆矩阵\n",
    "    # print(\"Confusion Matrix:\")\n",
    "    # print(confusion_matrix(y_test, final_pred_result))\n",
    "    return geometric_mean\n",
    "\n",
    "\n",
    "# 在种群中找到重复的个体\n",
    "def find_duplicates(pop, similar=0.9):\n",
    "    \"\"\"\n",
    "    找到重复个体的索引。\n",
    "    :param arrays: 一个包含 array.array 的列表\n",
    "    :param threshold: 重复的判断阈值\n",
    "    :return: 重复对的索引列表\n",
    "    \"\"\"\n",
    "    n = len(pop)\n",
    "    duplicates = []  # 用于记录重复对的索引\n",
    "    for i in range(n):\n",
    "        duplicate = ()\n",
    "        for j in range(i + 1, n):\n",
    "            # 当前两组数组\n",
    "            a = pop[i]\n",
    "            b = pop[j]\n",
    "            # 计算1的个数\n",
    "            ones_a = sum(a)\n",
    "            ones_b = sum(b)\n",
    "            # 如果其中一个数组全是0，不可能满足条件\n",
    "            if ones_a == 0 or ones_b == 0:\n",
    "                continue\n",
    "            # 计算交集中的1的数量\n",
    "            common_ones = sum(x == 1 & y == 1 for x, y in zip(a, b))\n",
    "            # 判断是否满足重复的定义\n",
    "            if (common_ones / ones_a > similar) and (common_ones / ones_b > similar):\n",
    "                duplicate = duplicate + (j,)\n",
    "        duplicates.append(duplicate)\n",
    "    return duplicates\n",
    "\n",
    "\n",
    "# 根据索引对，去除种群中重复的个体\n",
    "def remove_duplicates(pop, duplicates):\n",
    "    \"\"\"\n",
    "    移除重复的个体。\n",
    "    :param arrays: 一个包含 array.array 的列表\n",
    "    :param duplicates: 重复对的索引列表\n",
    "    :return: 去重后的列表\n",
    "    \"\"\"\n",
    "    # 找到所有需要移除的索引\n",
    "    to_remove = set()  # 只保留后出现的索引\n",
    "    for duplicate in duplicates:\n",
    "        to_remove.update(duplicate)  # update是用来更新set集合的\n",
    "    # 构造去重后的列表\n",
    "    return [pop[i] for i in range(len(pop)) if i not in to_remove], len(to_remove)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T16:50:30.878420Z",
     "start_time": "2024-11-26T16:50:30.863922Z"
    }
   },
   "id": "42403853ade4c910",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NDGA-II"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bb11017ee1ef86"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from instance_selection.nsga_2.genetic_operator import selNSGA2, mutate_binary_inversion, selTournamentDCD\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import array\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from deap import base, creator, tools\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # 忽略警告\n",
    "# 最大化评价目标\n",
    "creator.create(\"FitnessMaxAndMax\", base.Fitness, weights=(1.0, 1.0))\n",
    "'''\n",
    "fitness:适应度：Gmean和mAUC\n",
    "pfc：每个分类器的成对故障信用，用于评估分类器集合的多样性\n",
    "'''\n",
    "creator.create(\"Individual\", array.array, typecode='i', fitness=creator.FitnessMaxAndMax, pfc=None, mlp=None)\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# 设置参数\n",
    "NDIM = num_instances\n",
    "lambda_ = 1.2  # 指数分布的参数λ（lambda）在下面的函数中，该值越大越偏向于1\n",
    "threshold = 1.0  # 阈值（阈值决定了生成0或1）\n",
    "\n",
    "\n",
    "# 指数分布\n",
    "def exponential_distribution(lambda_, threshold):\n",
    "    '''\n",
    "    :param lambda_: 指数分布的参数λ（lambda）\n",
    "    :param threshold: 阈值（阈值决定了生成0或1）\n",
    "    :return: \n",
    "    '''\n",
    "    # 生成一个指数分布的随机数\n",
    "    value = random.expovariate(lambda_)\n",
    "    # 根据值与阈值的比较，生成 0 或 1\n",
    "    if value < threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# 二进制编码\n",
    "toolbox.register(\"attr_binary\", exponential_distribution, lambda_, threshold)  # 0-1编码\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_binary, n=num_instances)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", fitness_function)\n",
    "\n",
    "# 单点交叉\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "# 二进制突变\n",
    "toolbox.register(\"mutate\", mutate_binary_inversion)\n",
    "# NSGA-II选择\n",
    "toolbox.register(\"select\", selNSGA2, x_test=x_test, y_test=y_test)\n",
    "# 找到种群中重复个体的索引对\n",
    "toolbox.register(\"find_duplicates\", find_duplicates)\n",
    "# 去重\n",
    "toolbox.register(\"remove_duplicates\", remove_duplicates)\n",
    "\n",
    "\n",
    "# 绘制Pareto Front曲线\n",
    "def plot_front(fronts, gen, title, show=False):\n",
    "    \"\"\"绘制当前代非支配排序的第一等级前沿\"\"\"\n",
    "    fitnesses = [ind.fitness.values for ind in fronts]\n",
    "    plt.scatter(*zip(*fitnesses), marker='o', label=f\"Generation {gen}\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Gmean\")\n",
    "    plt.ylabel(\"mAUC\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    if show is True:\n",
    "        plt.show()\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T16:50:31.113343Z",
     "start_time": "2024-11-26T16:50:30.879433Z"
    }
   },
   "id": "f286b798f84564ae",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 种群的迭代"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3af0218c1c802bf"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tevals\tfronts\tduplicates\tGmean\n",
      "1  \t40   \t6     \t30        \t0    \n",
      "2  \t40   \t6     \t25        \t0    \n",
      "3  \t40   \t7     \t25        \t0    \n",
      "4  \t40   \t7     \t26        \t0    \n",
      "5  \t40   \t7     \t27        \t0    \n",
      "6  \t40   \t9     \t28        \t0    \n",
      "7  \t40   \t11    \t30        \t0    \n",
      "8  \t40   \t12    \t23        \t0    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 143\u001B[0m\n\u001B[0;32m    139\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pop, logbook, save_ensembles\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 143\u001B[0m     pop, stats, ensembles \u001B[38;5;241m=\u001B[39m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    145\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m##############################集成分类器的预测结果：################################\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    146\u001B[0m     vote_ensembles(ensembles)\n",
      "Cell \u001B[1;32mIn[4], line 82\u001B[0m, in \u001B[0;36mmain\u001B[1;34m(seed)\u001B[0m\n\u001B[0;32m     80\u001B[0m     offspring[i]\u001B[38;5;241m.\u001B[39mmlp \u001B[38;5;241m=\u001B[39m mlp\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(offspring)):\n\u001B[1;32m---> 82\u001B[0m     offspring[i]\u001B[38;5;241m.\u001B[39mfitness\u001B[38;5;241m.\u001B[39mvalues \u001B[38;5;241m=\u001B[39m \u001B[43mtoolbox\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43moffspring\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;66;03m# 种群的合并\u001B[39;00m\n\u001B[0;32m     85\u001B[0m new_pop \u001B[38;5;241m=\u001B[39m pop \u001B[38;5;241m+\u001B[39m offspring\n",
      "Cell \u001B[1;32mIn[2], line 43\u001B[0m, in \u001B[0;36mfitness_function\u001B[1;34m(individual)\u001B[0m\n\u001B[0;32m     40\u001B[0m geometric_mean \u001B[38;5;241m=\u001B[39m gmean(recall_per_class)\n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m########################mAUC#######################\u001B[39;00m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# 计算 ROC-mAUC（ovo+macro）\u001B[39;00m\n\u001B[1;32m---> 43\u001B[0m auc_ovo_macro \u001B[38;5;241m=\u001B[39m \u001B[43mroc_auc_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex_pred_proba\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43movo\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     44\u001B[0m \u001B[43m                              \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmacro\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# index_pred_proba的概率之和应为1\u001B[39;00m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mround\u001B[39m(geometric_mean, \u001B[38;5;241m4\u001B[39m), \u001B[38;5;28mround\u001B[39m(auc_ovo_macro, \u001B[38;5;241m4\u001B[39m)\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    211\u001B[0m         )\n\u001B[0;32m    212\u001B[0m     ):\n\u001B[1;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    223\u001B[0m     )\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:634\u001B[0m, in \u001B[0;36mroc_auc_score\u001B[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001B[0m\n\u001B[0;32m    632\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m multi_class \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    633\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulti_class must be in (\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124movo\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124movr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 634\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_multiclass_roc_auc_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    635\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\n\u001B[0;32m    636\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    637\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    638\u001B[0m     labels \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(y_true)\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:765\u001B[0m, in \u001B[0;36m_multiclass_roc_auc_score\u001B[1;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001B[0m\n\u001B[0;32m    763\u001B[0m     y_true_encoded \u001B[38;5;241m=\u001B[39m _encode(y_true, uniques\u001B[38;5;241m=\u001B[39mclasses)\n\u001B[0;32m    764\u001B[0m     \u001B[38;5;66;03m# Hand & Till (2001) implementation (ovo)\u001B[39;00m\n\u001B[1;32m--> 765\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_average_multiclass_ovo_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    766\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_binary_roc_auc_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_true_encoded\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maverage\u001B[49m\n\u001B[0;32m    767\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    768\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    769\u001B[0m     \u001B[38;5;66;03m# ovr is same as multi-label\u001B[39;00m\n\u001B[0;32m    770\u001B[0m     y_true_multilabel \u001B[38;5;241m=\u001B[39m label_binarize(y_true, classes\u001B[38;5;241m=\u001B[39mclasses)\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_base.py:196\u001B[0m, in \u001B[0;36m_average_multiclass_ovo_score\u001B[1;34m(binary_metric, y_true, y_score, average)\u001B[0m\n\u001B[0;32m    193\u001B[0m     b_true \u001B[38;5;241m=\u001B[39m b_mask[ab_mask]\n\u001B[0;32m    195\u001B[0m     a_true_score \u001B[38;5;241m=\u001B[39m binary_metric(a_true, y_score[ab_mask, a])\n\u001B[1;32m--> 196\u001B[0m     b_true_score \u001B[38;5;241m=\u001B[39m binary_metric(b_true, \u001B[43my_score\u001B[49m\u001B[43m[\u001B[49m\u001B[43mab_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m]\u001B[49m)\n\u001B[0;32m    197\u001B[0m     pair_scores[ix] \u001B[38;5;241m=\u001B[39m (a_true_score \u001B[38;5;241m+\u001B[39m b_true_score) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39maverage(pair_scores, weights\u001B[38;5;241m=\u001B[39mprevalence)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def main(seed=None):\n",
    "    random.seed(seed)\n",
    "    NGEN = 100  # 迭代次数\n",
    "    POPSIZE = 40  # 种群数量\n",
    "    CXPB = 1.0  # 交叉因子/交叉率\n",
    "    MR = 0.2  # 突变因子/突变率\n",
    "    SIMILAR = 0.9  # 相似度\n",
    "    learning_rate = 0.1  # MLP的学习率\n",
    "    hidden_layer_sizes = (15,)\n",
    "    max_iter = 100\n",
    "    ####################################迭代过程的记录#############################\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = \"gen\", \"evals\", \"fronts\", \"duplicates\", \"Gmean\"\n",
    "    ####################################种群的初始化###########################\n",
    "    pop = toolbox.population(n=POPSIZE)\n",
    "    ####################################计算初始种群的适应度###########################\n",
    "    stop_sign = 0\n",
    "    ensembles = []  # 当前每个个体对应的mlp模型\n",
    "    save_ensembles = []  # 保存最好的集成模型\n",
    "    current_ensembles = []  # 存储当前种群对应的集成模型\n",
    "    g_means_record = []\n",
    "    #pop_x_sub = []  # 当前每个个体的实例选择的特征数据\n",
    "    #pop_y_sub = []  # 当前每个个体对应的实例选择的lable\n",
    "\n",
    "    # 对于每个个体都训练得到一个mlp模型\n",
    "    for i in range(len(pop)):\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, max_iter=max_iter, random_state=random_seed,\n",
    "                            learning_rate_init=learning_rate)\n",
    "        x_sub, y_sub = get_subset(pop[i])\n",
    "        mlp.fit(x_sub, y_sub)\n",
    "        ensembles.append(mlp)\n",
    "        #pop_x_sub.append(x_sub)\n",
    "        #pop_y_sub.append(y_sub)\n",
    "        pop[i].mlp = mlp\n",
    "\n",
    "    # 由mlp模型得到个体的适应度\n",
    "    for i in range(len(pop)):\n",
    "        pop[i].fitness.values = toolbox.evaluate(pop[i])\n",
    "    #################################计算PFC并进行非支配排序#########################################\n",
    "    # 计算PFC并进行非支配排序 PFC代替拥挤距离在不同的等级中进行二次排序\n",
    "    pop, pareto_fronts = toolbox.select(pop, len(pop))\n",
    "    # 保存第一个pareto_front中的模型，进行集成\n",
    "    for ind in pop:\n",
    "        save_ensembles.append(ind.mlp)\n",
    "    g_mean = vote_ensembles(save_ensembles)\n",
    "    g_means_record.append(g_mean)\n",
    "    # record = stats.compile(pop)\n",
    "    # logbook.record(gen=0, evals=len(pop), **record)\n",
    "    # print(logbook.stream)\n",
    "\n",
    "    ####################################种群的迭代#################################################\n",
    "    for gen in range(1, NGEN + 1):\n",
    "        # 清空当前的集成分类器\n",
    "        current_ensembles.clear()\n",
    "        # 选择\n",
    "        offspring = selTournamentDCD(pop, POPSIZE)\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring] #clone函数不会复制这些个体的fitness值\n",
    "        # 交叉\n",
    "        for i in range(0, len(offspring) - 1, 2):\n",
    "            if random.random() <= CXPB:\n",
    "                offspring[i], offspring[i + 1] = toolbox.mate(offspring[i], offspring[i + 1])\n",
    "            # 突变\n",
    "            offspring[i] = toolbox.mutate(offspring[i], MR)[0]\n",
    "            offspring[i + 1] = toolbox.mutate(offspring[i + 1], MR)[0]\n",
    "            del offspring[i].fitness.values, offspring[i + 1].fitness.values\n",
    "\n",
    "        # 计算新的种群适应度 \n",
    "        ensembles.clear()\n",
    "        # pop_x_sub.clear()\n",
    "        # pop_y_sub.clear()\n",
    "        for i in range(len(offspring)):\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, max_iter=max_iter, random_state=random_seed,\n",
    "                                learning_rate_init=learning_rate)\n",
    "            x_sub, y_sub = get_subset(offspring[i])\n",
    "            mlp.fit(x_sub, y_sub)\n",
    "            ensembles.append(mlp)\n",
    "            #pop_x_sub.append(x_sub)\n",
    "            #pop_y_sub.append(y_sub)\n",
    "            offspring[i].mlp = mlp\n",
    "        for i in range(len(offspring)):\n",
    "            offspring[i].fitness.values = toolbox.evaluate(offspring[i])\n",
    "\n",
    "        # 种群的合并\n",
    "        new_pop = pop + offspring\n",
    "\n",
    "        # 找到重复个体的索引对\n",
    "        duplicates = toolbox.find_duplicates(new_pop, SIMILAR)\n",
    "        # 去除对应重复的个体\n",
    "        new_pop, num_duplicates = toolbox.remove_duplicates(new_pop, duplicates)\n",
    "        if len(new_pop) < POPSIZE:\n",
    "            ###########################################再次对子代进行突变################################################\n",
    "            for ind in range(len(offspring)):\n",
    "                # 突变\n",
    "                offspring[i] = toolbox.mutate(offspring[i], MR)[0]\n",
    "                del offspring[i].fitness.values\n",
    "            # 计算新的种群适应度 \n",
    "            ensembles.clear()\n",
    "            # pop_x_sub.clear()\n",
    "            # pop_y_sub.clear()\n",
    "            for i in range(len(offspring)):\n",
    "                mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, max_iter=max_iter, random_state=random_seed,\n",
    "                                    learning_rate_init=learning_rate)\n",
    "                x_sub, y_sub = get_subset(offspring[i])\n",
    "                mlp.fit(x_sub, y_sub)\n",
    "                ensembles.append(mlp)\n",
    "                # pop_x_sub.append(x_sub)\n",
    "                # pop_y_sub.append(y_sub)\n",
    "                offspring[i].mlp = mlp\n",
    "            for i in range(len(offspring)):\n",
    "                offspring[i].fitness.values = toolbox.evaluate(offspring[i])\n",
    "        else:\n",
    "            offspring.clear()\n",
    "        # 种群的合并\n",
    "        pop = new_pop + offspring\n",
    "        ###############################################得到pareto_fronts############################################\n",
    "        pop, pareto_fronts = toolbox.select(pop, POPSIZE)\n",
    "        # print(\"下一代种群的规模：\", len(pop))\n",
    "        plot_front(pareto_fronts[0], gen, title=\"Pareto Front (Current Generation)\")\n",
    "        record = stats.compile(pop)\n",
    "        fronts_distribution = []\n",
    "        for fronts in pareto_fronts:\n",
    "            fronts_distribution.append(len(fronts))\n",
    "        logbook.record(gen=gen, evals=len(pop), fronts=len(fronts_distribution), duplicates=num_duplicates,\n",
    "                       Gmean=g_means_record[-1], **record)\n",
    "        print(logbook.stream)\n",
    "        # 保存第一个等级里的mlp模型进行集成\n",
    "        for ind in pop:\n",
    "            current_ensembles.append(ind.mlp)\n",
    "        g_mean = vote_ensembles(current_ensembles)\n",
    "        if g_mean > g_means_record[-1]:  # 当前的gmean与列表最后一个gmean做对比\n",
    "            save_ensembles = current_ensembles\n",
    "            g_means_record.append(g_mean)\n",
    "            stop_sign = 0\n",
    "        else:\n",
    "            stop_sign += 1\n",
    "        if stop_sign == 20:\n",
    "            break\n",
    "    return pop, logbook, save_ensembles\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pop, stats, ensembles = main()\n",
    "\n",
    "    print(\"##############################集成分类器的预测结果：################################\")\n",
    "    vote_ensembles(ensembles)\n",
    "    print(len(ensembles))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-26T16:50:44.075412Z",
     "start_time": "2024-11-26T16:50:31.114753Z"
    }
   },
   "id": "e8deac9b0ca9c40b",
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
