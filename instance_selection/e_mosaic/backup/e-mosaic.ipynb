{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# E-MOSAIC\n",
    "\n",
    "引用自[E. R. Q. Fernandes, A. C. P. L. F. de Carvalho and X. Yao, \"Ensemble of Classifiers Based on Multiobjective Genetic Sampling for Imbalanced Data,\" in IEEE Transactions on Knowledge and Data Engineering, vol. 32, no. 6, pp. 1104-1115, 1 June 2020, doi: 10.1109/TKDE.2019.2898861.]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8825cc0902bf4ba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据集的预处理 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a36fc2d4930535ec"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from utils.dataset_utils import get_classes_indexes_counts\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"#########################加载数据集#########################\")\n",
    "'''\n",
    "id = :\n",
    "12 balance_scale  \n",
    "76 nursery 8、4、12958(4266: 4320: 328: 4044)\n",
    "'''\n",
    "# 数据集\n",
    "# uci_dataset = fetch_ucirepo(id=76)\n",
    "mat_data = sio.loadmat('../../data/dataset/Nursery.mat')\n",
    "\n",
    "# 提取变量\n",
    "# features = uci_dataset.data.features  # 特征数据\n",
    "# targets = uci_dataset.data.targets  # 标签lable\n",
    "\n",
    "\n",
    "dataset_x = mat_data['X']\n",
    "dataset_y = mat_data['Y'][:, 0]  # mat_data['Y']得到的形状为[n,1]，通过[:,0]，得到形状[n,]\n",
    "\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", dataset_x.shape)\n",
    "print(\"label:\", dataset_y.shape)\n",
    "# 统计每个类别的个数，dataset_y.max()+1是类别的个数\n",
    "classes, counts = get_classes_indexes_counts(dataset_y)  #np.argmax(y_onehot, axis=1)找最大值的索引，将0-1序列转化为0,1,2,3......的整数标签\n",
    "print(\"每种类别的数量：\", counts)\n",
    "\n",
    "#############################################划分数据集##################################\n",
    "print(\"#########################划分数据集#########################\")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset_x, dataset_y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the feature data\n",
    "#scaler = StandardScaler()\n",
    "#X_train_scaled = scaler.fit_transform(x_train)\n",
    "#X_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", x_train.shape)\n",
    "print(\"label:\", y_train.shape)\n",
    "\n",
    "# 统计每个类别的个数 np.argmax(y_train, axis=1) Convert one-hot encoded test labels back to single class labels\n",
    "classes_train, counts_train = get_classes_indexes_counts(y_train)\n",
    "print(\"训练集每种类别的数量：\", counts_train)\n",
    "\n",
    "classes_test, counts_test = get_classes_indexes_counts(y_test)\n",
    "print(\"测试集每种类别的数量：\", counts_test)\n",
    "\n",
    "print(\"#########################平衡数据集#########################\")\n",
    "# 确定每个类别的数量\n",
    "num_instances = int(counts_train.min() * 1.0)  # 向下取整\n",
    "print(\"最小数量:\", num_instances)\n",
    "\n",
    "# 在每个类别中随机的选择该数量的实例的索引\n",
    "balanced_classes = np.array([])\n",
    "for indexes in classes_train:\n",
    "    random_selecte_indices = np.random.choice(indexes, size=num_instances, replace=False)\n",
    "    balanced_classes = np.hstack((balanced_classes, random_selecte_indices))\n",
    "balanced_classes = np.sort(balanced_classes).astype(int)\n",
    "\n",
    "# 得到平衡的数据集\n",
    "balanced_dataset_x = []\n",
    "balanced_dataset_y = []\n",
    "for index in balanced_classes:\n",
    "    balanced_dataset_x.append(x_train[index])\n",
    "    balanced_dataset_y.append(y_train[index])\n",
    "balanced_dataset_x = np.array(balanced_dataset_x)\n",
    "balanced_dataset_y = np.array(balanced_dataset_y).astype(int)\n",
    "\n",
    "# 显示数据集分布\n",
    "print(\"平衡的数据集的特征数据:\", balanced_dataset_x.shape)\n",
    "print(\"label:\", balanced_dataset_y.shape)\n",
    "\n",
    "# 统计每个类别的个数\n",
    "classes_balanced_dataset, counts_balanced_dataset = get_classes_indexes_counts(balanced_dataset_y)\n",
    "print(\"平衡的数据集中每种类别的数量：\", counts_balanced_dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abb6e4d62d32f110",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 评价函数\n",
    "（G-mean,mAUC两个目标）"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df0310c8b3d57eb3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.stats import gmean\n",
    "from sklearn.metrics import precision_score, roc_auc_score, accuracy_score\n",
    "from scipy.stats import mode\n",
    "\n",
    "\n",
    "##########################由个体得到选择的实例子集的索引###########################\n",
    "def get_indices(individual):\n",
    "    '''\n",
    "    :param individual: individual（用实值进行编码）\n",
    "    :return: 被选择实例的索引\n",
    "    '''\n",
    "    individual = np.round(individual)  # 数据范围在0-1之间，转化成int的同时会舍去小数部分，从而将个体映射到0-1编码\n",
    "    indices = np.where(individual == 1)  # 1代表选择该实例，返回值是tuple，tuple[0]取元组中的第一个元素\n",
    "    return indices[0]\n",
    "\n",
    "\n",
    "###########################获取实例子集############################\n",
    "def get_subset(individual):\n",
    "    '''\n",
    "    :param individual: \n",
    "    :return: 实例子集\n",
    "    '''\n",
    "    indices = get_indices(individual)\n",
    "    x_sub = balanced_dataset_x[indices, :]\n",
    "    y_sub = balanced_dataset_y[indices]\n",
    "    return x_sub, y_sub\n",
    "\n",
    "\n",
    "##########################适应度函数（PPV和PFC，为主要、次要指标）#################################\n",
    "def fitness_function(individual):\n",
    "    # 使用训练数据进行预测\n",
    "    ind_pred = individual.mlp.predict(x_test)  # 计算accuracy、PPV\n",
    "    index_pred_proba = individual.mlp.predict_proba(x_test)  # 计算mAUC\n",
    "    ######################G-mean#########################\n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(y_test, ind_pred)\n",
    "\n",
    "    # 计算每类召回率（每类正确预测个数 / 该类总数）\n",
    "    recall_per_class = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "    # 计算G-Mean\n",
    "    geometric_mean = gmean(recall_per_class)\n",
    "    ######################mAUC#######################\n",
    "    # 计算 ROC AUC（ovo+macro）\n",
    "    auc_ovo_macro = roc_auc_score(y_test, index_pred_proba, multi_class=\"ovo\", average=\"macro\")\n",
    "    return round(geometric_mean, 4), round(auc_ovo_macro, 4)\n",
    "\n",
    "\n",
    "# 集成分类器的投票\n",
    "def vote_ensembles(save_ensembles):\n",
    "    y_pred_labels_ensembles = []\n",
    "    for ensemble in save_ensembles:\n",
    "        ind_pred = ensemble.predict(x_test)  # 计算accuracy、PPV\n",
    "        # Convert one-hot encoded test labels back to single class labels\n",
    "        y_pred_labels_ensembles.append(ind_pred)\n",
    "    # 按列投票，取每列中出现次数最多的类别作为最终分类结果\n",
    "    final_pred_result = mode(y_pred_labels_ensembles, axis=0, keepdims=False).mode.flatten()\n",
    "    cm = confusion_matrix(y_test, final_pred_result)\n",
    "    # 计算每类召回率（每类正确预测个数 / 该类总数）\n",
    "    recall_per_class = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "    # 计算G-Mean\n",
    "    geometric_mean = gmean(recall_per_class)\n",
    "    # 计算准确率\n",
    "    accuracy = accuracy_score(y_test, final_pred_result)\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "    # 打印分类报告\n",
    "    # print(\"Classification Report:\")\n",
    "    # print(classification_report(y_test, final_pred_result))\n",
    "\n",
    "    # 打印混淆矩阵\n",
    "    # print(\"Confusion Matrix:\")\n",
    "    # print(confusion_matrix(y_test, final_pred_result))\n",
    "    return geometric_mean\n",
    "\n",
    "\n",
    "from array import array\n",
    "\n",
    "\n",
    "# 在种群中找到重复的个体\n",
    "def find_duplicates(pop, similar=0.9):\n",
    "    \"\"\"\n",
    "    找到重复个体的索引。\n",
    "    :param arrays: 一个包含 array.array 的列表\n",
    "    :param threshold: 重复的判断阈值\n",
    "    :return: 重复对的索引列表\n",
    "    \"\"\"\n",
    "    n = len(pop)\n",
    "    duplicates = []  # 用于记录重复对的索引\n",
    "\n",
    "    for i in range(n):\n",
    "        duplicate = ()\n",
    "        for j in range(i + 1, n):\n",
    "            # 当前两组数组\n",
    "            a = pop[i]\n",
    "            b = pop[j]\n",
    "\n",
    "            # 计算1的个数\n",
    "            ones_a = sum(a)\n",
    "            ones_b = sum(b)\n",
    "\n",
    "            # 如果其中一个数组全是0，不可能满足条件\n",
    "            if ones_a == 0 or ones_b == 0:\n",
    "                continue\n",
    "\n",
    "            # 计算交集中的1的数量\n",
    "            common_ones = sum(x == 1 & y == 1 for x, y in zip(a, b))\n",
    "\n",
    "            # 判断是否满足重复的定义\n",
    "            if (common_ones / ones_a > similar) and (common_ones / ones_b > similar):\n",
    "                duplicate = duplicate + (j,)\n",
    "        duplicates.append(duplicate)\n",
    "    return duplicates\n",
    "\n",
    "\n",
    "# 根据索引对，去除种群中重复的个体\n",
    "def remove_duplicates(pop, duplicates):\n",
    "    \"\"\"\n",
    "    移除重复的个体。\n",
    "    :param arrays: 一个包含 array.array 的列表\n",
    "    :param duplicates: 重复对的索引列表\n",
    "    :return: 去重后的列表\n",
    "    \"\"\"\n",
    "    # 找到所有需要移除的索引\n",
    "    to_remove = set()  # 只保留后出现的索引\n",
    "    for duplicate in duplicates:\n",
    "        to_remove.update(duplicate)\n",
    "    # 构造去重后的列表\n",
    "    return [pop[i] for i in range(len(pop)) if i not in to_remove], len(to_remove)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42403853ade4c910",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NDGA-II"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bb11017ee1ef86"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from instance_selection.nsga_2.genetic_operator import selNSGA2, mutate_binary_inversion, selTournamentDCD\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # 忽略警告\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import array\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "# 设置参数\n",
    "lambda_ = 1.5  # 指数分布的参数λ（lambda）在下面的函数中，该值越大越偏向于1\n",
    "threshold = 1.0  # 阈值（阈值决定了生成0或1）\n",
    "def exponential_distribution(lambda_,threshold):\n",
    "    '''\n",
    "    :param lambda_: 指数分布的参数λ（lambda）\n",
    "    :param threshold: 阈值（阈值决定了生成0或1）\n",
    "    :return: \n",
    "    '''\n",
    "    # 生成一个指数分布的随机数\n",
    "    value = random.expovariate(lambda_)\n",
    "    # 根据值与阈值的比较，生成 0 或 1\n",
    "    if value < threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# 最大化评价目标\n",
    "creator.create(\"FitnessMaxAndMax\", base.Fitness, weights=(1.0, 1.0))\n",
    "'''\n",
    "fitness:适应度：Gmean和mAUC\n",
    "pfc：每个分类器的成对故障信用，用于评估分类器集合的多样性\n",
    "'''\n",
    "creator.create(\"Individual\", array.array, typecode='i', fitness=creator.FitnessMaxAndMax, pfc=None, mlp=None)\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "NDIM = num_instances\n",
    "\n",
    "# 二进制编码\n",
    "# toolbox.register(\"attr_binary\", random.randint, 0, 1)  # 0-1编码\n",
    "toolbox.register(\"attr_binary\", exponential_distribution, lambda_, threshold)  # 0-1编码\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_binary, n=num_instances)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", fitness_function)\n",
    "\n",
    "# 单点交叉\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "\n",
    "# 二进制突变\n",
    "toolbox.register(\"mutate\", mutate_binary_inversion)\n",
    "\n",
    "# NSGA-II选择\n",
    "toolbox.register(\"select\", selNSGA2, x_test=x_test, y_test=y_test)\n",
    "\n",
    "# 找到种群中重复个体的索引对\n",
    "toolbox.register(\"find_duplicates\", find_duplicates)\n",
    "\n",
    "# 去重\n",
    "toolbox.register(\"remove_duplicates\", remove_duplicates)\n",
    "\n",
    "# 创建一个MLP模型\n",
    "init_mlp = MLPClassifier(hidden_layer_sizes=(15,), max_iter=500, random_state=42)\n",
    "\n",
    "# 绘制Pareto Front曲线\n",
    "def plot_front(fronts, gen, title):\n",
    "    \"\"\"绘制当前代非支配排序的第一等级前沿\"\"\"\n",
    "    fitnesses = [ind.fitness.values for ind in fronts]\n",
    "    plt.scatter(*zip(*fitnesses), marker='o', label=f\"Generation {gen}\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"G-mean\")\n",
    "    plt.ylabel(\"mAUC\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f286b798f84564ae",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 种群的迭代"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3af0218c1c802bf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def main(seed=None):\n",
    "    random.seed(seed)\n",
    "\n",
    "    NGEN = 100  # 迭代次数\n",
    "    POPSIZE = 40  # 种群数量\n",
    "    CXPB = 1.0  # 交叉因子/交叉率\n",
    "    MR = 0.2  # 突变因子/突变率\n",
    "    SIMILAR = 0.9\n",
    "    max_iter = 100\n",
    "    ####################################迭代过程的记录#############################\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = \"gen\", \"evals\", \"fronts\", \"duplicates\", \"g-mean\"\n",
    "    ####################################种群的初始化###########################\n",
    "    pop = toolbox.population(n=POPSIZE)\n",
    "    ####################################计算初始种群的适应度###########################\n",
    "    stop_sign = 0\n",
    "    ensembles = []  # 当前每个个体对应的mlp模型\n",
    "    save_ensembles = []  # 保存最好的集成模型\n",
    "    current_ensembles = []  # 存储当前种群对应的集成模型\n",
    "    g_means_record = []\n",
    "    #pop_x_sub = []  # 当前每个个体的实例选择的特征数据\n",
    "    #pop_y_sub = []  # 当前每个个体对应的实例选择的lable\n",
    "    duplicates = []\n",
    "    # 对于每个个体都训练得到一个mlp模型\n",
    "    for i in range(len(pop)):\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(20,), max_iter=max_iter, random_state=42, learning_rate_init=0.1)\n",
    "        x_sub, y_sub = get_subset(pop[i])\n",
    "        mlp.fit(x_sub, y_sub)\n",
    "        ensembles.append(mlp)\n",
    "        #pop_x_sub.append(x_sub)\n",
    "        #pop_y_sub.append(y_sub)\n",
    "        pop[i].mlp = mlp\n",
    "\n",
    "    # 由mlp模型得到个体的适应度\n",
    "    for i in range(len(pop)):\n",
    "        pop[i].fitness.values = toolbox.evaluate(pop[i])\n",
    "\n",
    "    #################################计算PFC并进行非支配排序#########################################\n",
    "    # 计算PFC并进行非支配排序 PFC代替拥挤距离\n",
    "    pop, pareto_fronts = toolbox.select(pop, len(pop))\n",
    "    # 保存第一个pareto_front中的模型，进行集成\n",
    "    for ind in pareto_fronts[0]:\n",
    "        save_ensembles.append(ind.mlp)\n",
    "    g_mean = vote_ensembles(save_ensembles)\n",
    "    g_means_record.append(g_mean)\n",
    "\n",
    "    # record = stats.compile(pop)\n",
    "    # logbook.record(gen=0, evals=len(pop), **record)\n",
    "    # print(logbook.stream)\n",
    "    ####################################种群的迭代#################################################\n",
    "    for gen in range(1, NGEN + 1):\n",
    "        # 清空当前的集成分类器\n",
    "        current_ensembles.clear()\n",
    "        # 选择\n",
    "        offspring = selTournamentDCD(pop, POPSIZE)\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "        # 交叉\n",
    "        for i in range(0, len(offspring) - 1, 2):\n",
    "            if random.random() <= CXPB:\n",
    "                offspring[i], offspring[i + 1] = toolbox.mate(offspring[i], offspring[i + 1])\n",
    "            # 突变\n",
    "            offspring[i] = toolbox.mutate(offspring[i], MR)[0]\n",
    "            offspring[i + 1] = toolbox.mutate(offspring[i + 1], MR)[0]\n",
    "            del offspring[i].fitness.values, offspring[i + 1].fitness.values\n",
    "\n",
    "        # 计算新的种群适应度 \n",
    "        ensembles.clear()\n",
    "        #pop_x_sub.clear()\n",
    "        #pop_y_sub.clear()\n",
    "        for i in range(len(offspring)):\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=(20,), max_iter=max_iter, random_state=42, learning_rate_init=0.1)\n",
    "            x_sub, y_sub = get_subset(offspring[i])\n",
    "            mlp.fit(x_sub, y_sub)\n",
    "            ensembles.append(mlp)\n",
    "            #pop_x_sub.append(x_sub)\n",
    "            #pop_y_sub.append(y_sub)\n",
    "            offspring[i].mlp = mlp\n",
    "        for i in range(len(offspring)):\n",
    "            offspring[i].fitness.values = toolbox.evaluate(offspring[i])\n",
    "\n",
    "        # 种群的合并\n",
    "        new_pop = pop + offspring\n",
    "\n",
    "        # 找到重复个体的索引对\n",
    "        duplicates = toolbox.find_duplicates(new_pop, SIMILAR)\n",
    "        # 去除对应重复的个体\n",
    "        new_pop, num_duplicates = toolbox.remove_duplicates(new_pop, duplicates)\n",
    "        if len(new_pop) < POPSIZE:\n",
    "            ###########################################再次进行突变################################################\n",
    "            for ind in range(len(offspring)):\n",
    "                # 突变\n",
    "                offspring[i] = toolbox.mutate(offspring[i], MR)[0]\n",
    "                del offspring[i].fitness.values\n",
    "            # 计算新的种群适应度 \n",
    "            ensembles.clear()\n",
    "            #pop_x_sub.clear()\n",
    "            #pop_y_sub.clear()\n",
    "            for i in range(len(offspring)):\n",
    "                mlp = MLPClassifier(hidden_layer_sizes=(20,), max_iter=max_iter, random_state=42, learning_rate_init=0.1)\n",
    "                x_sub, y_sub = get_subset(offspring[i])\n",
    "                mlp.fit(x_sub, y_sub)\n",
    "                ensembles.append(mlp)\n",
    "                #pop_x_sub.append(x_sub)\n",
    "                #pop_y_sub.append(y_sub)\n",
    "                offspring[i].mlp = mlp\n",
    "            for i in range(len(offspring)):\n",
    "                offspring[i].fitness.values = toolbox.evaluate(offspring[i])\n",
    "        else:\n",
    "            offspring.clear()\n",
    "        # 种群的合并\n",
    "        pop = new_pop + offspring\n",
    "        ###############################################得到pareto_fronts############################################\n",
    "        pop, pareto_fronts = toolbox.select(pop, POPSIZE)\n",
    "        print(\"下一代种群的规模：\", len(pop))\n",
    "        plot_front(pareto_fronts[0], gen, title=\"Pareto Front (Current Generation)\")\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=gen, evals=len(pop), fronts=len(pareto_fronts[0]), duplicates=num_duplicates,\n",
    "                       g_mean=g_means_record[-1], **record)\n",
    "        print(logbook.stream)\n",
    "        # 保存第一个等级里的mlp模型进行集成\n",
    "        for ind in pareto_fronts[0]:\n",
    "            current_ensembles.append(ind.mlp)\n",
    "        g_mean = vote_ensembles(current_ensembles)\n",
    "        if g_mean > g_means_record[-1]:  # 当前的gmean与列表最后一个gmean做对比\n",
    "            save_ensembles = current_ensembles\n",
    "            g_means_record.append(g_mean)\n",
    "            stop_sign = 0\n",
    "        else:\n",
    "            stop_sign += 1\n",
    "        if stop_sign == 100:\n",
    "            break\n",
    "    return pop, logbook, save_ensembles\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pop, stats, ensembles = main()\n",
    "\n",
    "    print(\"##############################集成分类器的预测结果：################################\")\n",
    "    vote_ensembles(ensembles)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8deac9b0ca9c40b",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
