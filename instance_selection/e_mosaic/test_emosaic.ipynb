{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 测试"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18f9113d638eec2d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/dataset/imbalance/Letter.mat'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:39\u001B[0m, in \u001B[0;36m_open_file\u001B[1;34m(file_like, appendmat, mode)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 39\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfile_like\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;66;03m# Probably \"not found\"\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../../data/dataset/imbalance/Letter.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 23\u001B[0m\n\u001B[0;32m     20\u001B[0m datasetname \u001B[38;5;241m=\u001B[39m DATASET[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDATASETNAME\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# 加载、划分数据集\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m mat_data \u001B[38;5;241m=\u001B[39m \u001B[43msio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloadmat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mIMBALANCED_DATASET_PATH\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mDATASET\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mDATASETNAME\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m x \u001B[38;5;241m=\u001B[39m mat_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     25\u001B[0m y \u001B[38;5;241m=\u001B[39m mat_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mY\u001B[39m\u001B[38;5;124m'\u001B[39m][:, \u001B[38;5;241m0\u001B[39m]  \u001B[38;5;66;03m# mat_data['Y']得到的形状为[n,1]，通过[:,0]，得到形状[n,]\u001B[39;00m\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:225\u001B[0m, in \u001B[0;36mloadmat\u001B[1;34m(file_name, mdict, appendmat, **kwargs)\u001B[0m\n\u001B[0;32m     88\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     89\u001B[0m \u001B[38;5;124;03mLoad MATLAB file.\u001B[39;00m\n\u001B[0;32m     90\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;124;03m    3.14159265+3.14159265j])\u001B[39;00m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    224\u001B[0m variable_names \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvariable_names\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m--> 225\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _open_file_context(file_name, appendmat) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m    226\u001B[0m     MR, _ \u001B[38;5;241m=\u001B[39m mat_reader_factory(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    227\u001B[0m     matfile_dict \u001B[38;5;241m=\u001B[39m MR\u001B[38;5;241m.\u001B[39mget_variables(variable_names)\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\contextlib.py:119\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__enter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwds, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerator didn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt yield\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:17\u001B[0m, in \u001B[0;36m_open_file_context\u001B[1;34m(file_like, appendmat, mode)\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;129m@contextmanager\u001B[39m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_context\u001B[39m(file_like, appendmat, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m---> 17\u001B[0m     f, opened \u001B[38;5;241m=\u001B[39m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_like\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mappendmat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     19\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m f\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:45\u001B[0m, in \u001B[0;36m_open_file\u001B[1;34m(file_like, appendmat, mode)\u001B[0m\n\u001B[0;32m     43\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m appendmat \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m file_like\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.mat\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m     44\u001B[0m         file_like \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.mat\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfile_like\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     47\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\n\u001B[0;32m     48\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mReader needs file name or open file-like object\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     49\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../../data/dataset/imbalance/Letter.mat'"
     ]
    }
   ],
   "source": [
    "from utils.dataset_utils import get_distribution\n",
    "from instance_selection.parameter.parameter import *  # 导入参数的设定\n",
    "from instance_selection.operator.init_toolbox import init_toolbox_emosaic\n",
    "from instance_selection.operator.metrics import calculate_gmean_mauc, calculate_average_gmean_mauc\n",
    "from instance_selection.operator.genetic_operator import selTournamentNDCD\n",
    "from instance_selection.operator.ensemble import vote_result_ensembles, ensemble_individuals\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "import random\n",
    "import numpy as np\n",
    "from deap import tools\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # 忽略警告\n",
    "\n",
    "DATASET = Letter  # 数据集名称（包含对应参数的字典形式）\n",
    "\n",
    "datasetname = DATASET['DATASETNAME'].split('.')[0]\n",
    "\n",
    "# 加载、划分数据集\n",
    "mat_data = sio.loadmat(IMBALANCED_DATASET_PATH + DATASET['DATASETNAME'])\n",
    "x = mat_data['X']\n",
    "y = mat_data['Y'][:, 0]  # mat_data['Y']得到的形状为[n,1]，通过[:,0]，得到形状[n,]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=RANDOM_SEED)  # 划分数据集\n",
    "scaler = StandardScaler()  # 数据的标准化\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "unique_elements_all, classes_all, counts_all = get_distribution(y)  # 获取原始数据集分布\n",
    "unique_elements_train, classes_train, counts_train = get_distribution(y_train)  # 获取训练集分布\n",
    "unique_elements_test, classes_test, counts_test = get_distribution(y_test)  # 获取测试集分布\n",
    "print(datasetname + f' instances: {x.shape[0]}')\n",
    "print(datasetname + f' distribution: {counts_all}')\n",
    "print(f'trainset distribution: {counts_train}')\n",
    "print(f'testset distribution: {counts_test}')\n",
    "model = MLPClassifier(hidden_layer_sizes=(DATASET['HIDDEN_SIZE'],), max_iter=DATASET['MAX_ITER'],\n",
    "                      random_state=RANDOM_SEED, learning_rate_init=DATASET['LEARNING_RATE'])\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# 测试模型\n",
    "y_test_probs = model.predict_proba(x_test)\n",
    "y_test_preds = model.predict(x_test)\n",
    "\n",
    "print(calculate_gmean_mauc(y_test_probs, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T05:18:44.277417Z",
     "start_time": "2025-03-08T05:18:44.163919Z"
    }
   },
   "id": "8bc748f7d445015d",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "## E-MOSAIC"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d0853f79163e74f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "toolbox = init_toolbox_emosaic(model, x_train, y_train, n_splits=N_SPLITS, random_seed=RANDOM_SEED)  # 初始化toolbox\n",
    "\n",
    "\n",
    "def main(x_train, y_train, model, balanced_method='balanced'):\n",
    "    not_replaced = 0\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = \"gen\", \"fronts\", \"ensembles_size\", \"avg_gmean\", \"avg_mauc\"\n",
    "    ####################################种群的初始化###########################\n",
    "    pop = toolbox.population(n=POPSIZE)  # 个体编码默认全为0\n",
    "    pop = toolbox.init_population(pop, balanced_method=balanced_method)  # 初始化种群中的个体\n",
    "    toolbox.evaluate(pop)  # 计算个体的适应度\n",
    "    save_ensembles = ensemble_individuals(pop, model, x_train, y_train)  # 保存最优的集成分类器\n",
    "    save_gmean, save_mauc = calculate_average_gmean_mauc(pop)\n",
    "    ####################################种群的迭代#################################################\n",
    "    for gen in range(1, NGEN + 1):\n",
    "        offspring = selTournamentNDCD(pop, POPSIZE, tournsize=3)  # 锦标赛选择（1、先根据非支配排序的等级2、再根据拥挤距离）\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "        for i in range(0, len(offspring) - 1, 2):\n",
    "            if random.random() <= CXPB:\n",
    "                offspring[i], offspring[i + 1] = toolbox.mate(offspring[i], offspring[i + 1])  # 单点交叉\n",
    "            offspring[i] = toolbox.mutate(offspring[i], MR)[0]  # 二进制反转突变\n",
    "            offspring[i + 1] = toolbox.mutate(offspring[i + 1], MR)[0]  # 二进制反转突变\n",
    "            del offspring[i].fitness.values, offspring[i + 1].fitness.values\n",
    "        #############################################################合并、去重#####################################################\n",
    "        offspring = toolbox.individuals_constraints(offspring)  # 限制每个类至少有一个实例被选择\n",
    "        pop = pop + offspring  # 种群的合并\n",
    "        pop, _ = toolbox.remove_duplicates(pop)  # 去重\n",
    "        while len(pop) < POPSIZE:  # 保证种群大小为POPSIZE\n",
    "            add_individual = []\n",
    "            num_add = POPSIZE - len(pop)\n",
    "            for i in range(0, num_add):\n",
    "                index = random.randint(0, len(offspring) - 1)  # 在0-len(offspring)范围内随机产生一个索引\n",
    "                offspring[index] = toolbox.mutate(offspring[index], MR)[0]  # 选择index对应的个体进行突变\n",
    "                del offspring[index].fitness.values\n",
    "                add_individual.append(offspring[index])\n",
    "            add_individual = toolbox.individuals_constraints(add_individual)  # 限制每个类至少有一个实例被选择\n",
    "            pop = pop + add_individual  # 种群的合并\n",
    "            pop, _ = toolbox.remove_duplicates(pop)  # 去重\n",
    "        toolbox.evaluate(pop)  # 计算新种群适应度\n",
    "        ###############################################得到pareto_fronts############################################\n",
    "        pop, pareto_fronts = toolbox.select(pop, POPSIZE)\n",
    "        ensembles = pop  # 集成的个体\n",
    "        curr_gmean, curr_mauc = calculate_average_gmean_mauc(ensembles)  # 计算的是所有个体的metrics平均值\n",
    "        if curr_gmean >= save_gmean and curr_mauc >= save_mauc:\n",
    "            save_ensembles = ensembles\n",
    "            not_replaced = 0\n",
    "        else:\n",
    "            not_replaced += 1\n",
    "        if not_replaced >= STOP_SIGN:\n",
    "            break  # 迭代结束\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=gen, fronts=len(pareto_fronts), ensembles_size=len(ensembles),\n",
    "                       avg_gmean=curr_gmean, avg_mauc=curr_mauc, **record)\n",
    "        # print(logbook.stream)\n",
    "    ensemble_classifiers = ensemble_individuals(save_ensembles, model, x_train, y_train)\n",
    "    return ensemble_classifiers\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"*****************算法开始执行：******************\")\n",
    "    num_run = 30  # 运行次数\n",
    "    ensembles_results = [[] for _ in range(num_run)]\n",
    "    for i in range(num_run):\n",
    "        ensemble_classifiers = main(x_train, y_train, model=model)\n",
    "        vote_pred_prob = vote_result_ensembles(ensemble_classifiers, x_test)  # 默认预测结果是软标签\n",
    "        gmean, mauc, recall_per_class = calculate_gmean_mauc(vote_pred_prob, y_test)\n",
    "        ensembles_results[i] = [gmean, mauc]\n",
    "        print(f\"第{i + 1}次执行：Gmean：{gmean}，mAUC：{mauc}\")\n",
    "    print(\"*****************算法执行结束！******************\")\n",
    "    ensembles_result_mean = np.mean(ensembles_results, axis=0)\n",
    "    print(f'集成分类结果（平均值）：{ensembles_result_mean}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0643f2768950227",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 绘制变化取钱"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb01ab584c260a1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Example data\n",
    "data1 = np.round(np.array(ensembles_results).T, 4)\n",
    "\n",
    "datasets = [data1]\n",
    "colors1 = plt.cm.viridis(np.linspace(0, 1, len(data1)))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot Dataset 1\n",
    "for i, (curve, color) in enumerate(zip(data1, colors1)):\n",
    "    x = np.arange(1, len(curve) + 1)\n",
    "    y = curve\n",
    "    avg = np.mean(y)\n",
    "    plt.plot(x, y, label=f'Random - Curve {i + 1} (Avg: {avg:.4f})', color=color)\n",
    "    for xi, yi in zip(x, y):\n",
    "        plt.text(xi, yi, f'{yi}', fontsize=9, ha='center', va='bottom', color=color)\n",
    "\n",
    "# Plot settings\n",
    "plt.title('Curves from Two 2D Numpy Arrays with Point Values and Averages', fontsize=14)\n",
    "plt.xlabel('Number of iterations', fontsize=12)\n",
    "plt.ylabel('Value', fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(alpha=0.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path = 'C:\\\\Users\\\\zsc\\\\Desktop\\\\evolution computation\\\\meeting\\\\2025.1.8\\\\e-mosaic\\\\' + datasetname + '\\\\'\n",
    "# 创建文件夹（如果不存在）\n",
    "folder = os.path.dirname(save_path)\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "# Show plot\n",
    "plt.savefig(save_path + datasetname + f'ensemble_gmean_mauc.jpg', dpi=300, bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89745a06a8326acf",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
