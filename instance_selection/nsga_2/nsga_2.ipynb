{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 数据集构建"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f6e0ae9de365691"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征数据: (67557, 42)\n",
      "label: (67557,)\n",
      "每种类别的数量： [ 6449 16635 44473]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from utils.dataset_utils import get_classes_indexes_counts\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "import numpy as np\n",
    "\n",
    "################################################################加载数据集################################################\n",
    "# 数据集\n",
    "mat_data = sio.loadmat('../../data/dataset/Connect4.mat')\n",
    "# 提取变量\n",
    "dataset_x = mat_data['X']\n",
    "dataset_y = mat_data['Y'][:, 0]  # mat_data['Y']得到的形状为[n,1]，通过[:,0]，得到形状[n,]\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", dataset_x.shape)\n",
    "print(\"label:\", dataset_y.shape)\n",
    "# 统计每个类别的个数，dataset_y.max()+1是类别的个数\n",
    "classes, counts = get_classes_indexes_counts(dataset_y)\n",
    "print(\"每种类别的数量：\", counts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T07:27:00.297854Z",
     "start_time": "2024-11-12T07:27:00.273913Z"
    }
   },
   "id": "4bbfb8b04ee2220",
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  划分数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b163bfd820e476e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征数据: (47289, 42)\n",
      "label: (47289,)\n",
      "每种类别的数量： [ 4498 11595 31196]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dataset_x, dataset_y, test_size=0.3, random_state=42)\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", x_train.shape)\n",
    "print(\"label:\", y_train.shape)\n",
    "# 统计每个类别的个数\n",
    "classes_train, counts_train = get_classes_indexes_counts(y_train)\n",
    "print(\"每种类别的数量：\", counts_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T07:27:03.279646Z",
     "start_time": "2024-11-12T07:27:03.262735Z"
    }
   },
   "id": "b15c4bd533249491",
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 训练集的构建\n",
    "1.首先找出类别数量最小的类\n",
    "2.取最小类别数量的90%，作为平衡数据集的各类别原始数量\n",
    "3.在每个类别中随机抽取实例构成初始数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8811199107bb05a9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最小数量: 4048\n",
      "平衡的数据集的特征数据: (12144, 42)\n",
      "label: (12144,)\n",
      "平衡的数据集中每种类别的数量： [4048 4048 4048]\n"
     ]
    }
   ],
   "source": [
    "# 确定每个类别的数量\n",
    "num_instances = int(counts_train.min() * 0.9)  # 向下取整\n",
    "print(\"最小数量:\", num_instances)\n",
    "\n",
    "# 在每个类别中随机的选择该数量的实例的索引\n",
    "balanced_classes = np.array([])\n",
    "for indexes in classes_train:\n",
    "    random_selecte_indices = np.random.choice(indexes, size=num_instances, replace=False)\n",
    "    balanced_classes = np.hstack((balanced_classes, random_selecte_indices))\n",
    "balanced_classes = np.sort(balanced_classes).astype(int)\n",
    "\n",
    "# 得到平衡的数据集\n",
    "balanced_dataset_x = []\n",
    "balanced_dataset_y = np.array([])\n",
    "for index in balanced_classes:\n",
    "    balanced_dataset_x.append(x_train[index])\n",
    "    balanced_dataset_y = np.hstack((balanced_dataset_y, y_train[index]))\n",
    "balanced_dataset_x = np.array(balanced_dataset_x)\n",
    "balanced_dataset_y = np.array(balanced_dataset_y).astype(int)\n",
    "\n",
    "# 显示数据集分布\n",
    "print(\"平衡的数据集的特征数据:\", balanced_dataset_x.shape)\n",
    "print(\"label:\", balanced_dataset_y.shape)\n",
    "\n",
    "# 统计每个类别的个数\n",
    "classes_balanced_dataset, counts_balanced_dataset = get_classes_indexes_counts(balanced_dataset_y)\n",
    "print(\"平衡的数据集中每种类别的数量：\", counts_balanced_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T07:27:05.476004Z",
     "start_time": "2024-11-12T07:27:05.412158Z"
    }
   },
   "id": "746a165e373967a6",
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 单独训练"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cddedb62759138ca"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 952  470  529 1293 3099  648 2765 2004 8508]\n",
      "准确率: 0.6196467337675153\n",
      "\n",
      "分类报告:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.49      0.27      1951\n",
      "           1       0.56      0.61      0.58      5040\n",
      "           2       0.88      0.64      0.74     13277\n",
      "\n",
      "    accuracy                           0.62     20268\n",
      "   macro avg       0.54      0.58      0.53     20268\n",
      "weighted avg       0.73      0.62      0.66     20268\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "x_train_single = scaler.fit_transform(balanced_dataset_x)\n",
    "x_test_single = scaler.transform(x_test)\n",
    "# 构建并训练MLP模型\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(15,), max_iter=500, random_state=42)\n",
    "mlp.fit(x_train_single, balanced_dataset_y)\n",
    "\n",
    "# 预测和评估模型\n",
    "y_pred = mlp.predict(x_test_single)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred).ravel())\n",
    "\n",
    "# 输出结果\n",
    "print(\"准确率:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n分类报告:\\n\", classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T07:27:19.402239Z",
     "start_time": "2024-11-12T07:27:15.097106Z"
    }
   },
   "id": "523273a215749ed",
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 算法的实现"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "855b2a2d0d65a780"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "\n",
    "\n",
    "##########################由个体得到选择的实例子集的索引###########################\n",
    "def get_indices(individual):\n",
    "    '''\n",
    "    :param individual: individual（用实值进行编码）\n",
    "    :return: 被选择实例的索引\n",
    "    '''\n",
    "    individual = np.round(individual)  # 数据范围在0-1之间，转化成int的同时会舍去小数部分，从而将个体映射到0-1编码\n",
    "    indices = np.where(individual == 1)  # 1代表选择该实例，返回值是tuple，tuple[0]取元组中的第一个元素\n",
    "    return indices[0]\n",
    "\n",
    "\n",
    "###########################获取实例子集############################\n",
    "def get_subset(individual):\n",
    "    '''\n",
    "    :param individual: \n",
    "    :return: 实例子集\n",
    "    '''\n",
    "    indices = get_indices(individual)\n",
    "    x_sub = balanced_dataset_x[indices, :]\n",
    "    y_sub = balanced_dataset_y[indices]\n",
    "    return x_sub, y_sub\n",
    "\n",
    "\n",
    "##########################适应度函数（PPV和PFC，为主要、次要指标）#################################\n",
    "def fitness_function(x_sub, y_sub, ensembles, index):\n",
    "    ######################PPV#######################\n",
    "    # 使用训练数据进行预测\n",
    "    index_pred = ensembles[index].predict(x_sub)\n",
    "    # 计算混淆矩阵 average=\"micro\"也即PPV，每个类别的tp/(tp+fp)\n",
    "    ppv = precision_score(y_sub, index_pred, average=\"micro\")\n",
    "\n",
    "    ######################PFC#######################\n",
    "    f2 = 0.0\n",
    "    for i in range(len(ensembles)):\n",
    "        if i != index:\n",
    "            # 计算两个数组中索引对应的元素值不相等的个数\n",
    "            i_pred = ensembles[i].predict(x_sub)\n",
    "            # 每个类别的错误数可以通过 np.sum(conf_matrix, axis=1) - np.diag(conf_matrix) 得到，这个操作计算了每一行的总和减去对角线的正确预测数，即为错误分类数。\n",
    "            # 计算混淆矩阵\n",
    "            conf_matrix = confusion_matrix(y_sub, i_pred)\n",
    "            # 计算每个类别的分类错误数\n",
    "            classification_errors = np.sum(conf_matrix, axis=1) - np.diag(conf_matrix)\n",
    "            classification_errors_counts = np.sum(classification_errors)\n",
    "            if classification_errors_counts == 0:\n",
    "                classification_errors_counts = 1\n",
    "            count = sum(1 for a, b in zip(index_pred, i_pred) if a != b)\n",
    "            f2 = f2 + count / classification_errors_counts\n",
    "    pfc = f2 / (len(ensembles) - 1)\n",
    "    return round(ppv, 4), round(pfc, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T07:27:25.638188Z",
     "start_time": "2024-11-12T07:27:25.625926Z"
    }
   },
   "id": "1b2fbc6f174a89bf",
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 多目标评价"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c21d5f2e37b5c51"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'FitnessMinAndMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "D:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tevals\tmin            \tmax        \n",
      "0  \t30   \t[0.5019 0.    ]\t[0.58 0.  ]\n",
      "1  \t30   \t[0.4949 0.    ]\t[0.58 0.  ]\n",
      "2  \t30   \t[0.5125 0.    ]\t[0.58 0.  ]\n",
      "3  \t30   \t[0.5292 0.    ]\t[0.5861 0.    ]\n",
      "4  \t30   \t[0.5552 0.    ]\t[0.5861 0.    ]\n",
      "5  \t30   \t[0.58 0.  ]    \t[0.5861 0.    ]\n",
      "6  \t30   \t[0.5451 0.    ]\t[0.5861 0.    ]\n",
      "7  \t30   \t[0.539 0.   ]  \t[0.5861 0.    ]\n",
      "8  \t30   \t[0.5204 0.    ]\t[0.5861 0.    ]\n",
      "9  \t30   \t[0.566 0.   ]  \t[0.5861 0.    ]\n"
     ]
    }
   ],
   "source": [
    "import array\n",
    "import random\n",
    "import numpy\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "\n",
    "creator.create(\"FitnessMinAndMax\", base.Fitness, weights=(1.0, 1.0))\n",
    "creator.create(\"Individual\", array.array, typecode='d', fitness=creator.FitnessMinAndMax)\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Problem definition\n",
    "\n",
    "BOUND_LOW, BOUND_UP = 0.0, 1.0\n",
    "\n",
    "NDIM = num_instances\n",
    "\n",
    "\n",
    "def uniform(low, up, size=None):\n",
    "    \n",
    "    return [random.uniform(low, up) for i in range(size)]\n",
    "\n",
    "\n",
    "toolbox.register(\"attr_float\", uniform, BOUND_LOW, BOUND_UP, NDIM)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.attr_float)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# toolbox.register(\"evaluate\", benchmarks.zdt1)\n",
    "toolbox.register(\"evaluate\", fitness_function)\n",
    "# toolbox.register(\"mate\", tools.cxSimulatedBinaryBounded, low=BOUND_LOW, up=BOUND_UP, eta=20.0)\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "toolbox.register(\"mutate\", tools.mutPolynomialBounded, low=BOUND_LOW, up=BOUND_UP, eta=20.0, indpb=1.0 / NDIM)\n",
    "# toolbox.register(\"select\", tools.selNSGA2)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "init_mlp = MLPClassifier(hidden_layer_sizes=(20,), max_iter=800, random_state=42)\n",
    "\n",
    "\n",
    "def main(seed=None):\n",
    "    random.seed(seed)\n",
    "\n",
    "    NGEN = 10\n",
    "    MU = 30\n",
    "    CXPB = 0.9\n",
    "\n",
    "    ####################################迭代过程的记录###########################\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    # stats.register(\"avg\", numpy.mean, axis=0)\n",
    "    # stats.register(\"std\", numpy.std, axis=0)\n",
    "    stats.register(\"min\", numpy.min, axis=0)\n",
    "    stats.register(\"max\", numpy.max, axis=0)\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = \"gen\", \"evals\", \"min\", \"max\"\n",
    "\n",
    "    ####################################种群的初始化###########################\n",
    "    pop = toolbox.population(n=MU)\n",
    "    \n",
    "    ####################################计算初始种群的适应度###########################\n",
    "    ensembles = []  # 当前每个个体对应的mlp模型\n",
    "    save_ensembles = []  # 存储每个个体对应的mlp模型\n",
    "    pop_x_sub = []  # 当前每个个体的实例选择的特征数据\n",
    "    pop_y_sub = []  # 当前每个个体对应的实例选择的lable\n",
    "    # 对于每个个体都训练得到一个mlp模型\n",
    "    for i in range(len(pop)):\n",
    "        mlp = init_mlp\n",
    "        x_sub, y_sub = get_subset(pop[i])\n",
    "        mlp.fit(x_sub, y_sub)\n",
    "        ensembles.append(mlp)\n",
    "        pop_x_sub.append(x_sub)\n",
    "        pop_y_sub.append(y_sub)\n",
    "    save_ensembles = ensembles  # 保存初始种群对应的mlp集合\n",
    "    # 由mlp模型得到个体的适应度\n",
    "    for i in range(len(pop)):\n",
    "        pop[i].fitness.values = toolbox.evaluate(pop_x_sub[i], pop_y_sub[i], ensembles, i)\n",
    "    record = stats.compile(pop)\n",
    "    logbook.record(gen=0, evals=len(pop), **record)\n",
    "    print(logbook.stream)\n",
    "    ####################################种群的迭代###########################\n",
    "    for gen in range(1, NGEN):\n",
    "        # 选择\n",
    "        offspring = toolbox.select(pop, len(pop))\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "\n",
    "        # 交叉\n",
    "        for i in range(0, len(offspring) - 1, 2):\n",
    "            if random.random() <= CXPB:\n",
    "                offspring[i], offspring[i + 1] = toolbox.mate(offspring[i], offspring[i + 1])\n",
    "            # 突变\n",
    "            offspring[i] = toolbox.mutate(offspring[i])[0]\n",
    "            offspring[i + 1] = toolbox.mutate(offspring[i + 1])[0]\n",
    "            del offspring[i].fitness.values, offspring[i + 1].fitness.values\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        # fitnesses = toolbox.map(toolbox.evaluate, offspring)\n",
    "        # for ind, fit in zip(offspring, fitnesses):\n",
    "        #     ind.fitness.values = fit\n",
    "        # 计算新的种群适应度 \n",
    "        ensembles.clear()\n",
    "        pop_x_sub.clear()\n",
    "        pop_y_sub.clear()\n",
    "        for i in range(len(offspring)):\n",
    "            mlp = init_mlp\n",
    "            x_sub, y_sub = get_subset(offspring[i])\n",
    "            mlp.fit(x_sub, y_sub)\n",
    "            ensembles.append(mlp)\n",
    "            pop_x_sub.append(x_sub)\n",
    "            pop_y_sub.append(y_sub)\n",
    "        for i in range(len(offspring)):\n",
    "            offspring[i].fitness.values = toolbox.evaluate(pop_x_sub[i], pop_y_sub[i], ensembles, i)\n",
    "\n",
    "        # Select the next generation population\n",
    "        pop = toolbox.select(pop + offspring, MU)\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=gen, evals=len(pop), **record)\n",
    "        print(logbook.stream)\n",
    "\n",
    "    return pop, logbook\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pop, stats = main()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-12T07:37:18.404533Z",
     "start_time": "2024-11-12T07:33:00.565857Z"
    }
   },
   "id": "b68e95c1a5b9442a",
   "execution_count": 64
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
