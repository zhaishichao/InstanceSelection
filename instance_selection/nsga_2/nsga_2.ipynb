{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 数据集构建"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f6e0ae9de365691"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征数据: (67557, 42)\n",
      "label: (67557,)\n",
      "每种类别的数量： [ 6449 16635 44473]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.dataset_utils import get_classes_indexes_counts\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "import numpy as np\n",
    "\n",
    "################################################################加载数据集################################################\n",
    "# 数据集\n",
    "mat_data = sio.loadmat('../../data/dataset/Connect4.mat')\n",
    "# 提取变量\n",
    "dataset_x = mat_data['X']\n",
    "dataset_y = mat_data['Y'][:, 0]  # mat_data['Y']得到的形状为[n,1]，通过[:,0]，得到形状[n,]\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", dataset_x.shape)\n",
    "print(\"label:\", dataset_y.shape)\n",
    "\n",
    "# One-hot encode target variable 强制将类别转换为0，1，2，3......\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_onehot = encoder.fit_transform(dataset_y.reshape(-1, 1))\n",
    "\n",
    "# 统计每个类别的个数，dataset_y.max()+1是类别的个数\n",
    "classes, counts = get_classes_indexes_counts(dataset_y)\n",
    "print(\"每种类别的数量：\", counts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T12:15:47.100833Z",
     "start_time": "2024-11-19T12:15:46.545685Z"
    }
   },
   "id": "4bbfb8b04ee2220",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  划分数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b163bfd820e476e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征数据: (47289, 42)\n",
      "label: (47289, 3)\n",
      "训练集每种类别的数量： [ 4498 11595 31196]\n",
      "测试集每种类别的数量： [ 1951  5040 13277]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset_x, y_onehot, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the feature data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(x_train)\n",
    "X_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", x_train.shape)\n",
    "print(\"label:\", y_train.shape)\n",
    "\n",
    "# 统计每个类别的个数 np.argmax(y_train, axis=1) Convert one-hot encoded test labels back to single class labels\n",
    "classes_train, counts_train = get_classes_indexes_counts(np.argmax(y_train, axis=1))\n",
    "print(\"训练集每种类别的数量：\", counts_train)\n",
    "\n",
    "classes_test, counts_test = get_classes_indexes_counts(np.argmax(y_test, axis=1))\n",
    "print(\"测试集每种类别的数量：\", counts_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T12:15:48.351982Z",
     "start_time": "2024-11-19T12:15:48.293892Z"
    }
   },
   "id": "b15c4bd533249491",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 训练集的构建\n",
    "1.首先找出类别数量最小的类\n",
    "2.取最小类别数量的90%，作为平衡数据集的各类别原始数量\n",
    "3.在每个类别中随机抽取实例构成初始数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8811199107bb05a9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最小数量: 4048\n",
      "平衡的数据集的特征数据: (12144, 42)\n",
      "label: (12144, 3)\n",
      "平衡的数据集中每种类别的数量： [4048 4048 4048]\n"
     ]
    }
   ],
   "source": [
    "# 确定每个类别的数量\n",
    "num_instances = int(counts_train.min() * 0.9)  # 向下取整\n",
    "print(\"最小数量:\", num_instances)\n",
    "\n",
    "# 在每个类别中随机的选择该数量的实例的索引\n",
    "balanced_classes = np.array([])\n",
    "for indexes in classes_train:\n",
    "    random_selecte_indices = np.random.choice(indexes, size=num_instances, replace=False)\n",
    "    balanced_classes = np.hstack((balanced_classes, random_selecte_indices))\n",
    "balanced_classes = np.sort(balanced_classes).astype(int)\n",
    "\n",
    "# 得到平衡的数据集\n",
    "balanced_dataset_x = []\n",
    "balanced_dataset_y = []\n",
    "for index in balanced_classes:\n",
    "    balanced_dataset_x.append(x_train[index])\n",
    "    balanced_dataset_y.append(y_train[index, :])\n",
    "balanced_dataset_x = np.array(balanced_dataset_x)\n",
    "balanced_dataset_y = np.array(balanced_dataset_y).astype(int)\n",
    "\n",
    "# 显示数据集分布\n",
    "print(\"平衡的数据集的特征数据:\", balanced_dataset_x.shape)\n",
    "print(\"label:\", balanced_dataset_y.shape)\n",
    "\n",
    "# 统计每个类别的个数\n",
    "classes_balanced_dataset, counts_balanced_dataset = get_classes_indexes_counts(np.argmax(balanced_dataset_y, axis=1))\n",
    "print(\"平衡的数据集中每种类别的数量：\", counts_balanced_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T12:15:49.914383Z",
     "start_time": "2024-11-19T12:15:49.886953Z"
    }
   },
   "id": "746a165e373967a6",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 多目标评价"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "855b2a2d0d65a780"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.stats import gmean\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix, precision_score, roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "##########################由个体得到选择的实例子集的索引###########################\n",
    "def get_indices(individual):\n",
    "    '''\n",
    "    :param individual: individual（用实值进行编码）\n",
    "    :return: 被选择实例的索引\n",
    "    '''\n",
    "    individual = np.round(individual)  # 数据范围在0-1之间，转化成int的同时会舍去小数部分，从而将个体映射到0-1编码\n",
    "    indices = np.where(individual == 1)  # 1代表选择该实例，返回值是tuple，tuple[0]取元组中的第一个元素\n",
    "    return indices[0]\n",
    "\n",
    "\n",
    "###########################获取实例子集############################\n",
    "def get_subset(individual):\n",
    "    '''\n",
    "    :param individual: \n",
    "    :return: 实例子集\n",
    "    '''\n",
    "    indices = get_indices(individual)\n",
    "    x_sub = balanced_dataset_x[indices, :]\n",
    "    y_sub = balanced_dataset_y[indices, :]\n",
    "    return x_sub, y_sub\n",
    "\n",
    "\n",
    "##########################适应度函数（PPV和PFC，为主要、次要指标）#################################\n",
    "def fitness_function(individual):\n",
    "    ######################PPV#######################\n",
    "    # 使用训练数据进行预测\n",
    "    index_pred = individual.mlp.predict(x_test)  # 计算accuracy、PPV\n",
    "    index_pred_proba = individual.mlp.predict_proba(x_test)  # 计算mAUC\n",
    "\n",
    "    # Convert one-hot encoded test labels back to single class labels\n",
    "    y_test_labels = np.argmax(y_test, axis=1)\n",
    "    y_pred_labels = np.argmax(index_pred, axis=1)\n",
    "    _, counts = get_classes_indexes_counts(y_test_labels)\n",
    "    #print(\"类型数量\",len(counts))\n",
    "    # 计算每个类别的 Precision\n",
    "    class_precisions = precision_score(y_test_labels, y_pred_labels, average=None)\n",
    "    #print(\"每个类别的PPV：\", class_precisions)\n",
    "    geometric_mean = gmean(class_precisions)\n",
    "    ######################PFC#######################\n",
    "    # 7. 计算 ROC AUC（ovo+macro）\n",
    "    auc_ovo_macro = roc_auc_score(y_test, index_pred_proba, multi_class=\"ovo\", average=\"macro\")\n",
    "    return round(geometric_mean, 4), round(auc_ovo_macro, 4)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T12:18:24.613657Z",
     "start_time": "2024-11-19T12:18:24.594267Z"
    }
   },
   "id": "1b2fbc6f174a89bf",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NSGA-II"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c21d5f2e37b5c51"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tevals\tmin            \tmax            \n",
      "0  \t40   \t[0.3111 0.612 ]\t[0.3497 0.6569]\n",
      "1  \t40   \t[0.335  0.6235]\t[0.3605 0.6774]\n",
      "2  \t40   \t[0.3354 0.6357]\t[0.3605 0.6774]\n",
      "3  \t40   \t[0.3396 0.6357]\t[0.3605 0.6774]\n",
      "4  \t40   \t[0.3396 0.6372]\t[0.3655 0.6774]\n",
      "5  \t40   \t[0.3396 0.6381]\t[0.369  0.6774]\n",
      "6  \t40   \t[0.3426 0.6381]\t[0.37   0.6774]\n",
      "7  \t40   \t[0.3468 0.6467]\t[0.37   0.6774]\n",
      "8  \t40   \t[0.3587 0.6661]\t[0.3706 0.6797]\n",
      "9  \t40   \t[0.3605 0.6729]\t[0.3723 0.6797]\n",
      "10 \t40   \t[0.3605 0.6729]\t[0.3723 0.6797]\n",
      "11 \t40   \t[0.3605 0.6729]\t[0.3723 0.6819]\n",
      "12 \t40   \t[0.3605 0.6729]\t[0.3723 0.6819]\n",
      "13 \t40   \t[0.3658 0.6729]\t[0.3723 0.6819]\n",
      "14 \t40   \t[0.3658 0.673 ]\t[0.3745 0.6819]\n",
      "15 \t40   \t[0.3658 0.673 ]\t[0.3745 0.6819]\n",
      "16 \t40   \t[0.3658 0.673 ]\t[0.3745 0.6819]\n",
      "17 \t40   \t[0.3658 0.6712]\t[0.3794 0.6819]\n",
      "18 \t40   \t[0.3658 0.6712]\t[0.3794 0.6819]\n",
      "19 \t40   \t[0.3679 0.6712]\t[0.3804 0.6858]\n",
      "20 \t40   \t[0.3655 0.6712]\t[0.3804 0.6858]\n",
      "21 \t40   \t[0.3679 0.6712]\t[0.3804 0.6858]\n",
      "22 \t40   \t[0.3703 0.6712]\t[0.3804 0.6858]\n",
      "23 \t40   \t[0.374  0.6712]\t[0.3804 0.6858]\n",
      "24 \t40   \t[0.374  0.6712]\t[0.3804 0.6858]\n",
      "25 \t40   \t[0.374  0.6712]\t[0.3804 0.6858]\n",
      "26 \t40   \t[0.374  0.6735]\t[0.3881 0.6921]\n",
      "27 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "28 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "29 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "30 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "31 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "32 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "33 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "34 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "35 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "36 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "37 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "38 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "39 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "40 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "41 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "42 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "43 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "44 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "45 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "46 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "47 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "48 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "49 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "50 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "51 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "52 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "53 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "54 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "55 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "56 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "57 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "58 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "59 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "60 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "61 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "62 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "63 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "64 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "65 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "66 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "67 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "68 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "69 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "70 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "71 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "72 \t40   \t[0.3804 0.6858]\t[0.3881 0.6921]\n",
      "73 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "74 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "75 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "76 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "77 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "78 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "79 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "80 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "81 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "82 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "83 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "84 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "85 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "86 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "87 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "88 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "89 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "90 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "91 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "92 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "93 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "94 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "95 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "96 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "97 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "98 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n",
      "99 \t40   \t[0.3804 0.6855]\t[0.3881 0.6921]\n"
     ]
    }
   ],
   "source": [
    "from instance_selection.nsga_2.genetic_operator import selNSGA2, mutate_binary_inversion, selTournamentDCD\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # 忽略警告\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import array\n",
    "import random\n",
    "import numpy\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "\n",
    "# 最大化评价目标\n",
    "creator.create(\"FitnessMaxAndMax\", base.Fitness, weights=(1.0, 1.0))\n",
    "'''\n",
    "fitness:适应度：Gmean和mAUC\n",
    "class_accuracies：分类器对每个类的分类准确度\n",
    "PPVs：PPV也即Precision,PPVs表示对每个类的分类精度\n",
    "PFC：每个分类器的成对故障信用，用于评估分类器集合的多样性\n",
    "\n",
    "'''\n",
    "creator.create(\"Individual\", array.array, typecode='d', fitness=creator.FitnessMaxAndMax, pfc=None, mlp=None)\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "BOUND_LOW, BOUND_UP = 0.0, 1.0\n",
    "\n",
    "NDIM = num_instances\n",
    "# 二进制编码\n",
    "toolbox.register(\"attr_binary\", random.randint, 0, 1)  # 0-1编码\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_binary, n=num_instances)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# toolbox.register(\"evaluate\", benchmarks.zdt1)\n",
    "toolbox.register(\"evaluate\", fitness_function)\n",
    "# toolbox.register(\"mate\", tools.cxSimulatedBinaryBounded, low=BOUND_LOW, up=BOUND_UP, eta=20.0)\n",
    "# 单点交叉\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "# 二进制突变\n",
    "toolbox.register(\"mutate\", mutate_binary_inversion)\n",
    "toolbox.register(\"select\", selNSGA2,x_test=x_test,y_test=y_test)\n",
    "# toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "init_mlp = MLPClassifier(hidden_layer_sizes=(20,), max_iter=800, random_state=42)\n",
    "\n",
    "\n",
    "def main(seed=None):\n",
    "    random.seed(seed)\n",
    "\n",
    "    NGEN = 100\n",
    "    MU = 40\n",
    "    CXPB = 1.0\n",
    "    MR = 0.2\n",
    "\n",
    "    ####################################迭代过程的记录###########################\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    # stats.register(\"avg\", numpy.mean, axis=0)\n",
    "    # stats.register(\"std\", numpy.std, axis=0)\n",
    "    stats.register(\"min\", numpy.min, axis=0)\n",
    "    stats.register(\"max\", numpy.max, axis=0)\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = \"gen\", \"evals\", \"min\", \"max\"\n",
    "\n",
    "    ####################################种群的初始化###########################\n",
    "    pop = toolbox.population(n=MU)\n",
    "\n",
    "    ####################################计算初始种群的适应度###########################\n",
    "    ensembles = []  # 当前每个个体对应的mlp模型\n",
    "    base_estimators = []  # 基学习器\n",
    "    save_ensemble = None  # 存储每个个体对应的mlp模型\n",
    "    pop_x_sub = []  # 当前每个个体的实例选择的特征数据\n",
    "    pop_y_sub = []  # 当前每个个体对应的实例选择的lable\n",
    "    # 对于每个个体都训练得到一个mlp模型\n",
    "    for i in range(len(pop)):\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(20,), max_iter=800, random_state=42)\n",
    "        x_sub, y_sub = get_subset(pop[i])\n",
    "        mlp.fit(x_sub, y_sub)\n",
    "        ensembles.append(mlp)\n",
    "        pop_x_sub.append(x_sub)\n",
    "        pop_y_sub.append(y_sub)\n",
    "        pop[i].mlp = mlp\n",
    "\n",
    "    # 由mlp模型得到个体的适应度\n",
    "    for i in range(len(pop)):\n",
    "        pop[i].fitness.values = toolbox.evaluate(pop[i])\n",
    "\n",
    "    #################################计算PFC并进行非支配排序#########################################\n",
    "    # 计算PFC并进行非支配排序 PFC代替拥挤距离\n",
    "    pop = toolbox.select(pop, len(pop))\n",
    "\n",
    "    record = stats.compile(pop)\n",
    "    logbook.record(gen=0, evals=len(pop), **record)\n",
    "    print(logbook.stream)\n",
    "    ####################################种群的迭代###########################\n",
    "    for gen in range(1, NGEN):\n",
    "        # 选择\n",
    "        offspring = selTournamentDCD(pop, len(pop))\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "\n",
    "        # 交叉\n",
    "        for i in range(0, len(offspring) - 1, 2):\n",
    "            if random.random() <= CXPB:\n",
    "                offspring[i], offspring[i + 1] = toolbox.mate(offspring[i], offspring[i + 1])\n",
    "            # 突变\n",
    "            offspring[i] = toolbox.mutate(offspring[i])[0]\n",
    "            offspring[i + 1] = toolbox.mutate(offspring[i + 1])[0]\n",
    "            del offspring[i].fitness.values, offspring[i + 1].fitness.values\n",
    "\n",
    "        # 计算新的种群适应度 \n",
    "        ensembles.clear()\n",
    "        pop_x_sub.clear()\n",
    "        pop_y_sub.clear()\n",
    "        for i in range(len(offspring)):\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=(20,), max_iter=1000, random_state=42)\n",
    "            x_sub, y_sub = get_subset(offspring[i])\n",
    "            mlp.fit(x_sub, y_sub)\n",
    "            ensembles.append(mlp)\n",
    "            pop_x_sub.append(x_sub)\n",
    "            pop_y_sub.append(y_sub)\n",
    "            offspring[i].mlp = mlp\n",
    "        for i in range(len(offspring)):\n",
    "            offspring[i].fitness.values = toolbox.evaluate(offspring[i])\n",
    "\n",
    "        # Select the next generation population\n",
    "        pop = toolbox.select(pop + offspring, MU)\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=gen, evals=len(pop), **record)\n",
    "        print(logbook.stream)\n",
    "\n",
    "    return pop, logbook\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pop, stats = main()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T14:18:41.139512Z",
     "start_time": "2024-11-19T12:18:35.026116Z"
    }
   },
   "id": "b68e95c1a5b9442a",
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
