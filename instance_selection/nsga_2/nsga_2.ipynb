{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 数据集构建"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f6e0ae9de365691"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征数据: (1000, 24)\n",
      "label: (1000,)\n",
      "每种类别的数量： [103  89 116 114 116  86 107  97  83  89]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from utils.dataset_utils import get_classes_indexes_counts\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "import numpy as np\n",
    "\n",
    "################################################################加载数据集################################################\n",
    "# 数据集\n",
    "mat_data = sio.loadmat('../../data/dataset/LedDisplay.mat')\n",
    "# 提取变量\n",
    "dataset_x = mat_data['X']\n",
    "dataset_y = mat_data['Y'][:, 0]  # mat_data['Y']得到的形状为[n,1]，通过[:,0]，得到形状[n,]\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", dataset_x.shape)\n",
    "print(\"label:\", dataset_y.shape)\n",
    "# 统计每个类别的个数，dataset_y.max()+1是类别的个数\n",
    "classes, counts = get_classes_indexes_counts(dataset_y)\n",
    "print(\"每种类别的数量：\", counts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T11:45:12.839521Z",
     "start_time": "2024-11-11T11:45:12.824365Z"
    }
   },
   "id": "4bbfb8b04ee2220",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  划分数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b163bfd820e476e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征数据: (700, 24)\n",
      "label: (700,)\n",
      "每种类别的数量： [67 68 79 79 81 63 71 63 63 66]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dataset_x, dataset_y, test_size=0.3, random_state=42)\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", x_train.shape)\n",
    "print(\"label:\", y_train.shape)\n",
    "# 统计每个类别的个数\n",
    "classes_train, counts_train = get_classes_indexes_counts(y_train)\n",
    "print(\"每种类别的数量：\", counts_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T11:45:14.595289Z",
     "start_time": "2024-11-11T11:45:14.581776Z"
    }
   },
   "id": "b15c4bd533249491",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 训练集的构建\n",
    "1.首先找出类别数量最小的类\n",
    "2.取最小类别数量的90%，作为平衡数据集的各类别原始数量\n",
    "3.在每个类别中随机抽取实例构成初始数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8811199107bb05a9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最小数量: 56\n",
      "平衡的数据集的特征数据: (560, 24)\n",
      "label: (560,)\n",
      "平衡的数据集中每种类别的数量： [56 56 56 56 56 56 56 56 56 56]\n"
     ]
    }
   ],
   "source": [
    "# 确定每个类别的数量\n",
    "num_instances = int(counts_train.min() * 0.9)  # 向下取整\n",
    "print(\"最小数量:\", num_instances)\n",
    "\n",
    "# 在每个类别中随机的选择该数量的实例的索引\n",
    "balanced_classes = np.array([])\n",
    "for indexes in classes_train:\n",
    "    random_selecte_indices = np.random.choice(indexes, size=num_instances, replace=False)\n",
    "    balanced_classes = np.hstack((balanced_classes, random_selecte_indices))\n",
    "balanced_classes = np.sort(balanced_classes).astype(int)\n",
    "\n",
    "# 得到平衡的数据集\n",
    "balanced_dataset_x = []\n",
    "balanced_dataset_y = np.array([])\n",
    "for index in balanced_classes:\n",
    "    balanced_dataset_x.append(x_train[index])\n",
    "    balanced_dataset_y = np.hstack((balanced_dataset_y, y_train[index]))\n",
    "balanced_dataset_x = np.array(balanced_dataset_x)\n",
    "balanced_dataset_y = np.array(balanced_dataset_y).astype(int)\n",
    "\n",
    "# 显示数据集分布\n",
    "print(\"平衡的数据集的特征数据:\", balanced_dataset_x.shape)\n",
    "print(\"label:\", balanced_dataset_y.shape)\n",
    "\n",
    "# 统计每个类别的个数\n",
    "classes_balanced_dataset, counts_balanced_dataset = get_classes_indexes_counts(balanced_dataset_y)\n",
    "print(\"平衡的数据集中每种类别的数量：\", counts_balanced_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T11:45:16.206318Z",
     "start_time": "2024-11-11T11:45:16.187075Z"
    }
   },
   "id": "746a165e373967a6",
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 单独训练"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cddedb62759138ca"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "x_train_single = scaler.fit_transform(balanced_dataset_x)\n",
    "x_test_single = scaler.transform(x_test)\n",
    "# 构建并训练MLP模型\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 20), max_iter=1000, random_state=42)\n",
    "mlp.fit(x_train_single, balanced_dataset_y)\n",
    "\n",
    "# 预测和评估模型\n",
    "y_pred = mlp.predict(x_test_single)\n",
    "\n",
    "# 输出结果\n",
    "print(\"准确率:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n分类报告:\\n\", classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "523273a215749ed",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NSGAII算法"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94e29ba55c98658f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 算法的实现"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "855b2a2d0d65a780"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "#####################################################\n",
    "def get_indices(individual):\n",
    "    '''\n",
    "    :param individual: individual（用实值进行编码）\n",
    "    :return: 被选择实例的索引\n",
    "    '''\n",
    "    individual = np.round(individual)  # 数据范围在0-1之间，转化成int的同时会舍去小数部分，从而将个体映射到0-1编码\n",
    "    indices = np.where(individual == 1)  # 1代表选择该实例，返回值是tuple，tuple[0]取元组中的第一个元素\n",
    "    return indices[0]\n",
    "\n",
    "\n",
    "#######################################################\n",
    "\n",
    "def get_subset(individual):\n",
    "    indices = get_indices(individual)\n",
    "    x_sub = balanced_dataset_x[indices, :]\n",
    "    y_sub = balanced_dataset_y[indices]\n",
    "    return x_sub, y_sub\n",
    "\n",
    "\n",
    "###########################################################\n",
    "\n",
    "def fitness_function(x_sub, y_sub, ensembles, index):\n",
    "    f1 = ensembles[index].fit(x_sub)\n",
    "    # 使用测试数据进行预测\n",
    "    y_pred = ensembles[index].predict(x_sub)\n",
    "\n",
    "    # 计算混淆矩阵\n",
    "    tn, fp, fn, tp = confusion_matrix(y_sub, y_pred).ravel()\n",
    "    f1 = 1.0 * tp / (tp + fp)\n",
    "    sum = 0.0\n",
    "    for i in range(len(ensembles)):\n",
    "        if i != index:\n",
    "            # 计算两个数组中索引对应的元素值不相等的个数\n",
    "            y_pred_i = ensembles[i].predict(x_sub)\n",
    "            tn_i, fp_i, fn_i, tp_i = confusion_matrix(y_sub, y_pred_i).ravel()\n",
    "            count = sum(1 for a, b in zip(y_pred, y_pred_i) if a != b)\n",
    "            sum = sum + count / (fp + fn + fp_i + fn_i)\n",
    "    f2 = sum / len(ensembles)\n",
    "    return f1, f2\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T14:17:53.685017Z",
     "start_time": "2024-11-11T14:17:53.673018Z"
    }
   },
   "id": "1b2fbc6f174a89bf",
   "execution_count": 85
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 多目标评价"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c21d5f2e37b5c51"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fitness_function() missing 3 required positional arguments: 'y_sub', 'ensembles', and 'index'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[86], line 114\u001B[0m\n\u001B[0;32m    110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pop, logbook\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 114\u001B[0m     pop, stats \u001B[38;5;241m=\u001B[39m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[86], line 73\u001B[0m, in \u001B[0;36mmain\u001B[1;34m(seed)\u001B[0m\n\u001B[0;32m     70\u001B[0m     pop_y_sub\u001B[38;5;241m.\u001B[39mappend(y_sub)\n\u001B[0;32m     72\u001B[0m fitnesses \u001B[38;5;241m=\u001B[39m toolbox\u001B[38;5;241m.\u001B[39mmap(toolbox\u001B[38;5;241m.\u001B[39mevaluate, pop)\n\u001B[1;32m---> 73\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ind, fit \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(pop, fitnesses):\n\u001B[0;32m     74\u001B[0m     ind\u001B[38;5;241m.\u001B[39mfitness\u001B[38;5;241m.\u001B[39mvalues \u001B[38;5;241m=\u001B[39m fit\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(pop)):\n",
      "\u001B[1;31mTypeError\u001B[0m: fitness_function() missing 3 required positional arguments: 'y_sub', 'ensembles', and 'index'"
     ]
    }
   ],
   "source": [
    "import array\n",
    "import random\n",
    "import numpy\n",
    "from deap import base\n",
    "from deap import benchmarks\n",
    "from deap.benchmarks.tools import diversity, convergence, hypervolume\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0, -1.0))\n",
    "creator.create(\"Individual\", array.array, typecode='d', fitness=creator.FitnessMin)\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Problem definition\n",
    "\n",
    "BOUND_LOW, BOUND_UP = 0.0, 1.0\n",
    "\n",
    "NDIM = 30\n",
    "\n",
    "\n",
    "def uniform(low, up, size=None):\n",
    "    try:\n",
    "        return [random.uniform(a, b) for a, b in zip(low, up)]\n",
    "    except TypeError:\n",
    "        return [random.uniform(a, b) for a, b in zip([low] * size, [up] * size)]\n",
    "\n",
    "\n",
    "toolbox.register(\"attr_float\", uniform, BOUND_LOW, BOUND_UP, NDIM)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.attr_float)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", benchmarks.zdt1)\n",
    "toolbox.register(\"evaluate\", fitness_function)\n",
    "# toolbox.register(\"mate\", tools.cxSimulatedBinaryBounded, low=BOUND_LOW, up=BOUND_UP, eta=20.0)\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "toolbox.register(\"mutate\", tools.mutPolynomialBounded, low=BOUND_LOW, up=BOUND_UP, eta=20.0, indpb=1.0 / NDIM)\n",
    "# toolbox.register(\"select\", tools.selNSGA2)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "\n",
    "def main(seed=None):\n",
    "    random.seed(seed)\n",
    "\n",
    "    NGEN = 250\n",
    "    MU = 30\n",
    "    CXPB = 0.9\n",
    "\n",
    "    ####################################迭代过程的记录###########################\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    # stats.register(\"avg\", numpy.mean, axis=0)\n",
    "    # stats.register(\"std\", numpy.std, axis=0)\n",
    "    stats.register(\"min\", numpy.min, axis=0)\n",
    "    stats.register(\"max\", numpy.max, axis=0)\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = \"gen\", \"evals\", \"min\", \"max\"\n",
    "\n",
    "    ####################################种群的初始化###########################\n",
    "    pop = toolbox.population(n=MU)\n",
    "\n",
    "    ####################################计算初始种群的适应度###########################\n",
    "    ensembles = []  # 当前每个个体对应的mlp模型\n",
    "    save_ensembles = []  # 存储每个个体对应的mlp模型\n",
    "    pop_x_sub = [] # 当前每个个体的实例选择的特征数据\n",
    "    pop_y_sub = [] # 当前每个个体对应的实例选择的lable\n",
    "    for i in range(len(pop)):\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(10, 20), max_iter=1000, random_state=42)\n",
    "        x_sub, y_sub = get_subset(pop[i])\n",
    "        mlp.fit(x_sub, y_sub)\n",
    "        ensembles.append(mlp)\n",
    "        pop_x_sub.append(x_sub)\n",
    "        pop_y_sub.append(y_sub)\n",
    "    save_ensembles = ensembles\n",
    "    for i in range(len(pop)):\n",
    "        pop.fitness.values[i] = toolbox.evaluate(pop_x_sub[i], pop_y_sub[i], ensembles)\n",
    "    record = stats.compile(pop)\n",
    "    logbook.record(gen=0, evals=len(pop), **record)\n",
    "    print(logbook.stream)\n",
    "    ####################################种群的迭代###########################\n",
    "    for gen in range(1, NGEN):\n",
    "        # 选择\n",
    "        offspring = toolbox.select(pop, len(pop))\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "\n",
    "        # 交叉\n",
    "        for i in range(0, len(offspring) - 1, 2):\n",
    "            if random.random() <= CXPB:\n",
    "                offspring[i], offspring[i + 1] = toolbox.mate(offspring[i], offspring[i + 1])\n",
    "            # 变异\n",
    "            offspring[i] = toolbox.mutate(offspring[i])[0]\n",
    "            offspring[i + 1] = toolbox.mutate(offspring[i + 1])[0]\n",
    "            del offspring[i].fitness.values, offspring[i + 1].fitness.values\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, offspring)\n",
    "        for ind, fit in zip(offspring, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        for i in range(len(pop)):\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=(10, 20), max_iter=1000, random_state=42)\n",
    "            x_sub, y_sub = get_subset(pop[i])\n",
    "            mlp.fit(x_sub, y_sub)\n",
    "            ensembles.append(mlp)\n",
    "            pop_x_sub.append(x_sub)\n",
    "            pop_y_sub.append(y_sub)\n",
    "        for i in range(len(pop)):\n",
    "            pop.fitness.values[i] = toolbox.evaluate(pop_x_sub[i], pop_y_sub[i], ensembles)\n",
    "\n",
    "        # Select the next generation population\n",
    "        pop = toolbox.select(pop + offspring, MU)\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=gen, evals=len(pop), **record)\n",
    "        print(logbook.stream)\n",
    "\n",
    "    print(\"Final population hypervolume is %f\" % hypervolume(pop, [11.0, 11.0]))\n",
    "\n",
    "    return pop, logbook\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pop, stats = main()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T14:17:58.891752Z",
     "start_time": "2024-11-11T14:17:56.646106Z"
    }
   },
   "id": "b68e95c1a5b9442a",
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "def swap(a, b):\n",
    "    return b, a\n",
    "\n",
    "\n",
    "list1 = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "print(list1)\n",
    "for ind1, ind2 in zip(list1[::2], list1[1::2]):\n",
    "    ind1, ind2 = ind1 + 1, ind2 + 2\n",
    "print(list1)            "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-11T13:20:20.707853Z",
     "start_time": "2024-11-11T13:20:20.691835Z"
    }
   },
   "id": "9f0f4463d816e16b",
   "execution_count": 73
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
