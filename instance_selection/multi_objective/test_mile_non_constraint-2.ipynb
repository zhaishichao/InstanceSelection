{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# E-SEIC\n",
    "Selection of evolutionary instances with constraints for unbalanced datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea42cd71d488f349"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T05:47:34.937833Z",
     "start_time": "2025-04-20T05:47:34.896342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.dataset_utils import get_distribution, k_fold_cross_validation\n",
    "from instance_selection.parameter.parameter import *  # 导入参数的设定\n",
    "from instance_selection.operator.init_toolbox import init_toolbox_eseic\n",
    "from instance_selection.operator.metrics import calculate_gmean_mauc, calculate_average_accuracy, calculate_accuracy\n",
    "from instance_selection.operator.genetic_operator import selTournamentNDCD\n",
    "from instance_selection.operator.ensemble import vote_result_ensembles, ensemble_individuals\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.base import clone\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import os\n",
    "from openpyxl import Workbook\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # 忽略警告\n",
    "# 数据的预处理\n",
    "def data_process(dataset=None, distribution=False):\n",
    "    datasetname = dataset.DATASETNAME.split('.')[0]\n",
    "    mat_data = sio.loadmat(IMBALANCED_DATASET_PATH + dataset.DATASETNAME)  # 加载、划分数据集\n",
    "    x = mat_data['X']\n",
    "    y = mat_data['Y'][:, 0]  # mat_data['Y']得到的形状为[n,1]，通过[:,0]，得到形状[n,]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, stratify=y,\n",
    "                                                        random_state=RANDOM_SEED)  # 划分数据集\n",
    "    scaler = StandardScaler()  # 数据的标准化\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    unique_elements_all, classes_all, counts_all = get_distribution(y)  # 获取原始数据集分布\n",
    "    unique_elements_train, classes_train, counts_train = get_distribution(y_train)  # 获取训练集分布\n",
    "    unique_elements_test, classes_test, counts_test = get_distribution(y_test)  # 获取测试集分布\n",
    "    weights_train = (1 / counts_train.astype(float)) / np.sum(1 / counts_train.astype(float))  # 计算每个类的权重，用于计算每个类别的权重\n",
    "    if distribution:\n",
    "        print(datasetname + f' distribution: {counts_all}')\n",
    "        print(f'trainset distribution: {counts_train}')\n",
    "        print(f'testset distribution: {counts_test}')\n",
    "    model = MLPClassifier(hidden_layer_sizes=(dataset.HIDDEN_SIZE,), max_iter=dataset.MAX_ITER,\n",
    "                          random_state=RANDOM_SEED, learning_rate_init=dataset.LEARNING_RATE)\n",
    "    y_train_pred_proba = k_fold_cross_validation(model=clone(model), X=x_train, y=y_train, n_splits=N_SPLITS,\n",
    "                                                 method='soft',\n",
    "                                                 random_state=RANDOM_SEED)  # 交叉验证得到软标签\n",
    "    # 将概率转化为预测结果\n",
    "    y_train_pred = np.argmax(y_train_pred_proba, axis=1)\n",
    "\n",
    "    Acc1, Acc2, Acc3 = calculate_accuracy(y_train_pred, y_train, weights_train)\n",
    "    constraints = [Acc1, Acc2, Acc3]\n",
    "\n",
    "    return x_train, x_test, y_train, y_test, constraints, weights_train, clone(model)\n",
    "def main(x_train, y_train, model, balanced_method='random'):\n",
    "    list_of_sfe = []\n",
    "    ####################################种群的初始化###########################\n",
    "    pop = toolbox.population(n=POPSIZE)  # 个体编码默认全为0\n",
    "    pop = toolbox.init_population(pop, balanced_method=balanced_method)  # 初始化种群中的个体\n",
    "    toolbox.evaluate(pop)  # 计算个体的适应度\n",
    "    feasible_pop, infeasible_pop = toolbox.get_feasible_infeasible(pop)  # 得到可行解与不可行解\n",
    "    # 输出可行解的数量\n",
    "    print(f'第{0}代，可行解的数量为{len(feasible_pop)}')\n",
    "    list_of_sfe.append(len(feasible_pop))\n",
    "    ####################################种群的迭代#################################################\n",
    "    for gen in range(1, NGEN + 11):\n",
    "        offspring = selTournamentNDCD(pop, POPSIZE, tournsize=3)  # 锦标赛选择（1、先根据非支配排序的等级2、再根据拥挤距离）\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "        for i in range(0, len(offspring) - 1, 2):\n",
    "            if random.random() <= CXPB:\n",
    "                offspring[i], offspring[i + 1] = toolbox.mate(offspring[i], offspring[i + 1])  # 单点交叉\n",
    "            offspring[i] = toolbox.mutate(offspring[i], MR)[0]  # 二进制反转突变\n",
    "            offspring[i + 1] = toolbox.mutate(offspring[i + 1], MR)[0]  # 二进制反转突变\n",
    "            del offspring[i].fitness.values, offspring[i + 1].fitness.values\n",
    "        #############################################################合并、去重#####################################################\n",
    "        offspring = toolbox.individuals_constraints(offspring)  # 限制每个类至少有一个实例被选择\n",
    "        pop = pop + offspring  # 种群的合并\n",
    "        pop, _ = toolbox.remove_duplicates(pop)  # 去重\n",
    "        while len(pop) < POPSIZE:  # 保证种群大小为POPSIZE\n",
    "            add_individual = []\n",
    "            num_add = POPSIZE - len(pop)\n",
    "            for i in range(0, num_add):\n",
    "                index = random.randint(0, len(offspring) - 1)  # 在0-len(offspring)范围内随机产生一个索引\n",
    "                offspring[index] = toolbox.mutate(offspring[index], MR)[0]  # 选择index对应的个体进行突变\n",
    "                del offspring[index].fitness.values\n",
    "                add_individual.append(offspring[index])\n",
    "            add_individual = toolbox.individuals_constraints(add_individual)  # 限制每个类至少有一个实例被选择\n",
    "            pop = pop + add_individual  # 种群的合并\n",
    "            pop, _ = toolbox.remove_duplicates(pop)  # 去重\n",
    "        pop = toolbox.individuals_constraints(pop)  # 限制每个类至少有5个实例被选择\n",
    "        toolbox.evaluate(pop)  # 计算新种群适应度\n",
    "        ###############################################得到pareto_fronts############################################\n",
    "        feasible_pop, infeasible_pop = toolbox.get_feasible_infeasible(pop)  # 得到可行解与不可行解\n",
    "        # 输出可行解的数量\n",
    "        print(f'第{gen}代，可行解的数量为{len(feasible_pop)}')\n",
    "        list_of_sfe.append(len(feasible_pop))\n",
    "        pop, pareto_fronts = toolbox.select(pop, POPSIZE) # 从混合的种群中选择POPSIZE\n",
    "    ensemble_classifiers = ensemble_individuals(pop, model, x_train, y_train)\n",
    "    return ensemble_classifiers, list_of_sfe\n",
    "def save_to_excel(data, save_path, filename='avg_results'):\n",
    "    \"\"\"\n",
    "    将列表数据逐行写入Excel文件\n",
    "    参数:\n",
    "        data: 二维列表，每个子列表代表一行数据\n",
    "        filename: 输出的Excel文件名(默认为output.xlsx)\n",
    "    \"\"\"\n",
    "    # 创建一个新的工作簿\n",
    "    wb = Workbook()\n",
    "    # 获取活动的工作表\n",
    "    ws = wb.active\n",
    "    # 逐行写入数据\n",
    "    for row in data:\n",
    "        avg = row[1].tolist()\n",
    "        avg.insert(0, row[0])\n",
    "        std = row[2].tolist()\n",
    "        std.insert(0, row[0])\n",
    "        ws.append(avg)\n",
    "        ws.append(std)\n",
    "    # 创建 Excel 文件完整路径\n",
    "    file_path = os.path.join(save_path, filename + \".xlsx\")\n",
    "    # 保存Excel文件\n",
    "    wb.save(file_path)\n",
    "    print(f\"数据已成功写入到 {file_path}\")"
   ],
   "id": "606d66515f44780e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": "## 运行",
   "metadata": {
    "collapsed": false
   },
   "id": "b1848de64743684e"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-20T05:47:34.939888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DATASETS = [Balance_Scale,Dermatology,Ecoli,Car,Pen_Digits,WallRobot,German,Wine,Nursery,Penbased,USPS,Satellite,Page_Blocks,Shuttle,Contraceptive,Automobile,Ovarian]  # 数据集名称（包含对应的参数配置）\n",
    "# DATASETS = [Balance_Scale,Dermatology,Ecoli,Car,Pen_Digits,WallRobot,Wine,Satellite,Shuttle]  # 数据集名称（包含对应的参数配置）\n",
    "DATASETS = [German,Nursery,Penbased,Contraceptive,USPS]  # 数据集名称（包含对应的参数配置）\n",
    "if __name__ == \"__main__\":\n",
    "    save_path = 'C:/Users/zsc/Desktop/MILE/'\n",
    "    datasets_sfe_results = []\n",
    "    print(\"*****************算法开始执行：******************\")\n",
    "    for j, dataset in enumerate(DATASETS):\n",
    "        x_train, x_test, y_train, y_test, constraints, weights_train, model = data_process(dataset=dataset,\n",
    "                                                                                           distribution=False)\n",
    "        toolbox = init_toolbox_eseic(model, x_train, y_train, weights_train, constraints, n_splits=N_SPLITS,\n",
    "                                     random_seed=42)  # 初始化toolbox\n",
    "        num_run = 4  # 运行次数\n",
    "        for i in range(num_run):\n",
    "            _, list_of_sfe = main(x_train, y_train, model=model, balanced_method='random')\n",
    "            datasets_sfe_results.append([dataset.DATASETNAME.split('.')[0], list_of_sfe])\n",
    "    print(\"*****************算法执行结束！******************\")\n",
    "    for k, list in enumerate(datasets_sfe_results):\n",
    "        print(f'{list[0]}的第{(k + 1) % (num_run+1)}次运行的结果为：{list[1]}')"
   ],
   "id": "83fe98bf11a51bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************算法开始执行：******************\n",
      "第0代，可行解的数量为3\n",
      "第1代，可行解的数量为15\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "a=np.array(datasets_sfe_results)",
   "id": "67d425887fe282a8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
