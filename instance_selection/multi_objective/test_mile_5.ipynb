{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# E-SEIC\n",
    "Selection of evolutionary instances with constraints for unbalanced datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea42cd71d488f349"
  },
  {
   "cell_type": "code",
   "source": [
    "from utils.dataset_utils import get_distribution, k_fold_cross_validation\n",
    "from instance_selection.parameter.parameter import *  # 导入参数的设定\n",
    "from instance_selection.operator.init_toolbox import init_toolbox_eseic\n",
    "from instance_selection.operator.metrics import calculate_gmean_mauc, calculate_average_accuracy, \\\n",
    "    calculate_average_gmean_mauc, calculate_accuracy\n",
    "from instance_selection.operator.genetic_operator import selTournamentNDCD\n",
    "from instance_selection.operator.ensemble import vote_result_ensembles, ensemble_individuals\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.base import clone\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "import random\n",
    "from deap import tools\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # 忽略警告\n",
    "\n",
    "DATASET = Splice  # 数据集名称（包含对应的参数配置）\n",
    "\n",
    "datasetname = DATASET.DATASETNAME.split('.')[0]\n",
    "mat_data = sio.loadmat(IMBALANCED_DATASET_PATH + DATASET.DATASETNAME)  # 加载、划分数据集\n",
    "x = mat_data['X']\n",
    "y = mat_data['Y'][:, 0]  # mat_data['Y']得到的形状为[n,1]，通过[:,0]，得到形状[n,]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, stratify=y,\n",
    "                                                    random_state=RANDOM_SEED+1)  # 划分数据集\n",
    "scaler = StandardScaler()  # 数据的标准化\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "unique_elements_all, classes_all, counts_all = get_distribution(y)  # 获取原始数据集分布\n",
    "unique_elements_train, classes_train, counts_train = get_distribution(y_train)  # 获取训练集分布\n",
    "unique_elements_test, classes_test, counts_test = get_distribution(y_test)  # 获取测试集分布\n",
    "print(datasetname + f' distribution: {counts_all}')\n",
    "print(f'trainset distribution: {counts_train}')\n",
    "print(f'testset distribution: {counts_test}')\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(DATASET.HIDDEN_SIZE,), max_iter=DATASET.MAX_ITER,\n",
    "                      random_state=RANDOM_SEED+1, learning_rate_init=DATASET.LEARNING_RATE)\n",
    "\n",
    "weights_train = (1 / counts_train.astype(float)) / np.sum(1 / counts_train.astype(float))  # 计算每个类的权重，用于计算每个类别的权重\n",
    "weights_test = (1 / counts_test.astype(float)) / np.sum(1 / counts_test.astype(float))  # 计算每个类的权重，用于计算每个类别的权重\n",
    "\n",
    "num_instances = int(np.ceil(counts_train.min() * 0.9))  # 取最小数量的类的0.9（向下取整）\n",
    "print(\"最小数量:\", num_instances)\n",
    "\n",
    "y_train_pred_proba = k_fold_cross_validation(model=clone(model), X=x_train, y=y_train, n_splits=N_SPLITS - 2,\n",
    "                                             method='soft',\n",
    "                                             random_state=RANDOM_SEED+1)  # 交叉验证得到软标签\n",
    "# 将概率转化为预测结果\n",
    "y_train_pred = np.argmax(y_train_pred_proba, axis=1)\n",
    "\n",
    "Acc1, Acc2, Acc3 = calculate_accuracy(y_train_pred, y_train, weights_train)\n",
    "constraints = [Acc1, Acc2, Acc3]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-13T14:20:00.676973Z",
     "start_time": "2025-04-13T14:19:59.884374Z"
    }
   },
   "id": "cfea17902425a78f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splice distribution: [ 767  768 1655]\n",
      "trainset distribution: [ 537  538 1158]\n",
      "testset distribution: [230 230 497]\n",
      "最小数量: 484\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## E-SEIC"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1848de64743684e"
  },
  {
   "cell_type": "code",
   "source": [
    "toolbox = init_toolbox_eseic(model, x_train, y_train, weights_train, constraints, n_splits=N_SPLITS - 2,\n",
    "                             random_seed=RANDOM_SEED)  # 初始化toolbox\n",
    "\n",
    "\n",
    "def main(x_train, y_train, model, balanced_method='balanced'):\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = \"gen\", \"feasible\", \"ensembles_size\", \"avg_gmean\", \"avg_mauc\", \"avg_acc2\"\n",
    "    ####################################种群的初始化###########################\n",
    "    pop = toolbox.population(n=POPSIZE)  # 个体编码默认全为0\n",
    "    pop = toolbox.init_population(pop, balanced_method=balanced_method)  # 初始化种群中的个体\n",
    "    toolbox.evaluate(pop)  # 计算个体的适应度\n",
    "    ####################################种群的迭代#################################################\n",
    "    for gen in range(1, NGEN + 1):\n",
    "        offspring = selTournamentNDCD(pop, POPSIZE, tournsize=3)  # 锦标赛选择（1、先根据非支配排序的等级2、再根据拥挤距离）\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "        for i in range(0, len(offspring) - 1, 2):\n",
    "            if random.random() <= CXPB:\n",
    "                offspring[i], offspring[i + 1] = toolbox.mate(offspring[i], offspring[i + 1])  # 单点交叉\n",
    "            offspring[i] = toolbox.mutate(offspring[i], MR)[0]  # 二进制反转突变\n",
    "            offspring[i + 1] = toolbox.mutate(offspring[i + 1], MR)[0]  # 二进制反转突变\n",
    "            del offspring[i].fitness.values, offspring[i + 1].fitness.values\n",
    "        #############################################################合并、去重#####################################################\n",
    "        offspring = toolbox.individuals_constraints(offspring)  # 限制每个类至少有一个实例被选择\n",
    "        pop = pop + offspring  # 种群的合并\n",
    "        pop, _ = toolbox.remove_duplicates(pop)  # 去重\n",
    "        while len(pop) < POPSIZE:  # 保证种群大小为POPSIZE\n",
    "            add_individual = []\n",
    "            num_add = POPSIZE - len(pop)\n",
    "            for i in range(0, num_add):\n",
    "                index = random.randint(0, len(offspring) - 1)  # 在0-len(offspring)范围内随机产生一个索引\n",
    "                offspring[index] = toolbox.mutate(offspring[index], MR)[0]  # 选择index对应的个体进行突变\n",
    "                del offspring[index].fitness.values\n",
    "                add_individual.append(offspring[index])\n",
    "            add_individual = toolbox.individuals_constraints(add_individual)  # 限制每个类至少有一个实例被选择\n",
    "            pop = pop + add_individual  # 种群的合并\n",
    "            pop, _ = toolbox.remove_duplicates(pop)  # 去重\n",
    "        pop = toolbox.individuals_constraints(pop)  # 限制每个类至少有5个实例被选择\n",
    "        toolbox.evaluate(pop)  # 计算新种群适应度\n",
    "        ###############################################得到pareto_fronts############################################\n",
    "        feasible_pop, infeasible_pop = toolbox.get_feasible_infeasible(pop)  # 得到可行解与不可行解\n",
    "        if len(feasible_pop) >= POPSIZE:\n",
    "            pop, pareto_fronts = toolbox.select(feasible_pop, POPSIZE)\n",
    "            # ensembles = pareto_fronts[0]  # pareto_first_front\n",
    "            ensembles = pop  # pop均为可行解，则集成pop中所有个体\n",
    "        elif len(feasible_pop) > 0:\n",
    "            pop = feasible_pop + infeasible_pop[:POPSIZE - len(feasible_pop)]  # 在不可行解中选取违约程度小的个体，保证pop数量为POPSIZE\n",
    "            # ensembles = tools.sortNondominated(feasible_pop, len(feasible_pop))[0]  # pareto_first_front\n",
    "            ensembles = feasible_pop  # 只集成可行解\n",
    "            # ensembles = pop  # 集成种群\n",
    "        else:\n",
    "            pop = feasible_pop + infeasible_pop[:POPSIZE - len(feasible_pop)]  # 加入不可行解中违约程度小的个体，保证pop数量为POPSIZE\n",
    "            ensembles = [infeasible_pop[0]]  # 没有可行解，集成不可行解中第一个个体\n",
    "            # ensembles = pop  # 集成种群\n",
    "        avg_gmean, avg_mauc = calculate_average_gmean_mauc(ensembles)  # 计算gmean、mauc的平均值\n",
    "        _, avg_acc2, _ = calculate_average_accuracy(ensembles)  # 计算acc1、acc2、acc3的平均值\n",
    "\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=gen, feasible=len(feasible_pop), ensembles_size=len(ensembles), avg_gmean=avg_gmean,\n",
    "                       avg_mauc=avg_mauc, avg_acc2=avg_acc2, **record)\n",
    "        # print(logbook.stream)\n",
    "    ensemble_classifiers = ensemble_individuals(ensembles, model, x_train, y_train)\n",
    "    return ensemble_classifiers\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"*****************算法开始执行：******************\")\n",
    "    num_run = 40  # 运行次数\n",
    "    ensembles_results = [[] for _ in range(num_run)]\n",
    "    for i in range(num_run):\n",
    "        ensemble_classifiers = main(x_train, y_train, model=model, balanced_method='random')\n",
    "        vote_pred_prob = vote_result_ensembles(ensemble_classifiers, x_test)  # 默认预测结果是软标签\n",
    "        vote_pred = np.argmax(vote_pred_prob, axis=1)\n",
    "        gmean, mauc, recall_per_class = calculate_gmean_mauc(vote_pred_prob, y_test)\n",
    "        acc1, acc2, acc3 = calculate_accuracy(vote_pred, y_test, weights_test)\n",
    "        ensembles_results[i] = [gmean, mauc, acc1, acc2, acc3, len(ensemble_classifiers)]\n",
    "        print(\n",
    "            f\"第{i + 1}次执行：Gmean：{gmean}，mAUC：{mauc}，Acc1：{acc1}，Acc2：{acc2}，Acc3：{acc3}，集成的数量：{len(ensemble_classifiers)}\")\n",
    "    print(\"*****************算法执行结束！******************\")\n",
    "    ensembles_result_mean = np.mean(ensembles_results, axis=0)\n",
    "    print(f'集成分类结果（平均值）：{ensembles_result_mean}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-13T19:33:49.976044Z",
     "start_time": "2025-04-13T14:20:00.677973Z"
    }
   },
   "id": "ec2997db669640b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************算法开始执行：******************\n",
      "第1次执行：Gmean：0.870394，mAUC：0.967721，Acc1：0.878788，Acc2：0.870813，Acc3：0.288193，集成的数量：30\n",
      "第2次执行：Gmean：0.857739，mAUC：0.967103，Acc1：0.869383，Acc2：0.858548，Acc3：0.283359，集成的数量：30\n",
      "第3次执行：Gmean：0.866842，mAUC：0.967006，Acc1：0.874608，Acc2：0.867352，Acc3：0.287226，集成的数量：30\n",
      "第4次执行：Gmean：0.863247，mAUC：0.967821，Acc1：0.871473，Acc2：0.863783，Acc3：0.285923，集成的数量：30\n",
      "第5次执行：Gmean：0.851415，mAUC：0.96902，Acc1：0.864159，Acc2：0.852081，Acc3：0.280879，集成的数量：30\n",
      "第6次执行：Gmean：0.854376，mAUC：0.965801，Acc1：0.868339，Acc2：0.855542，Acc3：0.281846，集成的数量：30\n",
      "第7次执行：Gmean：0.863905，mAUC：0.967277，Acc1：0.871473，Acc2：0.864561，Acc3：0.286386，集成的数量：30\n",
      "第8次执行：Gmean：0.878154，mAUC：0.965633，Acc1：0.886102，Acc2：0.878622，Acc3：0.290925，集成的数量：30\n",
      "第9次执行：Gmean：0.865629，mAUC：0.9668，Acc1：0.872518，Acc2：0.866011，Acc3：0.286974，集成的数量：30\n",
      "第10次执行：Gmean：0.860955，mAUC：0.965463，Acc1：0.871473，Acc2：0.861447，Acc3：0.284536，集成的数量：30\n",
      "第11次执行：Gmean：0.864181，mAUC：0.965612，Acc1：0.873563，Acc2：0.865124，Acc3：0.286175，集成的数量：30\n",
      "第12次执行：Gmean：0.853374，mAUC：0.967414，Acc1：0.865204，Acc2：0.854308，Acc3：0.28193，集成的数量：30\n",
      "第13次执行：Gmean：0.862036，mAUC：0.966003，Acc1：0.869383，Acc2：0.862441，Acc3：0.285671，集成的数量：30\n",
      "第14次执行：Gmean：0.870984，mAUC：0.968213，Acc1：0.878788，Acc2：0.871592，Acc3：0.288655，集成的数量：30\n",
      "第15次执行：Gmean：0.874421，mAUC：0.971073，Acc1：0.884013，Acc2：0.874945，Acc3：0.289285，集成的数量：30\n",
      "第16次执行：Gmean：0.874764，mAUC：0.967935，Acc1：0.876698，Acc2：0.874922，Acc3：0.291178，集成的数量：30\n",
      "第17次执行：Gmean：0.865567，mAUC：0.967616，Acc1：0.873563，Acc2：0.865903，Acc3：0.286638，集成的数量：30\n",
      "第18次执行：Gmean：0.854275，mAUC：0.964513，Acc1：0.865204，Acc2：0.855087，Acc3：0.282392，集成的数量：30\n",
      "第19次执行：Gmean：0.864318，mAUC：0.967356，Acc1：0.871473，Acc2：0.864561，Acc3：0.286386，集成的数量：30\n",
      "第20次执行：Gmean：0.870726，mAUC：0.967561，Acc1：0.876698，Acc2：0.871029，Acc3：0.288866，集成的数量：30\n",
      "第21次执行：Gmean：0.860725，mAUC：0.96724，Acc1：0.872518，Acc2：0.861339，Acc3：0.284199，集成的数量：30\n",
      "第22次执行：Gmean：0.872606，mAUC：0.966968，Acc1：0.879833，Acc2：0.873041，Acc3：0.289244，集成的数量：30\n",
      "第23次执行：Gmean：0.868685，mAUC：0.96978，Acc1：0.877743，Acc2：0.869364，Acc3：0.287604，集成的数量：30\n",
      "第24次执行：Gmean：0.848104，mAUC：0.966915，Acc1：0.863114，Acc2：0.849074，Acc3：0.279366，集成的数量：30\n",
      "第25次执行：Gmean：0.864065，mAUC：0.965228，Acc1：0.874608，Acc2：0.865016，Acc3：0.285839，集成的数量：30\n",
      "第26次执行：Gmean：0.864838，mAUC：0.967903，Acc1：0.875653，Acc2：0.865687，Acc3：0.285965，集成的数量：30\n",
      "第27次执行：Gmean：0.871962，mAUC：0.969727，Acc1：0.877743，Acc2：0.872478，Acc3：0.289454，集成的数量：30\n",
      "第28次执行：Gmean：0.865282，mAUC：0.969362，Acc1：0.874608，Acc2：0.865795，Acc3：0.286301，集成的数量：30\n",
      "第29次执行：Gmean：0.865319，mAUC：0.966295，Acc1：0.873563，Acc2：0.865903，Acc3：0.286638，集成的数量：30\n",
      "第30次执行：Gmean：0.862892，mAUC：0.966907，Acc1：0.869383，Acc2：0.86322，Acc3：0.286134，集成的数量：30\n",
      "第31次执行：Gmean：0.857987，mAUC：0.967347，Acc1：0.870428，Acc2：0.859219，Acc3：0.283485，集成的数量：30\n",
      "第32次执行：Gmean：0.87096，mAUC：0.968746，Acc1：0.879833，Acc2：0.871484，Acc3：0.288319，集成的数量：30\n",
      "第33次执行：Gmean：0.874771，mAUC：0.967409，Acc1：0.881923，Acc2：0.875161，Acc3：0.289958，集成的数量：30\n",
      "第34次执行：Gmean：0.867718，mAUC：0.968033，Acc1：0.875653，Acc2：0.868023，Acc3：0.287352，集成的数量：30\n",
      "第35次执行：Gmean：0.868152，mAUC：0.967931，Acc1：0.875653，Acc2：0.868801，Acc3：0.287815，集成的数量：30\n",
      "第36次执行：Gmean：0.861294，mAUC：0.967566，Acc1：0.868339，Acc2：0.861771，Acc3：0.285545，集成的数量：30\n",
      "第37次执行：Gmean：0.863733，mAUC：0.967836，Acc1：0.870428，Acc2：0.863891，Acc3：0.28626，集成的数量：30\n",
      "第38次执行：Gmean：0.865191，mAUC：0.968079，Acc1：0.874608，Acc2：0.865795，Acc3：0.286301，集成的数量：30\n",
      "第39次执行：Gmean：0.873037，mAUC：0.967654，Acc1：0.881923，Acc2：0.873604，Acc3：0.289033，集成的数量：30\n",
      "第40次执行：Gmean：0.866376，mAUC：0.969163，Acc1：0.876698，Acc2：0.867136，Acc3：0.286553，集成的数量：30\n",
      "*****************算法执行结束！******************\n",
      "集成分类结果（平均值）：[ 0.86502498  0.96747575  0.87392888  0.86561185  0.2863697  30.        ]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 写入到Excel "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed4dbb395903bfa7"
  },
  {
   "cell_type": "code",
   "source": [
    "from utils.excel_utils import save_to_excel_2\n",
    "\n",
    "columns = ['Gmean', 'MAUC', 'Acc1', 'Acc2', 'Acc3', 'num_ensemble']\n",
    "\n",
    "save_path = 'C:/Users/zsc/Desktop/Third/Stratified/7-3/MILE/' + datasetname + '/'\n",
    "filename = datasetname\n",
    "save_to_excel_2(save_path, filename, columns, ensembles_results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-13T19:33:53.621544Z",
     "start_time": "2025-04-13T19:33:49.981359Z"
    }
   },
   "id": "520fa2429669bb3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel 文件已保存至: C:/Users/zsc/Desktop/Third/Stratified/7-3/MILE/Splice/Splice.xlsx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:/Users/zsc/Desktop/Third/Stratified/7-3/MILE/Splice/Splice.xlsx'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
