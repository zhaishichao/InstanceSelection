{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# E-MOSAIC\n",
    "\n",
    "引用自[E. R. Q. Fernandes, A. C. P. L. F. de Carvalho and X. Yao, \"Ensemble of Classifiers Based on Multiobjective Genetic Sampling for Imbalanced Data,\" in IEEE Transactions on Knowledge and Data Engineering, vol. 32, no. 6, pp. 1104-1115, 1 June 2020, doi: 10.1109/TKDE.2019.2898861.]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8825cc0902bf4ba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据集的预处理 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a36fc2d4930535ec"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################加载数据集#########################\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/dataset/Satellite.mat'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:39\u001B[0m, in \u001B[0;36m_open_file\u001B[1;34m(file_like, appendmat, mode)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 39\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfile_like\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;66;03m# Probably \"not found\"\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../../data/dataset/Satellite.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 17\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# 数据集\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# Nursery(0.1)、Satellite(0.001)、Contraceptive(0.1)\u001B[39;00m\n\u001B[0;32m     16\u001B[0m datasetname \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSatellite.mat\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m---> 17\u001B[0m mat_data \u001B[38;5;241m=\u001B[39m \u001B[43msio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloadmat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../../data/dataset/\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdatasetname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m dataset_x \u001B[38;5;241m=\u001B[39m mat_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     20\u001B[0m dataset_y \u001B[38;5;241m=\u001B[39m mat_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mY\u001B[39m\u001B[38;5;124m'\u001B[39m][:, \u001B[38;5;241m0\u001B[39m]  \u001B[38;5;66;03m# mat_data['Y']得到的形状为[n,1]，通过[:,0]，得到形状[n,]\u001B[39;00m\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:225\u001B[0m, in \u001B[0;36mloadmat\u001B[1;34m(file_name, mdict, appendmat, **kwargs)\u001B[0m\n\u001B[0;32m     88\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     89\u001B[0m \u001B[38;5;124;03mLoad MATLAB file.\u001B[39;00m\n\u001B[0;32m     90\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;124;03m    3.14159265+3.14159265j])\u001B[39;00m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    224\u001B[0m variable_names \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvariable_names\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m--> 225\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _open_file_context(file_name, appendmat) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m    226\u001B[0m     MR, _ \u001B[38;5;241m=\u001B[39m mat_reader_factory(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    227\u001B[0m     matfile_dict \u001B[38;5;241m=\u001B[39m MR\u001B[38;5;241m.\u001B[39mget_variables(variable_names)\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\contextlib.py:119\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__enter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwds, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerator didn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt yield\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:17\u001B[0m, in \u001B[0;36m_open_file_context\u001B[1;34m(file_like, appendmat, mode)\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;129m@contextmanager\u001B[39m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_context\u001B[39m(file_like, appendmat, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m---> 17\u001B[0m     f, opened \u001B[38;5;241m=\u001B[39m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_like\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mappendmat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     19\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m f\n",
      "File \u001B[1;32mD:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:45\u001B[0m, in \u001B[0;36m_open_file\u001B[1;34m(file_like, appendmat, mode)\u001B[0m\n\u001B[0;32m     43\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m appendmat \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m file_like\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.mat\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m     44\u001B[0m         file_like \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.mat\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m---> 45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfile_like\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     47\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\n\u001B[0;32m     48\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mReader needs file name or open file-like object\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     49\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../../data/dataset/Satellite.mat'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from utils.dataset_utils import get_classes_indexes_counts\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 随机种子\n",
    "random_seed = 42\n",
    "print(\"#########################加载数据集#########################\")\n",
    "# 数据集\n",
    "# Nursery(0.1)、Satellite(0.001)、Contraceptive(0.1)\n",
    "datasetname = 'Satellite.mat'\n",
    "mat_data = sio.loadmat('../../data/dataset/' + datasetname)\n",
    "\n",
    "dataset_x = mat_data['X']\n",
    "dataset_y = mat_data['Y'][:, 0]  # mat_data['Y']得到的形状为[n,1]，通过[:,0]，得到形状[n,]\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", dataset_x.shape)\n",
    "print(\"label:\", dataset_y.shape)\n",
    "# 统计每个类别的个数\n",
    "classes, counts = get_classes_indexes_counts(dataset_y)  #np.argmax(y_onehot, axis=1)找最大值的索引，将0-1序列转化为0,1,2,3......的整数标签\n",
    "print(\"每种类别的分布：\", counts)\n",
    "print(\"#########################划分数据集#########################\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset_x, dataset_y, test_size=0.3, random_state=random_seed)\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", x_train.shape)\n",
    "print(\"label:\", y_train.shape)\n",
    "# 统计每个类别的个数 \n",
    "classes_train, counts_train = get_classes_indexes_counts(y_train)\n",
    "# 计算每个类的权重\n",
    "weights_train = (1 / counts_train.astype(float)) / np.sum(1 / counts_train.astype(float))\n",
    "print(\"训练集每种类别的分布：\", counts_train)\n",
    "print(\"训练集每种类别的权重：\", weights_train)\n",
    "classes_test, counts_test = get_classes_indexes_counts(y_test)\n",
    "print(\"测试集每种类别的分布：\", counts_test)\n",
    "print(\"#########################平衡数据集#########################\")\n",
    "# 确定每个类别的分布\n",
    "num_instances = int(counts_train.min() * 1.0)  # 向下取整\n",
    "num_instances_train = len(y_train)  # 取训练集的数量\n",
    "\n",
    "print(\"最小数量:\", num_instances)\n",
    "# 在每个类别中随机的选择该数量的实例的索引\n",
    "balanced_classes = np.array([])\n",
    "for indexes in classes_train:\n",
    "    random_selecte_indices = np.random.choice(indexes, size=num_instances, replace=False)\n",
    "    balanced_classes = np.hstack((balanced_classes, random_selecte_indices))\n",
    "balanced_classes = np.sort(balanced_classes).astype(int)\n",
    "# 得到平衡的数据集\n",
    "balanced_dataset_x = []\n",
    "balanced_dataset_y = []\n",
    "for index in balanced_classes:\n",
    "    balanced_dataset_x.append(x_train[index])\n",
    "    balanced_dataset_y.append(y_train[index])\n",
    "balanced_dataset_x = np.array(balanced_dataset_x)\n",
    "balanced_dataset_y = np.array(balanced_dataset_y).astype(int)\n",
    "# 显示数据集分布\n",
    "print(\"平衡的数据集的特征数据:\", balanced_dataset_x.shape)\n",
    "print(\"label:\", balanced_dataset_y.shape)\n",
    "# 统计每个类别的分布\n",
    "classes_balanced_dataset, counts_balanced_dataset = get_classes_indexes_counts(balanced_dataset_y)\n",
    "print(\"平衡的数据集中每种类别的分布：\", counts_balanced_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-09T11:18:38.490825Z",
     "start_time": "2024-12-09T11:18:37.634771Z"
    }
   },
   "id": "abb6e4d62d32f110",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 评价函数\n",
    "（Acc1、Acc2、Acc3）\n",
    "Acc1、Acc2是实例选择选了多少，S就是多少；而Acc3是划分完数据集之后，每个类的数量作为si"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df0310c8b3d57eb3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.stats import gmean\n",
    "from sklearn.metrics import precision_score, roc_auc_score, accuracy_score\n",
    "from scipy.stats import mode\n",
    "\n",
    "\n",
    "##########################适应度函数（Acc1,Acc2,Acc3）#################################\n",
    "def fitness_function(individual):\n",
    "    # 使用训练数据进行预测\n",
    "    y_sub, ind_pred = individual.y_sub_and_pred[0], individual.y_sub_and_pred[1]  # 获取个体的实例选择标签和预测标签\n",
    "    ######################计算混淆矩阵#########################\n",
    "    cm = confusion_matrix(y_sub, ind_pred)\n",
    "    tp_per_class = cm.diagonal()  # 对角线元素表示每个类预测正确的个数，对角线求和，即所有预测正确的实例个数之和，计算Acc1\n",
    "    s_per_class = cm.sum(axis=1)\n",
    "    Acc1 = np.sum(tp_per_class) / np.sum(s_per_class)  # Acc1\n",
    "    Acc2 = np.mean(tp_per_class.astype(float) / s_per_class.astype(float))  # Acc2\n",
    "    Acc3 = np.mean((tp_per_class.astype(float) / s_per_class.astype(float)) * weights_train)  # Acc3\n",
    "    return round(Acc1, 4), round(Acc2, 4), round(Acc3, 4)\n",
    "\n",
    "\n",
    "# 集成分类器的投票\n",
    "def vote_ensembles(ensembles, show_result=False):\n",
    "    y_pred_labels_ensembles = []\n",
    "    y_pred_prob_labels_ensembles = []\n",
    "    for ensemble in ensembles:\n",
    "        ind_pred = ensemble.predict(x_test)  # 计算accuracy、PPV\n",
    "        ind_proba = ensemble.predict_proba(x_test)\n",
    "        y_pred_labels_ensembles.append(ind_pred)\n",
    "        y_pred_prob_labels_ensembles.append(ind_proba)\n",
    "    # 按列投票，取每列中出现次数最多的类别作为最终分类结果\n",
    "    final_pred_result = mode(y_pred_labels_ensembles, axis=0, keepdims=False).mode.flatten()\n",
    "    # 堆叠为三维数组\n",
    "    stacked_predictions_prob = np.stack(y_pred_prob_labels_ensembles, axis=0)\n",
    "    # 对第一个维度 (num_classifiers) 求平均\n",
    "    ensemble_predictions_prob = np.mean(stacked_predictions_prob, axis=0)\n",
    "    # 计算 ROC AUC（ovo+macro）\n",
    "    auc_ovo_macro = roc_auc_score(y_test, ensemble_predictions_prob, multi_class=\"ovo\", average=\"macro\")\n",
    "    cm = confusion_matrix(y_test, final_pred_result)\n",
    "    # 计算每类召回率（每类正确预测个数 / 该类总数）\n",
    "    recall_per_class = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "    # 计算G-Mean\n",
    "    geometric_mean = gmean(recall_per_class)\n",
    "    # 计算准确率\n",
    "    accuracy = accuracy_score(y_test, final_pred_result)\n",
    "    if show_result:\n",
    "        print(f'Accuracy: {accuracy:.2f}')\n",
    "        # 打印分类报告\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, final_pred_result))\n",
    "        # 打印混淆矩阵\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_test, final_pred_result))\n",
    "    return round(geometric_mean, 4), round(auc_ovo_macro, 4), np.array(\n",
    "        [\"{:.4f}\".format(x) for x in recall_per_class]).tolist()  # 保留六位小数"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-09T11:18:38.490825Z"
    }
   },
   "id": "42403853ade4c910",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NSGA-II"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bb11017ee1ef86"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from instance_selection.multi_objective.genetic_operator import selNSGA2, mutate_binary_inversion, selTournamentDCD, \\\n",
    "    exponential_distribution, find_duplicates, remove_duplicates\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # 忽略警告\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import array\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "\n",
    "# 最大化评价目标\n",
    "creator.create(\"FitnessMaxAndMax\", base.Fitness, weights=(1.0, 1.0, 1.0))\n",
    "'''\n",
    "fitness:适应度：Gmean和mAUC\n",
    "pfc：每个分类器的成对故障信用，用于评估分类器集合的多样性\n",
    "'''\n",
    "creator.create(\"Individual\", array.array, typecode='i', fitness=creator.FitnessMaxAndMax, pfc=None, mlp=None,\n",
    "               y_sub_and_pred=None)\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "NDIM = num_instances_train\n",
    "# 设置参数\n",
    "lambda_ = 1.3  # 指数分布的参数λ（lambda）在下面的函数中，该值越大越偏向于1\n",
    "threshold = 1.0  # 阈值（阈值决定了生成0或1）\n",
    "\n",
    "# 二进制编码\n",
    "toolbox.register(\"attr_binary\", exponential_distribution, lambda_, threshold)  # 0-1编码\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_binary, n=num_instances)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# 适应度函数\n",
    "toolbox.register(\"evaluate\", fitness_function, weights_train=weights_train)\n",
    "\n",
    "# 单点交叉\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "\n",
    "# 二进制突变\n",
    "toolbox.register(\"mutate\", mutate_binary_inversion)\n",
    "\n",
    "# NSGA-II选择（非支配排序后）\n",
    "toolbox.register(\"select\", selNSGA2, x_test=x_test, y_test=y_test)\n",
    "# toolbox.register(\"select\", tools.selNSGA2)\n",
    "\n",
    "# 找到种群中重复个体的索引对\n",
    "toolbox.register(\"find_duplicates\", find_duplicates)\n",
    "\n",
    "# 去重\n",
    "toolbox.register(\"remove_duplicates\", remove_duplicates)\n",
    "\n",
    "\n",
    "# 运行NSGA-II算法并绘图\n",
    "def plot_pareto(pareto_fronts, ax):\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(pareto_fronts)))\n",
    "    for i, front in enumerate(pareto_fronts):\n",
    "        front_points = np.array([ind.fitness.values for ind in front])\n",
    "        ax.scatter(front_points[:, 0], front_points[:, 1], front_points[:, 2], label=f\"Front {i}\", color=colors[i])\n",
    "\n",
    "\n",
    "# Step 2: 动画绘图函数\n",
    "fig = plt.figure(figsize=(12.8, 9.6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# 动画中的数据\n",
    "pareto_fronts_history = []\n",
    "\n",
    "\n",
    "def update(frame):\n",
    "    ax.clear()\n",
    "\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(pareto_fronts_history[frame])))\n",
    "\n",
    "    for i, front in enumerate(pareto_fronts_history[frame]):\n",
    "        front_points = np.array([ind.fitness.values for ind in front])\n",
    "        ax.scatter(front_points[:, 0], front_points[:, 1], front_points[:, 2], color=colors[i], label=f\"Front {i}\")\n",
    "    ax.set_title(f\"Generation {frame}\")\n",
    "    ax.set_xlabel(\"Acc 1\")\n",
    "    ax.set_ylabel(\"Acc 2\")\n",
    "    ax.set_zlabel(\"Acc 3\")\n",
    "    # ticks = np.linspace(0, 1, 10)\n",
    "    # ax.set_xticks(ticks)\n",
    "    # ax.set_yticks(ticks)\n",
    "    # ax.set_zticks(ticks)\n",
    "    ax.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-09T11:18:38.491858Z"
    }
   },
   "id": "f286b798f84564ae",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 种群的迭代"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3af0218c1c802bf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from utils.dataset_utils import get_subset\n",
    "\n",
    "\n",
    "def main(seed=None):\n",
    "    random.seed(seed)\n",
    "\n",
    "    NGEN = 30  # 迭代次数\n",
    "    POPSIZE = 40  # 种群数量\n",
    "    CXPB = 1.0  # 交叉因子/交叉率\n",
    "    MR = 0.25  # 突变因子/突变率\n",
    "    # MLP\n",
    "    learning_rate = 0.001\n",
    "    hidden_size = 20\n",
    "    max_iter = 1000\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # 配置五折交叉验证\n",
    "\n",
    "    ####################################迭代过程的记录#############################\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = \"gen\", \"fronts\", \"fronts_0_size\", \"Acc1\", \"Acc2\", \"Acc3\", \"recall_per_class\", \"Gmean\", \"mAUC\"\n",
    "    ####################################种群的初始化###########################\n",
    "    pop = toolbox.population(n=POPSIZE)\n",
    "    ####################################计算初始种群的适应度###########################\n",
    "    stop_sign = 0\n",
    "    ensembles = []  # 当前每个个体对应的mlp模型\n",
    "    # 对于每个个体都训练得到一个mlp模型\n",
    "    for i in range(len(pop)):\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(hidden_size,), max_iter=max_iter, random_state=random_seed,\n",
    "                            learning_rate_init=learning_rate)\n",
    "        x_sub, y_sub = get_subset(pop[i], x_train, y_train)\n",
    "        # 使用 cross_val_predict 进行交叉验证并获取结果\n",
    "        y_pred = cross_val_predict(mlp, x_sub, y_sub, cv=cv)\n",
    "        # 用实例选择的子集训练模型\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(hidden_size,), max_iter=max_iter, random_state=random_seed,\n",
    "                            learning_rate_init=learning_rate)\n",
    "        mlp.fit(x_sub, y_sub)\n",
    "        pop[i].mlp = mlp\n",
    "        pop[i].y_sub_and_pred = (y_sub, y_pred)\n",
    "    # 由mlp模型得到个体的适应度\n",
    "    for i in range(len(pop)):\n",
    "        pop[i].fitness.values = toolbox.evaluate(pop[i])\n",
    "    #################################计算PFC并进行非支配排序#########################################\n",
    "    # 计算PFC并进行非支配排序 PFC代替拥挤距离\n",
    "    pop, pareto_fronts = toolbox.select(pop, len(pop))\n",
    "    ####################################种群的迭代#################################################\n",
    "    for gen in range(1, NGEN + 1):\n",
    "        # 选择\n",
    "        offspring = selTournamentDCD(pop, POPSIZE)\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "        # 交叉\n",
    "        for i in range(0, len(offspring) - 1, 2):\n",
    "            if random.random() <= CXPB:\n",
    "                offspring[i], offspring[i + 1] = toolbox.mate(offspring[i], offspring[i + 1])\n",
    "            # 突变\n",
    "            offspring[i] = toolbox.mutate(offspring[i], MR)[0]\n",
    "            offspring[i + 1] = toolbox.mutate(offspring[i + 1], MR)[0]\n",
    "            del offspring[i].fitness.values, offspring[i + 1].fitness.values\n",
    "        # 计算新的种群适应度 \n",
    "        for i in range(len(offspring)):\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=(hidden_size,), max_iter=max_iter, random_state=random_seed,\n",
    "                                learning_rate_init=learning_rate)\n",
    "            x_sub, y_sub = get_subset(offspring[i], x_train, y_train)\n",
    "            # 使用 cross_val_predict 进行交叉验证并获取预测\n",
    "            y_pred = cross_val_predict(mlp, x_sub, y_sub, cv=cv)\n",
    "            # 用实例选择的子集训练模型\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=(hidden_size,), max_iter=max_iter, random_state=random_seed,\n",
    "                                learning_rate_init=learning_rate)\n",
    "            mlp.fit(x_sub, y_sub)\n",
    "            offspring[i].mlp = mlp\n",
    "            offspring[i].y_sub_and_pred = (y_sub, y_pred)\n",
    "        for i in range(len(offspring)):\n",
    "            offspring[i].fitness.values = toolbox.evaluate(offspring[i])\n",
    "        # 种群的合并\n",
    "        pop = pop + offspring\n",
    "        ###############################################得到pareto_fronts############################################\n",
    "        pop, pareto_fronts = toolbox.select(pop, POPSIZE)\n",
    "        #pop, pareto_fronts = toolbox.select(pop, POPSIZE)\n",
    "        record = stats.compile(pop)\n",
    "        # 保存第一个等级里的mlp模型进行集成\n",
    "        for ind in pareto_fronts[0]:\n",
    "            ensembles.clear()\n",
    "            ensembles.append(ind.mlp)\n",
    "        Acc1_list = []\n",
    "        Acc2_list = []\n",
    "        Acc3_list = []\n",
    "        for ind in pareto_fronts[0]:\n",
    "            Acc1_list.append(ind.fitness.values[0])\n",
    "            Acc2_list.append(ind.fitness.values[1])\n",
    "            Acc3_list.append(ind.fitness.values[2])\n",
    "        # 求Acc1_list、Acc2_list、Acc3_list的平均值\n",
    "        Acc1_mean = round(sum(Acc1_list) / len(Acc1_list), 4)\n",
    "        Acc2_mean = round(sum(Acc2_list) / len(Acc2_list), 4)\n",
    "        Acc3_mean = round(sum(Acc3_list) / len(Acc3_list), 4)\n",
    "\n",
    "        g_mean, m_auc, recall_per_class = vote_ensembles(ensembles, x_test, y_test)\n",
    "        logbook.record(gen=gen, fronts=len(pareto_fronts), fronts_0_size=len(pareto_fronts[0]),\n",
    "                       Acc1=Acc1_mean, Acc2=Acc2_mean, Acc3=Acc3_mean, recall_per_class=recall_per_class, Gmean=g_mean,\n",
    "                       mAUC=m_auc,\n",
    "                       **record)\n",
    "        print(logbook.stream)\n",
    "        # 清除并绘制当前一代的 Pareto-front\n",
    "        pareto_fronts_history.append(pareto_fronts)\n",
    "\n",
    "    # 使用 FuncAnimation 生成动画\n",
    "    savepath = \"C:/Users/sc_zh/Desktop/\"\n",
    "    writer = PillowWriter(fps=1)  # 设置帧率\n",
    "    anim = FuncAnimation(fig, update, frames=len(pareto_fronts_history), interval=200)\n",
    "    anim.save(savepath + datasetname + \"_pareto_front.gif\", writer=writer)\n",
    "    plt.show()\n",
    "    return pop, stats, ensembles\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pop, stats, ensembles = main()\n",
    "    print(\"##############################集成分类器的预测结果：################################\")\n",
    "    g_mean, m_auc, recall_per_class = vote_ensembles(ensembles, x_test, y_test, show_result=True)\n",
    "    print(f\"最终的集成分类结果：Recall_Per_Class{recall_per_class}，Gmean：{g_mean}，mAUC：{m_auc}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-09T11:18:38.492874Z"
    }
   },
   "id": "e8deac9b0ca9c40b",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
