{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# E-MOSAIC\n",
    "\n",
    "引用自[E. R. Q. Fernandes, A. C. P. L. F. de Carvalho and X. Yao, \"Ensemble of Classifiers Based on Multiobjective Genetic Sampling for Imbalanced Data,\" in IEEE Transactions on Knowledge and Data Engineering, vol. 32, no. 6, pp. 1104-1115, 1 June 2020, doi: 10.1109/TKDE.2019.2898861.]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8825cc0902bf4ba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据集的预处理 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a36fc2d4930535ec"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.dataset_utils import get_classes_indexes_counts\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 随机种子\n",
    "random_seed = 42\n",
    "print(\"#########################加载数据集#########################\")\n",
    "# 数据集\n",
    "# Nursery(0.1)、Satellite(0.001)、Contraceptive(0.1)\n",
    "datasetname = 'Satellite.mat'\n",
    "mat_data = sio.loadmat('../../data/dataset/' + datasetname)\n",
    "\n",
    "dataset_x = mat_data['X']\n",
    "dataset_y = mat_data['Y'][:, 0]  # mat_data['Y']得到的形状为[n,1]，通过[:,0]，得到形状[n,]\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", dataset_x.shape, \"label:\", dataset_y.shape)\n",
    "# 统计每个类别的个数\n",
    "classes, counts = get_classes_indexes_counts(dataset_y)  #np.argmax(y_onehot, axis=1)找最大值的索引，将0-1序列转化为0,1,2,3......的整数标签\n",
    "print(\"每种类别的分布：\", counts)\n",
    "print(\"#########################划分数据集#########################\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset_x, dataset_y, test_size=0.3, random_state=random_seed)\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", x_train.shape, \"label:\", y_train.shape)\n",
    "# 统计每个类别的个数 \n",
    "classes_train, counts_train = get_classes_indexes_counts(y_train)\n",
    "# 计算每个类的权重\n",
    "weights_train = (1 / counts_train.astype(float)) / np.sum(1 / counts_train.astype(float))\n",
    "print(\"训练集每种类别的分布：\", counts_train)\n",
    "print(\"训练集每种类别的权重：\", weights_train)\n",
    "classes_test, counts_test = get_classes_indexes_counts(y_test)\n",
    "print(\"测试集每种类别的分布：\", counts_test)\n",
    "print(\"#########################平衡数据集#########################\")\n",
    "# 确定每个类别的分布\n",
    "num_instances = int(counts_train.min() * 1.0)  # 向下取整\n",
    "num_instances_train = len(y_train)  # 取训练集的数量\n",
    "\n",
    "print(\"最小数量:\", num_instances)\n",
    "# 在每个类别中随机的选择该数量的实例的索引\n",
    "balanced_classes = np.array([])\n",
    "for indexes in classes_train:\n",
    "    random_selecte_indices = np.random.choice(indexes, size=num_instances, replace=False)\n",
    "    balanced_classes = np.hstack((balanced_classes, random_selecte_indices))\n",
    "balanced_classes = np.sort(balanced_classes).astype(int)\n",
    "# 得到平衡的数据集\n",
    "balanced_dataset_x = []\n",
    "balanced_dataset_y = []\n",
    "for index in balanced_classes:\n",
    "    balanced_dataset_x.append(x_train[index])\n",
    "    balanced_dataset_y.append(y_train[index])\n",
    "balanced_dataset_x = np.array(balanced_dataset_x)\n",
    "balanced_dataset_y = np.array(balanced_dataset_y).astype(int)\n",
    "# 显示数据集分布\n",
    "print(\"平衡的数据集的特征数据:\", balanced_dataset_x.shape)\n",
    "print(\"label:\", balanced_dataset_y.shape)\n",
    "# 统计每个类别的分布\n",
    "classes_balanced_dataset, counts_balanced_dataset = get_classes_indexes_counts(balanced_dataset_y)\n",
    "print(\"平衡的数据集中每种类别的分布：\", counts_balanced_dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abb6e4d62d32f110",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NSGA-II"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bb11017ee1ef86"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from instance_selection.multi_objective.genetic_operator import selNSGA2, mutate_binary_inversion, selTournamentDCD, \\\n",
    "    exponential_distribution, find_duplicates, remove_duplicates, fitness_function\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # 忽略警告\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import array\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "\n",
    "# 最大化评价目标\n",
    "creator.create(\"FitnessMaxAndMax\", base.Fitness, weights=(1.0, 1.0, 1.0))\n",
    "creator.create(\"Individual\", array.array, typecode='i', fitness=creator.FitnessMaxAndMax, pfc=None, mlp=None,\n",
    "               y_sub_and_pred=None)\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "NDIM = num_instances_train\n",
    "# 设置参数\n",
    "lambda_ = 1.5  # 指数分布的参数λ（lambda）在下面的函数中，该值越大越偏向于1\n",
    "threshold = 1.0  # 阈值（阈值决定了生成0或1）\n",
    "\n",
    "# 二进制编码\n",
    "toolbox.register(\"attr_binary\", exponential_distribution, lambda_, threshold)  # 0-1编码\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_binary, n=num_instances)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# 适应度函数\n",
    "toolbox.register(\"evaluate\", fitness_function, weights_train=weights_train)\n",
    "\n",
    "# 单点交叉\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "\n",
    "# 二进制突变\n",
    "toolbox.register(\"mutate\", mutate_binary_inversion)\n",
    "\n",
    "# NSGA-II选择（非支配排序后）\n",
    "toolbox.register(\"select\", selNSGA2, x_test=x_test, y_test=y_test)\n",
    "# toolbox.register(\"select\", tools.selNSGA2)\n",
    "\n",
    "# 找到种群中重复个体的索引对\n",
    "toolbox.register(\"find_duplicates\", find_duplicates)\n",
    "\n",
    "# 去重\n",
    "toolbox.register(\"remove_duplicates\", remove_duplicates)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f286b798f84564ae",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 种群的迭代"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3af0218c1c802bf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from instance_selection.multi_objective.ensemble_operator import vote_ensembles\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from utils.dataset_utils import get_subset\n",
    "\n",
    "# Step 2: 动画绘图函数\n",
    "fig = plt.figure(figsize=(12.8, 9.6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# 动画中的数据\n",
    "pareto_fronts_history = []\n",
    "\n",
    "def update(frame):\n",
    "    ax.clear()\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(pareto_fronts_history[frame])))\n",
    "    for i, front in enumerate(pareto_fronts_history[frame]):\n",
    "        front_points = np.array([ind.fitness.values for ind in front])\n",
    "        ax.scatter(front_points[:, 0], front_points[:, 1], front_points[:, 2], color=colors[i], label=f\"Front {i}\")\n",
    "    ax.set_title(f\"Generation {frame}\")\n",
    "    ax.set_xlabel(\"Acc 1\")\n",
    "    ax.set_ylabel(\"Acc 2\")\n",
    "    ax.set_zlabel(\"Acc 3\")\n",
    "    ax.legend()\n",
    "\n",
    "def main(seed=None):\n",
    "    random.seed(seed)\n",
    "\n",
    "    NGEN = 30  # 迭代次数\n",
    "    POPSIZE = 40  # 种群数量\n",
    "    CXPB = 1.0  # 交叉因子/交叉率\n",
    "    MR = 0.25  # 突变因子/突变率\n",
    "    # MLP\n",
    "    learning_rate = 0.001\n",
    "    hidden_size = 20\n",
    "    max_iter = 1000\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # 配置五折交叉验证\n",
    "\n",
    "    ####################################迭代过程的记录#############################\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = \"gen\", \"fronts\", \"fronts_0_size\", \"Acc1\", \"Acc2\", \"Acc3\", \"recall_per_class\", \"Gmean\", \"mAUC\"\n",
    "    ####################################种群的初始化###########################\n",
    "    pop = toolbox.population(n=POPSIZE)\n",
    "    ####################################计算初始种群的适应度###########################\n",
    "    stop_sign = 0\n",
    "    ensembles = []  # 当前每个个体对应的mlp模型\n",
    "    # 对于每个个体都训练得到一个mlp模型\n",
    "    for i in range(len(pop)):\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(hidden_size,), max_iter=max_iter, random_state=random_seed,\n",
    "                            learning_rate_init=learning_rate)\n",
    "        x_sub, y_sub = get_subset(pop[i], x_train, y_train)\n",
    "        # 使用 cross_val_predict 进行交叉验证并获取结果\n",
    "        y_pred = cross_val_predict(mlp, x_sub, y_sub, cv=cv)\n",
    "        # 用实例选择的子集训练模型\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(hidden_size,), max_iter=max_iter, random_state=random_seed,\n",
    "                            learning_rate_init=learning_rate)\n",
    "        mlp.fit(x_sub, y_sub)\n",
    "        pop[i].mlp = mlp\n",
    "        pop[i].y_sub_and_pred = (y_sub, y_pred)\n",
    "    # 由mlp模型得到个体的适应度\n",
    "    for i in range(len(pop)):\n",
    "        pop[i].fitness.values = toolbox.evaluate(pop[i])\n",
    "    #################################计算PFC并进行非支配排序#########################################\n",
    "    # 计算PFC并进行非支配排序 PFC代替拥挤距离\n",
    "    pop, pareto_fronts = toolbox.select(pop, len(pop))\n",
    "    ####################################种群的迭代#################################################\n",
    "    for gen in range(1, NGEN + 1):\n",
    "        # 选择\n",
    "        offspring = selTournamentDCD(pop, POPSIZE)\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "        # 交叉\n",
    "        for i in range(0, len(offspring) - 1, 2):\n",
    "            if random.random() <= CXPB:\n",
    "                offspring[i], offspring[i + 1] = toolbox.mate(offspring[i], offspring[i + 1])\n",
    "            # 突变\n",
    "            offspring[i] = toolbox.mutate(offspring[i], MR)[0]\n",
    "            offspring[i + 1] = toolbox.mutate(offspring[i + 1], MR)[0]\n",
    "            del offspring[i].fitness.values, offspring[i + 1].fitness.values\n",
    "        # 计算新的种群适应度 \n",
    "        for i in range(len(offspring)):\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=(hidden_size,), max_iter=max_iter, random_state=random_seed,\n",
    "                                learning_rate_init=learning_rate)\n",
    "            x_sub, y_sub = get_subset(offspring[i], x_train, y_train)\n",
    "            # 使用 cross_val_predict 进行交叉验证并获取预测\n",
    "            y_pred = cross_val_predict(mlp, x_sub, y_sub, cv=cv)\n",
    "            # 用实例选择的子集训练模型\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=(hidden_size,), max_iter=max_iter, random_state=random_seed,\n",
    "                                learning_rate_init=learning_rate)\n",
    "            mlp.fit(x_sub, y_sub)\n",
    "            offspring[i].mlp = mlp\n",
    "            offspring[i].y_sub_and_pred = (y_sub, y_pred)\n",
    "        for i in range(len(offspring)):\n",
    "            offspring[i].fitness.values = toolbox.evaluate(offspring[i])\n",
    "        # 种群的合并\n",
    "        pop = pop + offspring\n",
    "        ###############################################得到pareto_fronts############################################\n",
    "        pop, pareto_fronts = toolbox.select(pop, POPSIZE)\n",
    "        #pop, pareto_fronts = toolbox.select(pop, POPSIZE)\n",
    "        record = stats.compile(pop)\n",
    "        # 保存第一个等级里的mlp模型进行集成\n",
    "        for ind in pareto_fronts[0]:\n",
    "            ensembles.clear()\n",
    "            ensembles.append(ind.mlp)\n",
    "        Acc1_list = []\n",
    "        Acc2_list = []\n",
    "        Acc3_list = []\n",
    "        for ind in pareto_fronts[0]:\n",
    "            Acc1_list.append(ind.fitness.values[0])\n",
    "            Acc2_list.append(ind.fitness.values[1])\n",
    "            Acc3_list.append(ind.fitness.values[2])\n",
    "        # 求Acc1_list、Acc2_list、Acc3_list的平均值\n",
    "        Acc1_mean = round(sum(Acc1_list) / len(Acc1_list), 4)\n",
    "        Acc2_mean = round(sum(Acc2_list) / len(Acc2_list), 4)\n",
    "        Acc3_mean = round(sum(Acc3_list) / len(Acc3_list), 4)\n",
    "\n",
    "        g_mean, m_auc, recall_per_class = vote_ensembles(ensembles, x_test, y_test)\n",
    "        logbook.record(gen=gen, fronts=len(pareto_fronts), fronts_0_size=len(pareto_fronts[0]),\n",
    "                       Acc1=Acc1_mean, Acc2=Acc2_mean, Acc3=Acc3_mean, recall_per_class=recall_per_class, Gmean=g_mean,\n",
    "                       mAUC=m_auc,\n",
    "                       **record)\n",
    "        print(logbook.stream)\n",
    "        # 清除并绘制当前一代的 Pareto-front\n",
    "        pareto_fronts_history.append(pareto_fronts)\n",
    "\n",
    "    # 使用 FuncAnimation 生成动画\n",
    "    savepath = \"C:/Users/sc_zh/Desktop/\"\n",
    "    writer = PillowWriter(fps=1)  # 设置帧率\n",
    "    anim = FuncAnimation(fig, update, frames=len(pareto_fronts_history), interval=200)\n",
    "    anim.save(savepath + datasetname + \"_pareto_front.gif\", writer=writer)\n",
    "    plt.show()\n",
    "    return pop, stats, ensembles\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pop, stats, ensembles = main()\n",
    "    print(\"##############################集成分类器的预测结果：################################\")\n",
    "    g_mean, m_auc, recall_per_class = vote_ensembles(ensembles, x_test, y_test, show_result=True)\n",
    "    print(f\"最终的集成分类结果：Recall_Per_Class{recall_per_class}，Gmean：{g_mean}，mAUC：{m_auc}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8deac9b0ca9c40b",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
