{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# E-SEIC\n",
    "Selection of evolutionary instances with constraints for unbalanced datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32b99fefdecdec4c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据集的预处理 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a36fc2d4930535ec"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contraceptive distribution: [629 333 511]\n",
      "trainset distribution: [499 262 417]\n",
      "testset distribution: [130  71  94]\n",
      "最小数量: 236\n"
     ]
    }
   ],
   "source": [
    "from utils.dataset_utils import get_distribution, k_fold_cross_validation\n",
    "from instance_selection.parameter.parameter import *  # 导入参数的设定\n",
    "from instance_selection.operator.init_toolbox import init_toolbox_eseic\n",
    "from instance_selection.operator.metrics import calculate_gmean_mauc, calculate_average_accuracy, \\\n",
    "    calculate_average_gmean_mauc, calculate_accuracy\n",
    "from instance_selection.operator.genetic_operator import selTournamentNDCD\n",
    "from instance_selection.operator.ensemble import vote_result_ensembles, ensemble_individuals\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.base import clone\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "import random\n",
    "from deap import tools\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # 忽略警告\n",
    "DATASET = Contraceptive  # 数据集名称（包含对应参数的字典形式）\n",
    "datasetname = DATASET['DATASETNAME'].split('.')[0]\n",
    "mat_data = sio.loadmat('../../data/dataset/' + DATASET['DATASETNAME'])  # 加载、划分数据集\n",
    "x = mat_data['X']\n",
    "y = mat_data['Y'][:, 0]  # mat_data['Y']得到的形状为[n,1]，通过[:,0]，得到形状[n,]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=RANDOM_SEED)  # 划分数据集\n",
    "scaler = StandardScaler()  # 数据的标准化\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "unique_elements_all, classes_all, counts_all = get_distribution(y)  # 获取原始数据集分布\n",
    "unique_elements_train, classes_train, counts_train = get_distribution(y_train)  # 获取训练集分布\n",
    "unique_elements_test, classes_test, counts_test = get_distribution(y_test)  # 获取测试集分布\n",
    "print(datasetname + f' distribution: {counts_all}')\n",
    "print(f'trainset distribution: {counts_train}')\n",
    "print(f'testset distribution: {counts_test}')\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(DATASET['HIDDEN_SIZE'],), max_iter=DATASET['MAX_ITER'],\n",
    "                      random_state=RANDOM_SEED, learning_rate_init=DATASET['LEARNING_RATE'])\n",
    "\n",
    "weights_train = (1 / counts_train.astype(float)) / np.sum(1 / counts_train.astype(float))  # 计算每个类的权重，用于计算每个类别的权重\n",
    "weights_test = (1 / counts_test.astype(float)) / np.sum(1 / counts_test.astype(float))  # 计算每个类的权重，用于计算每个类别的权重\n",
    "\n",
    "num_instances = int(np.ceil(counts_train.min() * 0.9))  # 取最小数量的类的0.9（向下取整）\n",
    "print(\"最小数量:\", num_instances)\n",
    "\n",
    "y_train_pred_proba = k_fold_cross_validation(model=clone(model), X=x_train, y=y_train, n_splits=N_SPLITS, method='soft',\n",
    "                                             random_state=RANDOM_SEED)  # 交叉验证得到软标签\n",
    "# 将概率转化为预测结果\n",
    "y_train_pred = np.argmax(y_train_pred_proba, axis=1)\n",
    "\n",
    "Acc1, Acc2, Acc3 = calculate_accuracy(y_train_pred, y_train, weights_train)\n",
    "constraints = [Acc1, Acc2, Acc3]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-04T08:09:11.934478Z",
     "start_time": "2025-01-04T08:09:11.252092Z"
    }
   },
   "id": "abb6e4d62d32f110",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## E-SEIC"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bb11017ee1ef86"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "toolbox = init_toolbox_eseic(model, x_train, y_train, weights_train, constraints, n_splits=N_SPLITS,\n",
    "                             random_seed=RANDOM_SEED)  # 初始化toolbox\n",
    "\n",
    "\n",
    "def main(x_train, y_train, model, balanced_method='balanced'):\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = \"gen\", \"feasible\", \"ensembles_size\", \"avg_gmean\", \"avg_mauc\", \"avg_acc2\"\n",
    "    ####################################种群的初始化###########################\n",
    "    pop = toolbox.population(n=POPSIZE)  # 个体编码默认全为0\n",
    "    pop = toolbox.init_population(pop, balanced_method=balanced_method)  # 初始化种群中的个体\n",
    "    toolbox.evaluate(pop)  # 计算个体的适应度\n",
    "    ####################################种群的迭代#################################################\n",
    "    for gen in range(1, NGEN + 1):\n",
    "        offspring = selTournamentNDCD(pop, POPSIZE, tournsize=3)  # 锦标赛选择（1、先根据非支配排序的等级2、再根据拥挤距离）\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "        for i in range(0, len(offspring) - 1, 2):\n",
    "            if random.random() <= CXPB:\n",
    "                offspring[i], offspring[i + 1] = toolbox.mate(offspring[i], offspring[i + 1])  # 单点交叉\n",
    "            offspring[i] = toolbox.mutate(offspring[i], MR)[0]  # 二进制反转突变\n",
    "            offspring[i + 1] = toolbox.mutate(offspring[i + 1], MR)[0]  # 二进制反转突变\n",
    "            del offspring[i].fitness.values, offspring[i + 1].fitness.values\n",
    "        #############################################################合并、去重#####################################################\n",
    "        pop = pop + offspring  # 种群的合并\n",
    "        pop, _ = toolbox.remove_duplicates(pop)  # 去重\n",
    "        while len(pop) < POPSIZE:  # 保证种群大小为POPSIZE\n",
    "            add_individual = []\n",
    "            num_add = POPSIZE - len(pop)\n",
    "            for i in range(0, num_add):\n",
    "                index = random.randint(0, len(offspring) - 1)  # 在0-len(offspring)范围内随机产生一个索引\n",
    "                offspring[index] = toolbox.mutate(offspring[index], MR)[0]  # 选择index对应的个体进行突变\n",
    "                del offspring[index].fitness.values\n",
    "                add_individual.append(offspring[index])\n",
    "            pop = pop + add_individual  # 种群的合并\n",
    "            pop, _ = toolbox.remove_duplicates(pop)  # 去重\n",
    "        toolbox.evaluate(pop)  # 计算新种群适应度\n",
    "        ###############################################得到pareto_fronts############################################\n",
    "        feasible_pop, infeasible_pop = toolbox.get_feasible_infeasible(pop)  # 得到可行解与不可行解\n",
    "        if len(feasible_pop) >= POPSIZE:\n",
    "            pop, pareto_fronts = toolbox.select(feasible_pop, POPSIZE)\n",
    "            ensembles = pareto_fronts[0]  # pareto_first_front\n",
    "        elif len(feasible_pop) > 0:\n",
    "            pop = feasible_pop + infeasible_pop[:POPSIZE - len(feasible_pop)]  # 在不可行解中选取违约程度小的个体，保证pop数量为POPSIZE\n",
    "            ensembles = tools.sortNondominated(feasible_pop, len(feasible_pop))[0]  # pareto_first_front\n",
    "        else:\n",
    "            pop = feasible_pop + infeasible_pop[:POPSIZE - len(feasible_pop)]  # 加入不可行解中违约程度小的个体，保证pop数量为POPSIZE\n",
    "            ensembles = [infeasible_pop[0]]  # 没有可行解，集成不可行解中第一个个体\n",
    "        avg_gmean, avg_mauc = calculate_average_gmean_mauc(ensembles)  # 计算gmean、mauc的平均值\n",
    "        _, avg_acc2, _ = calculate_average_accuracy(ensembles)  # 计算acc1、acc2、acc3的平均值\n",
    "\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=gen, feasible=len(feasible_pop), ensembles_size=len(ensembles), avg_gmean=avg_gmean,\n",
    "                       avg_mauc=avg_mauc, avg_acc2=avg_acc2, **record)\n",
    "        print(logbook.stream)\n",
    "    ensemble_classifiers = ensemble_individuals(ensembles, clone(model), x_train, y_train)\n",
    "    return ensemble_classifiers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-04T08:09:11.950006Z",
     "start_time": "2025-01-04T08:09:11.935479Z"
    }
   },
   "id": "27f76c56ed1e7071",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tfeasible\tensembles_size\tavg_gmean\tavg_mauc\tavg_acc2\n",
      "1  \t5       \t2             \t0.540561 \t0.707846\t0.543383\n",
      "2  \t10      \t3             \t0.544199 \t0.711359\t0.546258\n",
      "3  \t17      \t3             \t0.548115 \t0.724589\t0.550556\n",
      "4  \t21      \t3             \t0.548115 \t0.724589\t0.550556\n",
      "5  \t28      \t4             \t0.548793 \t0.723306\t0.550864\n",
      "6  \t37      \t4             \t0.548793 \t0.723306\t0.550864\n",
      "7  \t42      \t1             \t0.569665 \t0.726933\t0.569731\n",
      "8  \t51      \t1             \t0.569665 \t0.726933\t0.569731\n",
      "9  \t53      \t1             \t0.569665 \t0.726933\t0.569731\n",
      "10 \t48      \t1             \t0.569665 \t0.726933\t0.569731\n",
      "11 \t47      \t1             \t0.569665 \t0.726933\t0.569731\n",
      "12 \t45      \t1             \t0.569665 \t0.726933\t0.569731\n",
      "13 \t51      \t1             \t0.569665 \t0.726933\t0.569731\n",
      "14 \t47      \t1             \t0.569665 \t0.726933\t0.569731\n",
      "15 \t51      \t2             \t0.566143 \t0.725861\t0.567953\n",
      "16 \t51      \t2             \t0.566143 \t0.725861\t0.567953\n",
      "17 \t52      \t2             \t0.566143 \t0.725861\t0.567953\n",
      "18 \t48      \t2             \t0.566143 \t0.725861\t0.567953\n",
      "19 \t48      \t2             \t0.566143 \t0.725861\t0.567953\n",
      "20 \t50      \t2             \t0.566143 \t0.725861\t0.567953\n",
      "21 \t49      \t2             \t0.566143 \t0.725861\t0.567953\n",
      "22 \t57      \t3             \t0.566316 \t0.723711\t0.56841 \n",
      "23 \t55      \t3             \t0.566316 \t0.723711\t0.56841 \n",
      "24 \t59      \t3             \t0.566316 \t0.723711\t0.56841 \n",
      "25 \t55      \t3             \t0.566316 \t0.723711\t0.56841 \n",
      "26 \t53      \t3             \t0.566316 \t0.723711\t0.56841 \n",
      "27 \t59      \t3             \t0.566316 \t0.723711\t0.56841 \n",
      "28 \t54      \t4             \t0.565969 \t0.729461\t0.569445\n",
      "29 \t52      \t4             \t0.565969 \t0.729461\t0.569445\n",
      "30 \t47      \t4             \t0.565969 \t0.729461\t0.569445\n",
      "##############################集成分类器的预测结果：################################\n",
      "集成分类结果：Recall[0.60769231 0.50704225 0.5106383 ]，Gmean：0.539859，mAUC：0.754509，Acc1：0.552542，Acc2：0.541791，Acc3：0.177369\n",
      "训练已结束！\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ensemble_classifiers = main(x_train, y_train, model=model, balanced_method='random')\n",
    "    print(\"##############################集成分类器的预测结果：################################\")\n",
    "    vote_pred_prob = vote_result_ensembles(ensemble_classifiers, x_test)  # 默认预测结果是软标签\n",
    "    vote_pred = np.argmax(vote_pred_prob, axis=1)\n",
    "    gmean, mauc, recall_per_class = calculate_gmean_mauc(vote_pred_prob, y_test)\n",
    "    acc1, acc2, acc3 = calculate_accuracy(vote_pred, y_test, weights_test)\n",
    "    print(f\"集成分类结果：Recall{recall_per_class}，Gmean：{gmean}，mAUC：{mauc}，Acc1：{acc1}，Acc2：{acc2}，Acc3：{acc3}\")\n",
    "    print(\"训练已结束！\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-04T08:17:15.059815Z",
     "start_time": "2025-01-04T08:09:11.951513Z"
    }
   },
   "id": "e8deac9b0ca9c40b",
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
