{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### MLP多层感知机"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "448a3c9bddf91cb8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[423 227 423 187 228 443]\n",
      "准确率: 0.8990160538581046\n",
      "\n",
      "分类报告:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       423\n",
      "           1       0.96      0.98      0.97       227\n",
      "           2       0.89      0.92      0.90       423\n",
      "           3       0.71      0.64      0.68       187\n",
      "           4       0.88      0.94      0.91       228\n",
      "           5       0.89      0.86      0.87       443\n",
      "\n",
      "    accuracy                           0.90      1931\n",
      "   macro avg       0.88      0.88      0.88      1931\n",
      "weighted avg       0.90      0.90      0.90      1931\n",
      "\n",
      "Confusion Matrix:\n",
      "[[411   1  10   0   1   0]\n",
      " [  0 222   0   0   5   0]\n",
      " [  5   1 390  15   0  12]\n",
      " [  3   3  31 120   2  28]\n",
      " [  4   2   0   2 214   6]\n",
      " [  1   3   9  31  20 379]]\n",
      "[423 227 423 187 228 443]\n",
      "[411 222 390 120 214 379]\n",
      "1736\n",
      "(1931, 6)\n"
     ]
    }
   ],
   "source": [
    "from utils.dataset_utils import get_classes_indexes_counts\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# 导入必要的库\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "# data = load_iris()\n",
    "mat_data = sio.loadmat('../data/dataset/Satellite.mat')\n",
    "X = mat_data['X']  # 特征\n",
    "y = mat_data['Y'][:, 0]  # 标签\n",
    "\n",
    "# 将数据集分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)\n",
    "classes, counts = get_classes_indexes_counts(y_test)\n",
    "print(counts)\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 构建并训练MLP模型\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 20), max_iter=1000, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "index_pred_proba = mlp.predict_proba(X_test)\n",
    "# 预测和评估模型\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# 输出结果\n",
    "print(\"准确率:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n分类报告:\\n\", classification_report(y_test, y_pred))\n",
    "# 打印混淆矩阵\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(cm.sum(axis=1))\n",
    "print(cm.diagonal())\n",
    "print(cm.diagonal().sum())\n",
    "print(index_pred_proba.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-17T15:30:21.593069Z",
     "start_time": "2024-12-17T15:30:16.614095Z"
    }
   },
   "id": "9cd7ccca13891820",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别信息:\n",
      "类别 setosa:\n",
      " - 测试集数量: 15\n",
      " - 预测正确数量: 15\n",
      " - 预测错误数量: 0\n",
      "类别 versicolor:\n",
      " - 测试集数量: 15\n",
      " - 预测正确数量: 14\n",
      " - 预测错误数量: 1\n",
      "类别 virginica:\n",
      " - 测试集数量: 15\n",
      " - 预测正确数量: 12\n",
      " - 预测错误数量: 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "class_names = iris.target_names\n",
    "\n",
    "# 数据拆分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 定义并训练MLP模型\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# 测试集预测\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# 混淆矩阵\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# 输出结果\n",
    "print(\"类别信息:\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    total_count = np.sum(y_test == i)\n",
    "    correct_count = cm[i, i]\n",
    "    incorrect_count = total_count - correct_count\n",
    "    print(f\"类别 {class_name}:\")\n",
    "    print(f\" - 测试集数量: {total_count}\")\n",
    "    print(f\" - 预测正确数量: {correct_count}\")\n",
    "    print(f\" - 预测错误数量: {incorrect_count}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-17T15:30:21.791335Z",
     "start_time": "2024-12-17T15:30:21.593695Z"
    }
   },
   "id": "4f5c70b5119d0c03",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### k-folds交叉验证"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66d6d14f7b8da074"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        50\n",
      "  versicolor       1.00      0.54      0.70        50\n",
      "   virginica       0.68      1.00      0.81        50\n",
      "\n",
      "    accuracy                           0.85       150\n",
      "   macro avg       0.89      0.85      0.84       150\n",
      "weighted avg       0.89      0.85      0.84       150\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       1.00      0.31      0.47        13\n",
      "   virginica       0.59      1.00      0.74        13\n",
      "\n",
      "    accuracy                           0.80        45\n",
      "   macro avg       0.86      0.77      0.74        45\n",
      "weighted avg       0.88      0.80      0.77        45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\IDE\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. 加载鸢尾花数据集\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# 2. 初始化 MLP 模型\n",
    "mlp_1 = MLPClassifier(hidden_layer_sizes=(40,), max_iter=200, random_state=42)\n",
    "\n",
    "# 3. 配置五折交叉验证\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 4. 使用 cross_val_predict 进行交叉验证并获取预测\n",
    "y_pred = cross_val_predict(mlp_1, X, y, cv=cv)\n",
    "\n",
    "# 5. 输出分类报告\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y, y_pred, target_names=data.target_names))\n",
    "\n",
    "mlp_2 = MLPClassifier(hidden_layer_sizes=(40,), max_iter=200, random_state=42)\n",
    "# 数据集分割为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "mlp_2.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_pred = mlp_2.predict(X_test)\n",
    "\n",
    "# 输出分类报告\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-17T15:30:22.024091Z",
     "start_time": "2024-12-17T15:30:21.792336Z"
    }
   },
   "id": "ad39108c3a797bc6",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Nos下训练MLP"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "daa50f9a37227da"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1533  703 1358  626  707 1508]\n",
      "Accuracy: 0.86\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       423\n",
      "           1       0.94      0.98      0.96       227\n",
      "           2       0.79      0.92      0.85       423\n",
      "           3       0.70      0.37      0.48       187\n",
      "           4       0.85      0.84      0.85       228\n",
      "           5       0.84      0.84      0.84       443\n",
      "\n",
      "    accuracy                           0.86      1931\n",
      "   macro avg       0.85      0.82      0.82      1931\n",
      "weighted avg       0.85      0.86      0.85      1931\n",
      "\n",
      "Confusion Matrix:\n",
      "[[412   1   7   0   3   0]\n",
      " [  0 222   0   0   5   0]\n",
      " [  3   0 391  17   3   9]\n",
      " [  3   2  63  69   3  47]\n",
      " [ 14   5   0   2 192  15]\n",
      " [  0   5  37  11  19 371]]\n",
      "最终的集成分类结果：Recall_Per_Class[0.97399527 0.97797357 0.92434988 0.36898396 0.84210526 0.83747178]，Gmean：0.7822472905006482，mAUC：0.9755285901893908\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import gmean\n",
    "from utils.dataset_utils import get_classes_indexes_counts\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "\n",
    "mat_data = sio.loadmat('../data/dataset/Satellite.mat')\n",
    "X = mat_data['X']  # 特征\n",
    "y = mat_data['Y'][:, 0]  # 标签\n",
    "classes, counts = get_classes_indexes_counts(y)\n",
    "# 将数据集分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)\n",
    "\n",
    "print(counts)\n",
    "# 构建并训练MLP模型\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(20), max_iter=500, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_proba = mlp.predict_proba(X_test)\n",
    "# 预测和评估模型\n",
    "y_pred = mlp.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# 计算 ROC AUC（ovo+macro）\n",
    "auc_ovo_macro = roc_auc_score(y_test, y_proba, multi_class=\"ovo\", average=\"macro\")\n",
    "# 计算每类召回率（每类正确预测个数 / 该类总数）\n",
    "recall_per_class = cm.diagonal() / cm.sum(axis=1)\n",
    "# 计算G-Mean\n",
    "geometric_mean = gmean(recall_per_class)\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "# 打印分类报告\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "# 打印混淆矩阵\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(f\"最终的集成分类结果：Recall_Per_Class{recall_per_class}，Gmean：{geometric_mean}，mAUC：{auc_ovo_macro}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-17T15:30:23.303980Z",
     "start_time": "2024-12-17T15:30:22.025092Z"
    }
   },
   "id": "7ced2f4b739f085e",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 平衡数据集后的训练"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2e57a26e7e5a875"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征数据: (6435, 36) label: (6435,)\n",
      "每种类别的分布： [1533  703 1358  626  707 1508]\n",
      "#########################划分数据集#########################\n",
      "特征数据: (4504, 36) label: (4504,)\n",
      "训练集每种类别的分布： [1083  517  942  425  488 1049]\n",
      "训练集每种类别的权重： [0.09955827 0.20855244 0.11446031 0.25369791 0.22094593 0.10278514]\n",
      "测试集每种类别的分布： [450 186 416 201 219 459]\n",
      "#########################平衡数据集#########################\n",
      "最小数量: 425\n",
      "平衡的数据集的特征数据: (2550, 36)\n",
      "label: (2550,)\n",
      "平衡的数据集中每种类别的分布： [425 425 425 425 425 425]\n",
      "Accuracy: 0.87\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       450\n",
      "           1       0.96      0.97      0.97       186\n",
      "           2       0.90      0.88      0.89       416\n",
      "           3       0.63      0.53      0.58       201\n",
      "           4       0.80      0.93      0.86       219\n",
      "           5       0.84      0.85      0.84       459\n",
      "\n",
      "    accuracy                           0.87      1931\n",
      "   macro avg       0.85      0.86      0.85      1931\n",
      "weighted avg       0.87      0.87      0.87      1931\n",
      "\n",
      "Confusion Matrix:\n",
      "[[435   1   4   1   9   0]\n",
      " [  0 180   0   1   5   0]\n",
      " [  5   0 368  34   1   8]\n",
      " [  1   0  29 107   2  62]\n",
      " [  3   4   0   1 204   7]\n",
      " [  0   2   7  25  33 392]]\n",
      "最终的集成分类结果：Recall_Per_Class[0.96666667 0.96774194 0.88461538 0.53233831 0.93150685 0.8540305 ]，Gmean：0.8396655291087676，mAUC：0.98041581037801\n",
      "Acc1: 0.8502\n",
      "Acc2: 0.8502\n",
      "Acc3: 0.1398\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import gmean\n",
    "from utils.dataset_utils import get_classes_indexes_counts\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "import numpy as np\n",
    "\n",
    "mat_data = sio.loadmat('../data/dataset/Satellite.mat')\n",
    "X = mat_data['X']  # 特征\n",
    "y = mat_data['Y'][:, 0]  # 标签\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", X.shape, \"label:\", y.shape)\n",
    "# 统计每个类别的个数\n",
    "classes, counts = get_classes_indexes_counts(y)  #np.argmax(y_onehot, axis=1)找最大值的索引，将0-1序列转化为0,1,2,3......的整数标签\n",
    "print(\"每种类别的分布：\", counts)\n",
    "print(\"#########################划分数据集#########################\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# 显示数据集分布\n",
    "print(\"特征数据:\", x_train.shape, \"label:\", y_train.shape)\n",
    "# 统计每个类别的个数 \n",
    "classes_train, counts_train = get_classes_indexes_counts(y_train)\n",
    "# 计算每个类的权重\n",
    "weights_train = (1 / counts_train.astype(float)) / np.sum(1 / counts_train.astype(float))\n",
    "print(\"训练集每种类别的分布：\", counts_train)\n",
    "print(\"训练集每种类别的权重：\", weights_train)\n",
    "classes_test, counts_test = get_classes_indexes_counts(y_test)\n",
    "print(\"测试集每种类别的分布：\", counts_test)\n",
    "print(\"#########################平衡数据集#########################\")\n",
    "# 确定每个类别的分布\n",
    "num_instances = int(counts_train.min() * 1.0)  # 向下取整\n",
    "num_instances_train = len(y_train)  # 取训练集的数量\n",
    "\n",
    "print(\"最小数量:\", num_instances)\n",
    "# 在每个类别中随机的选择该数量的实例的索引\n",
    "balanced_classes = np.array([])\n",
    "for indexes in classes_train:\n",
    "    random_selecte_indices = np.random.choice(indexes, size=num_instances, replace=False)\n",
    "    balanced_classes = np.hstack((balanced_classes, random_selecte_indices))\n",
    "balanced_classes = np.sort(balanced_classes).astype(int)\n",
    "# 得到平衡的数据集\n",
    "balanced_dataset_x = []\n",
    "balanced_dataset_y = []\n",
    "for index in balanced_classes:\n",
    "    balanced_dataset_x.append(x_train[index])\n",
    "    balanced_dataset_y.append(y_train[index])\n",
    "balanced_dataset_x = np.array(balanced_dataset_x)\n",
    "balanced_dataset_y = np.array(balanced_dataset_y).astype(int)\n",
    "# 显示数据集分布\n",
    "print(\"平衡的数据集的特征数据:\", balanced_dataset_x.shape)\n",
    "print(\"label:\", balanced_dataset_y.shape)\n",
    "# 统计每个类别的分布\n",
    "classes_balanced_dataset, counts_balanced_dataset = get_classes_indexes_counts(balanced_dataset_y)\n",
    "print(\"平衡的数据集中每种类别的分布：\", counts_balanced_dataset)\n",
    "\n",
    "# 构建并训练MLP模型\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(15), max_iter=100, random_state=42, learning_rate_init=0.1)\n",
    "mlp.fit(x_train, y_train)\n",
    "#mlp.fit(balanced_dataset_x, balanced_dataset_y)\n",
    "y_proba = mlp.predict_proba(x_test)\n",
    "# 预测和评估模型\n",
    "y_pred = mlp.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# 计算 ROC AUC（ovo+macro）\n",
    "auc_ovo_macro = roc_auc_score(y_test, y_proba, multi_class=\"ovo\", average=\"macro\")\n",
    "# 计算每类召回率（每类正确预测个数 / 该类总数）\n",
    "recall_per_class = cm.diagonal() / cm.sum(axis=1)\n",
    "# 计算G-Mean\n",
    "geometric_mean = gmean(recall_per_class)\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "# 打印分类报告\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "# 打印混淆矩阵\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(f\"最终的集成分类结果：Recall_Per_Class{recall_per_class}，Gmean：{geometric_mean}，mAUC：{auc_ovo_macro}\")\n",
    "\n",
    "######################计算三个目标值#########################\n",
    "mlp_k_folds = MLPClassifier(hidden_layer_sizes=(15), max_iter=100, random_state=42, learning_rate_init=0.1)\n",
    "# 3. 配置五折交叉验证\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 4. 使用 cross_val_predict 进行交叉验证并获取预测\n",
    "y_pred_k_folds = cross_val_predict(mlp_k_folds, balanced_dataset_x, balanced_dataset_y, cv=cv)\n",
    "cm_k_folds = confusion_matrix(balanced_dataset_y, y_pred_k_folds)\n",
    "tp_per_class = cm_k_folds.diagonal()  # 对角线元素表示每个类预测正确的个数，对角线求和，即所有预测正确的实例个数之和，计算Acc1\n",
    "s_per_class = cm_k_folds.sum(axis=1)\n",
    "Acc1 = np.sum(tp_per_class) / np.sum(s_per_class)  # Acc1\n",
    "Acc2 = np.mean(tp_per_class.astype(float) / s_per_class.astype(float))  # Acc2\n",
    "Acc3 = np.mean((tp_per_class.astype(float) / s_per_class.astype(float)) * weights_train)  # Acc3\n",
    "# 输出Acc1, Acc2, Acc3\n",
    "print(\"Acc1:\", round(Acc1, 4))\n",
    "print(\"Acc2:\", round(Acc2, 4))\n",
    "print(\"Acc3:\", round(Acc3, 4))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-17T15:30:24.135317Z",
     "start_time": "2024-12-17T15:30:23.305203Z"
    }
   },
   "id": "5b1e9ebe6f7364a0",
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
