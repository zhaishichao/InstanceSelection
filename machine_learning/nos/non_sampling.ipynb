{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-16T12:35:04.401235Z",
     "start_time": "2025-03-16T12:35:04.017939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yeast distribution: [463  35  44  51 163 243 429  20  30]\n",
      "trainset distribution: [362  26  36  43 136 193 348  15  23]\n",
      "testset distribution: [101   9   8   8  27  50  81   5   7]\n",
      "最小数量: 14\n",
      "(0.0, 0.883151, array([0.44554455, 0.66666667, 1.        , 0.5       , 0.92592593,\n",
      "       0.66      , 0.67901235, 0.6       , 0.        ]))\n"
     ]
    }
   ],
   "source": [
    "from utils.dataset_utils import get_distribution, k_fold_cross_validation\n",
    "from instance_selection.parameter.parameter import *  # 导入参数的设定\n",
    "from instance_selection.operator.metrics import calculate_gmean_mauc, calculate_accuracy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.base import clone\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # 忽略警告\n",
    "\n",
    "DATASET = Yeast  # 数据集名称（包含对应参数的字典形式）\n",
    "datasetname = DATASET['DATASETNAME'].split('.')[0]\n",
    "mat_data = sio.loadmat(IMBALANCED_DATASET_PATH + DATASET['DATASETNAME'])  # 加载、划分数据集\n",
    "x = mat_data['X']\n",
    "y = mat_data['Y'][:, 0]  # mat_data['Y']得到的形状为[n,1]，通过[:,0]，得到形状[n,]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=RANDOM_SEED)  # 划分数据集\n",
    "scaler = StandardScaler()  # 数据的标准化\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "unique_elements_all, classes_all, counts_all = get_distribution(y)  # 获取原始数据集分布\n",
    "unique_elements_train, classes_train, counts_train = get_distribution(y_train)  # 获取训练集分布\n",
    "unique_elements_test, classes_test, counts_test = get_distribution(y_test)  # 获取测试集分布\n",
    "print(datasetname + f' distribution: {counts_all}')\n",
    "print(f'trainset distribution: {counts_train}')\n",
    "print(f'testset distribution: {counts_test}')\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(DATASET['HIDDEN_SIZE'],), max_iter=DATASET['MAX_ITER'],\n",
    "                      random_state=RANDOM_SEED, learning_rate_init=DATASET['LEARNING_RATE'])\n",
    "\n",
    "weights_train = (1 / counts_train.astype(float)) / np.sum(1 / counts_train.astype(float))  # 计算每个类的权重，用于计算每个类别的权重\n",
    "\n",
    "num_instances = int(np.ceil(counts_train.min() * 0.9))  # 取最小数量的类的0.9（向下取整）\n",
    "print(\"最小数量:\", num_instances)\n",
    "\n",
    "y_train_pred_proba = k_fold_cross_validation(model=clone(model), X=x_train, y=y_train, n_splits=N_SPLITS, method='soft',\n",
    "                                             random_state=RANDOM_SEED)  # 交叉验证得到软标签\n",
    "# 将概率转化为预测结果\n",
    "y_train_pred = np.argmax(y_train_pred_proba, axis=1)\n",
    "\n",
    "Acc1, Acc2, Acc3 = calculate_accuracy(y_train_pred, y_train, weights_train)\n",
    "constraints = [Acc1, Acc2, Acc3]\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_test_pred_proba = model.predict_proba(x_test)\n",
    "print(calculate_gmean_mauc(y_test_pred_proba, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
