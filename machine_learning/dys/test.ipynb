{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from instance_selection.operator.metrics import calculate_gmean_mauc\n",
    "from mlp_sklearn import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from instance_selection.parameter.parameter import *\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    DATASET = Nursery  # 数据集名称（包含对应参数的字典形式）\n",
    "    datasetname = DATASET['DATASETNAME'].split('.')[0]\n",
    "\n",
    "    # 加载、划分数据集\n",
    "    mat_data = sio.loadmat('../../data/dataset/' + DATASET['DATASETNAME'])\n",
    "    x = mat_data['X']\n",
    "    y = mat_data['Y'][:, 0]  # mat_data['Y']得到的形状为[n,1]，通过[:,0]，得到形状[n,]\n",
    "    # 对y使用one-hot编码\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    y_onehot = encoder.fit_transform(y)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y_onehot, test_size=0.3, random_state=RANDOM_SEED)  # 划分数据集\n",
    "    scaler = StandardScaler()  # 数据的标准化\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    # 定义网络参数\n",
    "    input_size = x.shape[1]\n",
    "    hidden_size = DATASET['HIDDEN_SIZE']\n",
    "    output_size = np.unique(y_train).size\n",
    "    learning_rate = DATASET['LEARNING_RATE']\n",
    "\n",
    "    # 创建MLP模型\n",
    "    model = MLPClassifier(hidden_layer_sizes=(DATASET['HIDDEN_SIZE'],), max_iter=DATASET['MAX_ITER'],\n",
    "                          random_state=RANDOM_SEED, learning_rate_init=DATASET['LEARNING_RATE'])\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred_prob = model.predict_proba(x_test)\n",
    "    gmean, mauc, recall_per_class = calculate_gmean_mauc(y_pred_prob, y_test)\n",
    "    print(f\"G-Mean: {gmean:.4f}, M-AUC: {mauc:.4f}, Recall per class: {recall_per_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, learning_rate=0.01):\n",
    "        # 初始化网络参数（权重和偏置）\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layers = []\n",
    "        self.biases = []\n",
    "\n",
    "        # 初始化每一层的权重和偏置\n",
    "        layer_sizes = [input_size] + hidden_sizes + [output_size]\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            self.layers.append(np.random.randn(layer_sizes[i], layer_sizes[i + 1]) * 0.1)\n",
    "            self.biases.append(np.zeros((1, layer_sizes[i + 1])))\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def relu_derivative(self, x):\n",
    "        return (x > 0).astype(float)\n",
    "\n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 存储每一层的中间结果\n",
    "        self.zs = []  # 线性变换结果\n",
    "        self.activations = [x]  # 激活后的结果\n",
    "\n",
    "        for i in range(len(self.layers)):\n",
    "            z = np.dot(self.activations[-1], self.layers[i]) + self.biases[i]\n",
    "            self.zs.append(z)\n",
    "            if i == len(self.layers) - 1:  # 输出层使用softmax\n",
    "                activation = self.softmax(z)\n",
    "            else:  # 隐藏层使用ReLU\n",
    "                activation = self.relu(z)\n",
    "            self.activations.append(activation)\n",
    "\n",
    "        return self.activations[-1]\n",
    "\n",
    "    def backward(self, x, y):\n",
    "        # 前向传播获取预测值\n",
    "        output = self.forward(x)\n",
    "\n",
    "        # 计算输出层的误差\n",
    "        m = y.shape[0]  # 样本数\n",
    "        dz = output - y  # 输出层误差（交叉熵损失的梯度）\n",
    "\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            dw = np.dot(self.activations[i].T, dz) / m\n",
    "            db = np.sum(dz, axis=0, keepdims=True) / m\n",
    "            if i > 0:\n",
    "                da = np.dot(dz, self.layers[i].T)\n",
    "                dz = da * self.relu_derivative(self.zs[i - 1])\n",
    "\n",
    "            # 更新权重和偏置\n",
    "            self.layers[i] -= self.learning_rate * dw\n",
    "            self.biases[i] -= self.learning_rate * db\n",
    "\n",
    "    def train_one_sample(self, x, y):\n",
    "        # 将输入 x 和 y 转换为行向量形式\n",
    "        x = x.reshape(1, -1)\n",
    "        y = y.reshape(1, -1)\n",
    "        self.backward(x, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        # 前向传播获取输出\n",
    "        output = self.forward(x)\n",
    "        return np.argmax(output, axis=1)\n",
    "\n",
    "    def predict_prob(self, x):\n",
    "        \"\"\"\n",
    "        返回每个样本的预测概率分布。\n",
    "        参数：\n",
    "        - x: 输入数据，形状为 (n_samples, n_features)\n",
    "        返回值：\n",
    "        - probs: 预测概率分布，形状为 (n_samples, n_classes)\n",
    "        \"\"\"\n",
    "        return self.forward(x)\n",
    "\n",
    "\n",
    "# 测试MLP\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建一个MLP，输入层大小为2，隐藏层大小为[4, 4]，输出层大小为2\n",
    "    mlp = MLP(input_size=2, hidden_sizes=[4, 4], output_size=2, learning_rate=0.01)\n",
    "\n",
    "    # 创建简单的数据集（逻辑回归任务）\n",
    "    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "    Y = np.array([[1, 0], [0, 1], [0, 1], [1, 0]])  # 独热编码标签\n",
    "\n",
    "    # 训练模型，每次输入一个样本\n",
    "    epochs = 1000\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(X.shape[0]):\n",
    "            mlp.train_one_sample(X[i], Y[i])\n",
    "\n",
    "    # 测试模型\n",
    "    predictions = mlp.predict(X)\n",
    "    print(\"Predictions:\", predictions)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e78fe340f98b58c8",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 模型的训练与测试"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9babec8081c3dfa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, learning_rate=0.01):\n",
    "        # 初始化网络参数（权重和偏置）\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layers = []\n",
    "        self.biases = []\n",
    "\n",
    "        # 初始化每一层的权重和偏置\n",
    "        layer_sizes = [input_size] + hidden_sizes + [output_size]\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            self.layers.append(np.random.randn(layer_sizes[i], layer_sizes[i + 1]) * 0.1)\n",
    "            self.biases.append(np.zeros((1, layer_sizes[i + 1])))\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def relu_derivative(self, x):\n",
    "        return (x > 0).astype(float)\n",
    "\n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 存储每一层的中间结果\n",
    "        self.zs = []  # 线性变换结果\n",
    "        self.activations = [x]  # 激活后的结果\n",
    "\n",
    "        for i in range(len(self.layers)):\n",
    "            z = np.dot(self.activations[-1], self.layers[i]) + self.biases[i]\n",
    "            self.zs.append(z)\n",
    "            if i == len(self.layers) - 1:  # 输出层使用softmax\n",
    "                activation = self.softmax(z)\n",
    "            else:  # 隐藏层使用ReLU\n",
    "                activation = self.relu(z)\n",
    "            self.activations.append(activation)\n",
    "\n",
    "        return self.activations[-1]\n",
    "\n",
    "    def backward(self, x, y):\n",
    "        # 前向传播获取预测值\n",
    "        output = self.forward(x)\n",
    "\n",
    "        # 计算输出层的误差\n",
    "        m = y.shape[0]  # 样本数\n",
    "        dz = output - y  # 输出层误差（交叉熵损失的梯度）\n",
    "\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            dw = np.dot(self.activations[i].T, dz) / m\n",
    "            db = np.sum(dz, axis=0, keepdims=True) / m\n",
    "            if i > 0:\n",
    "                da = np.dot(dz, self.layers[i].T)\n",
    "                dz = da * self.relu_derivative(self.zs[i - 1])\n",
    "\n",
    "            # 更新权重和偏置\n",
    "            self.layers[i] -= self.learning_rate * dw\n",
    "            self.biases[i] -= self.learning_rate * db\n",
    "\n",
    "    def train_one_sample(self, x, y):\n",
    "        # 将输入 x 和 y 转换为行向量形式\n",
    "        x = x.reshape(1, -1)\n",
    "        y = y.reshape(1, -1)\n",
    "        self.backward(x, y)\n",
    "\n",
    "    def predict_prob(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def predict(self, x):\n",
    "        probs = self.predict_prob(x)\n",
    "        return np.argmax(probs, axis=1)\n",
    "\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X = iris.data  # 特征\n",
    "y = iris.target  # 标签\n",
    "\n",
    "# 数据预处理\n",
    "# 将标签转换为独热编码\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_onehot = encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.3, random_state=42)\n",
    "\n",
    "# 创建 MLP 模型\n",
    "input_size = X_train.shape[1]  # 特征维度\n",
    "hidden_sizes = [10, 8]  # 两个隐藏层，大小分别为 10 和 8\n",
    "output_size = y_train.shape[1]  # 类别数\n",
    "mlp = MLP(input_size=input_size, hidden_sizes=hidden_sizes, output_size=output_size, learning_rate=0.01)\n",
    "\n",
    "# 训练模型\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    for i in range(X_train.shape[0]):\n",
    "        mlp.train_one_sample(X_train[i], y_train[i])\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} completed\")\n",
    "\n",
    "# 测试模型\n",
    "y_test_probs = mlp.predict_prob(X_test)\n",
    "y_test_preds = mlp.predict(X_test)\n",
    "\n",
    "# 计算测试集准确率\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "accuracy = np.mean(y_test_preds == y_test_labels)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cbceb5ae46a9a74",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: [ 2  4 11 14 21 24 27 32 38 40 43 46 62 72 75 82 92]\n",
      "Class 1: [ 9 25 31 33 37 41 53 71 74 76 77 84 86 95]\n",
      "Class 2: [12 30 36 39 45 47 50 51 54 56 57 58 60 66 67 69 93]\n",
      "Class 3: [ 1  6  7 10 16 17 26 44 48 59 68 79 81 83 88 89 90 91 98]\n",
      "Class 4: [ 3  5 13 15 23 34 35 42 49 61 73 78 80 87 96 99]\n",
      "Class 5: [ 0  8 18 19 20 22 28 29 52 55 63 64 65 70 85 94 97]\n"
     ]
    }
   ],
   "source": [
    "# 生成1000条特征数据x和对应的标签y(0-5)\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.rand(20, 2)\n",
    "y = np.random.randint(0, 6, size=100)\n",
    "unique_elements, _ = np.unique(y, return_counts=True)\n",
    "# 构造每个类别的索引列表\n",
    "class_indices = {element: np.where(y == element)[0] for element in unique_elements}\n",
    "# 输出类别以及索引列表\n",
    "for element, indices in class_indices.items():\n",
    "    print(f\"Class {element}: {indices}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T02:59:47.085951Z",
     "start_time": "2025-01-12T02:59:47.019354Z"
    }
   },
   "id": "dd9f4bd6b060ba9f",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from instance_selection.operator.constraint import individuals_constraints_in_classes\n",
    "# 生成2个长度为1000的list，list元素是0\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "inds = np.zeros((2,100))\n",
    "inds2 = individuals_constraints_in_classes(inds, x, y)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-01-12T02:59:50.593618Z"
    }
   },
   "id": "f1acfeab49c58df6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MLP-SKLEARN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed731b2d136e8b59"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.845994, 0.978635, array([0.96283784, 0.97080292, 0.82142857, 0.62307692, 0.89208633,\n",
      "       0.85901639]))\n"
     ]
    }
   ],
   "source": [
    "from utils.dataset_utils import get_distribution, k_fold_cross_validation\n",
    "from instance_selection.parameter.parameter import *  # 导入参数的设定\n",
    "from instance_selection.operator.metrics import calculate_gmean_mauc, calculate_average_accuracy, \\\n",
    "    calculate_average_gmean_mauc, calculate_accuracy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.base import clone\n",
    "import scipy.io as sio  # 从.mat文件中读取数据集\n",
    "import random\n",
    "from deap import tools\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # 忽略警告\n",
    "\n",
    "DATASET = Satellite\n",
    "\n",
    "# 数据集名称（包含对应参数的字典形式）\n",
    "datasetname = DATASET['DATASETNAME'].split('.')[0]\n",
    "mat_data = sio.loadmat(IMBALANCED_DATASET_PATH + DATASET['DATASETNAME'])  # 加载、划分数据集\n",
    "x = mat_data['X']\n",
    "y = mat_data['Y'][:, 0]  # mat_data['Y']得到的形状为[n,1]，通过[:,0]，得到形状[n,]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=RANDOM_SEED)  # 划分数据集\n",
    "scaler = StandardScaler()  # 数据的标准化\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(DATASET['HIDDEN_SIZE'],), max_iter=DATASET['MAX_ITER'],\n",
    "                      random_state=RANDOM_SEED, learning_rate_init=DATASET['LEARNING_RATE'],solver='adam')\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# 将概率转化为预测结果\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_proba = model.predict_proba(x_test)\n",
    "\n",
    "print(calculate_gmean_mauc(y_pred_proba, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T13:56:57.204942Z",
     "start_time": "2025-01-13T13:56:56.749432Z"
    }
   },
   "id": "eff897c6f5a9011d",
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
